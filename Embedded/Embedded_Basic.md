# **Embedded_Basic**

# **무엇을 배워야 임베디드 리눅스 개발을 잘할 수 있을까?**

---

좁게 보면 임베디드 리눅스 개발자가 알아야할 지식은 다음과 같다.

- 리눅스 디바이스 드라이버
- 리눅스 커널
- CPU 아키텍쳐
- SoC

조금 넓게 보면 다응 내용도 알면 좋다.

- 유저 공간 HAL(Hardware Abstraction Layer) 코드 구현
- 빌드 스크립트 구현
- 테스트용 디바이스 드라이버 구현
- git과 형상관리

## < 디바이스 드라이버 >

> 임베디드 리눅스 개발을 시작하면 바로 디바이스 드라이버를 맡는 경우가 많다. 물론 프로세스나 개발 회사 규모에 따라 드라이버 개발 범위가 다르다. 제품을 이루는 디바이스 드라이버의 특정 분야를 맡을 수도 있고 어떤 경우 한 명의 임베디드 개발자가 임베디드 리눅스를 책임지는 경우도 있다.

디바이스 드라이버의 사니로와 제어하는 하드웨어의 종류가 다양하다. 하지만 다응 내용 정도는 알아두는 것이 좋다.

- **인터럽트 핸들러 함수와 인터럽트를 처리하는 방식**
- **디바이스 파일로 open/read/write 연산 함수 등록하는 방법**
- **디바이스 트리를 읽어 디바이스 속성을 저장하는 방식**

개발에 투입이 되면 자신이 작성한 디바이스 드라이버 코드보다 다른사람이 작성한 코드를 읽을 가능성이 높다. 따라서 디바이스 드라이버 코드를 빨리 읽고 이해하는 능력을 키우는 것도 중요하다.

## < 리눅스 커널 >

디바이스 드라이버는 리눅스 커널에서 제공하는 함수로 이루어져 있다. 호출한 함수 원리를 알려면 자연히 리눅스 커널 코드를 분석할 수 밖에 없다. 어떤 분은 "리눅스 디바이스 드라이버는 리눅스 커널 그자체"라고 말하는데 그 의견에 동의한다.

또한 디바이스 드라이버 개발 과정은 코드를 입력해 드라이버를 구현하는 데 그치지 않는다. 인증 테스트 부서를 통해 드라이버 안정화 테스트 과정을 거치고 그 과정에서 다양한 버그나 문제 증상이 리포트 된다.

카메라 리눅스 디바이스의 경우 사진을 찍은 후 저장한 화면이 모두 검은색일 수 도 있고 그래픽 디바이스의 경우 화면이 깨질 수도 있다.

이 과정에서 만나는 다양한 버그를 수정해 문제를 해결하기 위해서는 리눅스 커널을 잘 알아야 한다.

## < CPU 아키텍쳐 >

리눅스 커널 코드를 조금 깊게 들여다 보면 만날 수 밖에 없는 것이 있다.

***바로 어셈블리 코드이다.***

리눅스 커널의 핵심 개념들은 대부분 어셈블리 코드로 구현돼 있다. 그 이유는 리눅스 커널 핵심동작은 CPU와 연관된 부분이 많기 때문이다.

- **컨텍스트 스위칭**
- **익셉션 벡터**
- **시스템 콜**
- **시그널 핸들러**
- **메모리 관리(MMU)**

처음 리눅스를 접하는 분은 무리해서 CPU 세부원리와 어셈블리 코드를 공부할 필요는 없다. 일단 리눅스 시스템과 커널 로그와 ftrace에 친숙해지는 것이 먼저이다.

위에 언급된 내용은 중간 정도만 하면 된다. 대신 시간을 모두 쏟아 부을 필요는 없다. 임베디드 및 BSP 리눅스 개발자의 핵심은 디바이스 드라이버와 커널이다. 하지만 위에서 언급한 기술에 신경을 안 쓰면 실전 개발에서 많은 걸림돌은 만나게 될 것이다.





# **임베디드 기본적인 몇가지**

## 버스

통신을 하기 위한 물리적(회로) 신호의 묶음(Bus). 전기적 신호 논할 때 사용

## 버스 프로토콜

버스 신호를 이용하여 통신 시작/종료, 방법 등 구체적으로 동작하는 버스 신호의 변화를 칭함



간단히 말하면 **버스는 전기신호를 말하고 프로토콜은 신호를 제어해서 통신하는 방법**을 말하는 것이다 !

대부분의 프로토콜은 H/W에서, 즉 IC레벨에서 구현되어 있다. 제어하는 엔지니어가 무언가를 바꾸거나 할 수는 없다. 하지만 개발자는 이것을 알아야 하는데 그 이유는 **H/W가 잘못 된 경우 어떤 부분이 잘못 되었는지 디버깅을 하기 위함**이다. 이미 구현되었으니 출력신호는 정해져 있으며 만일 정해진 대로 출력이 안되면 해당 부분을 디버깅하는 식으로 개발이 진행된다.

시스템이 항상 잘 동작하기만 한다면 단순 구현만 하면 되지만 반대인 경우 원인을 찾기 위해서는 그 배경 지식인 개념을 이해하고 있어야 시스템을 볼 수 있는 눈이 생기게 된다.



진짜진짜 시작하기에 앞서.... LSB와 MSB에대해서 알아보자. 우선 이들은 어떠한 크기의 데이터 형이 있다면 그 데이터에서 가장 왼쪽에 있는 비트인지 혹은 가장 오른쪽에 있는 비트인지를 나타내는 비트이다.

## LSB란?

Least Significnat Bit의 약자로 하나의 데이터 형에서 가장 낮은 위치의 Bit를 의미한다. 예를 들어 `signed char` 데이터 형과 `unsigned char` 데이터 형에 대해서 예를 들면 아래와 같다.

![image-20200728152327402](https://user-images.githubusercontent.com/58545240/89979211-29ad5d80-dcaa-11ea-81a4-21cdebd22f09.png)

일단 LSB의 위치는 가장 값이 작은 비트인 2^0에 위치하고 잇는 것을 알 수 있다. 이 LSB의 값을 이용하여 해당 데이터 형에 들어 있는 실제 숫자가 짝수인지 홀수인지 손쉽게 알아낼 수 있다.

이런 LSB는 프로그래밍 시 주로 난수발생 함수, 해시 함수, 검사합(CheckSum) 함수 등에서 많이 쓰이고 있다. 왜냐하면 LSB는 값이 조금이라도 변경된다면, 데이터형의 최하위 비트이므로 그 값이 거의 100% 변화가 발생하기 때문이다.

![image-20200728152551110](https://user-images.githubusercontent.com/58545240/89979228-35008900-dcaa-11ea-96cb-bd281c802d6c.png)

다음은 `signed char` 데이터 형에서의 LSB에 대해 알아보자. signed char 데이터 형의 LSB역시 unsigned char 데이터 형에서의 큰 차이점은 없다. 즉 LSB에서 중요한 점은 바로 특정한 데이터 형의 가장 최하위 비트라는 점이다.

## MSB란?

Most Significant Bit의 약자로 어떠한 데이터 형의 최상위 비트를 의미한다. 이 MSB는 데이터 형에 따라서 특징이 조금 나뉘는데 우선 위에서 소개했던 unsigned char 데이터형의 MSB에 대해 살펴보면 2^7이라는 값을 지니고 있는 위치의 비트이다. 그 외에는 unsigned char 데이터 형의 가장 값이 큰 위치의 최상위 비트정도로 정의를 내릴수가 있다.

다음은 가장 중요하게 살펴볼 signed char 데이터 형에서의 MSB이다. 위에 소개했던 signed char 데이터 형의 MSB를 살펴보면 MSB위치가 부호자리를 나타내고 있는 것을 알 수 있다. 따라서 해당 데이터 형의 값이 MSB만 확인하면, 양수인지 혹은 음수인지를 손쉽게 알아낼 수 있다.

### 중요점

LSB와 MSB의 그 뜻 자체를 이해하는 것도 중요하지만 LSB나 MSB를 집적적으로 프로그래밍을 할 때 조사를 하는 경우는 매우 드물다. 따라서 LSB와 MSB의 보다 실무적인 본질을 알아야 한다 !

그것은 바로.. 임베디드 시스템 등에서 `시리얼 통신`을 할 때 시리얼 통신의 경우 송수신할 데이터의 각 비트를 단위시간에 따라서 순차적으로 보내게 된다. 즉 하나의 단위시간 동안 0혹은 1밖에 보낼 수 없는 구조라는 것이다.

이를 다시 전자에서 예를 들었던 unsigned char나 signed char 데이터 형에 비추어 바라봤을 때는 어떤 위치의 비트들이 단위시간 동안 가장 먼저 보내지고 가장 늦게 보내질지를 알야아 한다. 즉, MSB의 비트부터 순차적으로 데이터 비트를 보내 맨 마지막에 LSB의 비트를 보내는 것인지, 혹은 정반대로 LSB의 비트부터 차례로 보낸 다음 MSB를 맨 마지막에 보내는지를 명확히 알아야 할 때 매우 중요한 사항이 될것이다.

![image-20200728153414336](https://user-images.githubusercontent.com/58545240/89979236-3d58c400-dcaa-11ea-8a38-91b18fd35b43.png)

위의 그림과 같이 LSB부터 송신할 때와 MSB부터 송신할 때 수신지에서 받아들이는 값은 LSB부터 송신할 때와 MSB부터 송신할 때에 상이한 것을 알 수 있다. 즉 어떠한 데이터의 가장 최상위 비트부터 송신할 때는 수신지에서 해당 MSB를 LSB위치로 밀어넣게 되어있기 때문에 위와 같은 그림으로 데이터 송수신이 발생한다.

## FTP

> **File Transfer Protocol**

파일전송 프로토콜의 약자로 [TCP](https://namu.wiki/w/TCP)/[IP](https://namu.wiki/w/IP) 네트워크 상에서 컴퓨터들이 파일을 교환하기 위해 1971년에 최초로 공개된 통신 규약이다. 네트워크에 연결된 컴퓨터끼리 데이터를 원활하게 교환하기 위한 목적으로 개발되었다. 파생형으로 FTP에 [TLS](https://namu.wiki/w/TLS) 프로토콜이 적용된 [FTPS](http://en.wikipedia.org/wiki/FTPS)가 있으며, 비슷한 기능을 제공하는 [SSH](https://namu.wiki/w/SSH) 프로토콜 기반의 [SFTP](http://en.wikipedia.org/wiki/SSH_File_Transfer_Protocol)가 있다. SFTP는 FTP라는 키워드를 포함하고 있으며 용도 또한 같으나 FTP와 기술적인 연관성은 없는 완전히 다른 프로토콜임을 주의해야 한다.

FTP는 비밀번호가 평문으로 전송되어 보안성이 매우 떨어지므로 FTPS를 사용하는걸 적극 권장한다. FTPS의 경우 PROT P를 사용하면 데이터 전송까지 암호화되어 높은 보안성을 지니며, PROT C를 사용하면 데이터 전송을 암호화하지 않아 보안성이 떨어지지만 빠른 파일 전송이 가능하다. SFTP의 경우 포트를 하나만 사용하기 때문에 방화벽이 설치된 환경에서 셋팅하기가 쉬워 초보자한테 권장되나, 프로토콜 구조상 PROT P를 사용한 FTPS보다 속도가 느리다는 결함이 있다. FTP와 FTPS는 보통 제어용으로 21번 포트 및 데이터 전송용으로 20번 포트를, 패시브 모드의 경우 50000번대 이상의 포트를 추가적으로 많이 사용하며 FTPS의 경우 990포트를 사용하는 경우도 있다. SFTP는 보통 22번 포트를 사용한다.



**세부사항**

- 네트워크에서 사용하는 프로토콜 중에서는 드물게 제어 채널과 전송 채널이 분리되어 있다. 쉽게 설명하면 전화기 한 대와 팩스 한 대를 가지고 전화기로는 지금 가지고 있는 자료에 대해서 물어보고, 필요한 자료를 요청하면 팩스로 열심히 자료를 전송 받는 형태이다.

- FTP를 사용하여 데이터를 주고받기 위해서는 FTP 서버와 FTP 클라이언트가 필요하다. 원래 데이터 교환을 목적으로 개발된 것이기 때문에 안정성과 신뢰성이 보장된다. 그렇기에 회사나 동아리 같은 곳에서 FTP 서버 하나 구축해두면 자료를 공유할 때 상당히 유용한 물건이 된다. 하지만 국내의 경우에는 자료를 공유하기 위한 대안이 많다 보니 있으면 유용하지만 없어도 그만인 수준.

- 많은 FTP 클라이언트들이 휘황찬란한 GUI 환경을 제공하지만, 본래는 아래 그림과 같이 명령어 입력 방식이다. GUI 환경에서 작동하는 FTP 클라이언트들은 단지 명령어들을 자동으로 전송해 주는 것 뿐이다.

- [웹 브라우저](https://namu.wiki/w/웹 브라우저)도 FTP를 지원한다. 위의 명령어 입력 방식이 어려울 경우에는 이 방법을 써도 된다. 인터넷 주소창에서 http:// 대신 ftp:// 를 붙이고 FTP 서버 주소를 치면 ID와 비밀번호를 묻는 화면이 뜨고, 그걸 치고 들어가면 브라우저 화면에 FTP 서버의 파일 목록이 링크 형태로 주르륵 뜬다. 이것은 대용량 파일 전송은 웹에서 사용하는 HTTP 프로토콜보다는 파일 전송용으로 나온 FTP 프로토콜이 유리한 점이 많기 때문에 지원하는 것. [엣지](https://namu.wiki/w/엣지(웹 브라우저))에서는 지원하지 않는다.

- 1990년대에는 대부분의 소프트웨어 업체나 게임 업체 등이 별도의 FTP 서버를 구축하고 익명의 접속을 허용한 후에 자신들이 개발한 프로그램의 셰어웨어나 데모 버전, 패치 등을 공개하곤 하였다. 사실 그 시절에는 지금처럼 인터넷이 발달한 것이 아니었기에 FTP 말고는 불특정 다수에게 효과적으로 자료를 배포할 수 있는 방법이 거의 없었다. 외국의 다른 게임 회사들 대부분은 비슷한 방식으로 FTP 서버를 운용하는 곳이 있고 간혹 예전에 발매했던 추억의 게임들을 FTP에서 무료로 받을 수 있는 경우도 있는 경우도 있으니 찾아보는 것도 나쁘지는 않다. 다만 현재는 자사 웹사이트에 공개하는 게 여러 모로 이득이고, 패치 같은 것은 프로그램 내에 패치 업데이트용 프로그램을 내장시키는 추세라서 FTP에 대해 배우는 곳도 많지 않고, 사장되는 추세이다.사실상 웹기반 [파일전송 서비스](https://namu.wiki/w/파일전송 서비스)로 완전히 대체되었다.

- [리눅스](https://namu.wiki/w/리눅스) 배포판과 각종 리눅스의 중요 오픈소스 소프트웨어들은 FTP로 배포되는 경우가 많다. yum이나 apt와 같은 각종 리눅스 저장소도 FTP로 운영되고 있으며, 유명 배포판의 경우에는 전 세계에 저장소 미러링 FTP 서버를 운영하는 경우가 많다. 한국에서는 [카이스트](https://namu.wiki/w/카이스트), [Daum](https://namu.wiki/w/Daum), [네오위즈](https://namu.wiki/w/네오위즈)에서 운영하는 FTP 서버가 유명하다.

### linux에서 FTP로 디렉토리 전체 다운받는 방법

FTP를 이용해서 특정 디렉토리 및 그 하위 내용을 모두 받으려면 (recursively) 어떻게 해야 할까? 물론 FileZilla 같은 GUI FTP 클라이언트 프로그램을 사용하면 쉽게 받을 수 있다. 

하지만 GUI 프로그램을 사용할 수 없는 Shell 환경에서라면 wget 명령을 사용해서 받아오는 방법이 있다.

```bash
wget [OPTION]... [URL] ...
```

예를 들어, FTP 서버 IP가 1.1.1.1 이고 계정은 user1 암호는 password1 받고 싶은 디렉토리 경로가 /home/user1/download 라면 아래와 같이 입력하면 된다.

```bash
wget -r --ftp-user=user1 --ftp-password=password1 ftp://1.1.1.1//home/user1/download
```

-r 옵션이 recursive 하게 다운로드 받는 옵션이고 경로는 절대 경로를 입력하되 서버 주소와 경로명 사이에 / 가 2개임을 유의하자.

더 자세한 옵션에 대한 설명은 wget --help 라고 입력하면 볼 수 있다.

# **메모리**

---

1. RAM
   - 컴퓨터를 종료하면 데이터가 날아가는 휘발성 메모리
   - 하드 디스크나 CD와는 달리 속도가 매우 빠르다.(데이터에 랜덤하게 접근할 수 있음)
   - 컴퓨터는 대부분의 데이터들은 메모리에 보관해 놓고 작업을 한다. 틈틈이 하드디스크에 저장!
2. ROM
   - 컴퓨터를 종료해도 데이터가 날아가지 않는 비휘발성 메모리
   - ex) CD-ROM, DVD-ROM, 하드디스크 => (데이터에 순차적으로 접근한다)

컴퓨터의 한 개의 메모리 소자는 0 혹은 1의 값을 보관할 수 있다. 이 이진수 한 자리를 가리켜 비트(Bit)라고 한다. 따라서, 1개의 비트는 0 또는 1의 값을 보관할 수 있다. 8bit = 1byte

8bit(1byte)로 나타낼 수 있는 최대의 수는 0 ~ 0xFF. 0부터 255로 총 256개의 수를 나타내게 된다.

컴퓨터에서 연산을 담당하는 CPU에는 **레지스터(register)**라는 작은 메모리 공간이 있는데 이곳에다가 값을 불러다 놓고 연산을 수행하게 된다. 예를 들어 a+b를 하기 위해서는 a와 b의 값을 어디다 적어놓아야지, a+b를 할 수 있는 것처럼 CPU에서 연산을 수행하기 위해 잠시 써놓는 부분을 레지스터라고 한다.

이러한 레지스터의 크기는 컴퓨터 상에서 연산이 실행되는 최소 단위라고 볼 수 있고, 이 크기를 **워드**라고 부른다.

1워드는 64비트, 즉 8바이트가 된다.

# **프로세스(Process)**

---

## 1. 프로세스란?

- 프로세스(Process)란 실행중에 있는 프로그램(Program)을 말한다.
- 스케쥴링의 대상이 되는 작업(task)와 같은 의미로 쓰인다.
- 프로세스 내부에는 최소 하나의 스레드(thread)를 가지고 있는데, 실제로는 스레드단위로 스케쥴링을 한다.
- 하드디스크에 있는 프로그램을 실행하면, 실행을 위해서 **메모리할당**이 이루어지고, 할당된 메모리 공간으로 바이너리 코드가 올라가게 되는데 이 순간부터 프로세스라 불린다.
- 모든 프로세스는 각각 4G의 가상 주소공간(메모리공간X)을 부여받는다.
  - 운영체제 약 2G, 나머지 약 2G 응용프로그램의 고유 영역
  - 개발자는 이 가상주소공간 4G가 진짜 메모리인것 처럼 사용한다.
- 가상주소공간(virtual addres space) != 가상 메모리(virtual memory)

## 2. 가상주소공간

### 가상주소공간의 구조

![image-20200729135756106-1596589351106](https://user-images.githubusercontent.com/58545240/89979399-9d4f6a80-dcaa-11ea-91f0-7588ef3ea810.png)

- Code 영역 : 프로그램을 실행시키는 실행 파일 내의 명령어들이 올라간다.
- Data 영역 : 전역변수, static 변수의 할당
- Heap 영역 : 프로그래머의 **동적할당**을 위한 메모리 영역
  - C언어 => malloc & free
  - C++ => new & delete
  - JAVA => new & Garbage Collector
- Stack 영역 : 지역변수, 함수 호출시 전달되는 인자(파라미터)를 위한 메모리 영역
- page : 가상주소공간 4G를 4096byte(4K) 단위로 나눈 하나의 메모리 블록을 page라고 한다.
- 연산을 할 때는 값을 stack으로부터 레지스터로 가져오고 ALU로 넘겨서 연산을 수행한다. 연산 결과 값은 레지스터에 먼저 저장하고, stack영역에 재전달 한다.
- 레지스터의 스택포인터(SP)는 stack 프레임을 위해서 미리 공간을 확보한다.

### virtual machine

- register based machine(연산결과를 레지스터에 저장)
- virtual stack machine(연산결과를 stack에 저장하고 이를 다시 heap으로 반환)
- 연산결과를 임시로 젖아하는 공간을 operand stack이라고 부른다.
- 인터프린터 언어는 heap에 데이터를 저장하고 연산은 레지스터 ALU에서 실행 후 실행 결과를 stack에 저장. 해당값을 heap에 전달하려면 다시 레지스터를 거쳐야 한다.

### stack vs heap

- 가상주소공간 중 stack은 빠르고 heap은 상대적으로 느리다.
- stack은 그냥 데이터를 쌓지만 heap은 도중에 del등을 통해서 지울 수 있다. 빈공간이 생기면 그 곳에 새로운 데이터가 추가 된다.(spacial locality 보장이 어렵다)
- 또한, heap은 메타데이터 정보를 함께 저장한다. 따라서 더 많은 용량을 사용하며 할당시 매번 metadata에게 여분 공간이 있는지 묻기 때문에 상대적으로 느리다.
- **heap의 최대장점**
  - 할당시점과 지우는 시점을 마음대로 저장할 수 있다.
  - 프로세스 도중에 용량을 변경할 수 있다.(stack의 경우 프로세스 실행 전에만 변경 가능하다. 용랑이 넘치는 경우 stack overflow가 발생한다.)

## 3. 가상메모리

- 가상메모리 : 물리적인 RAM + 하드디스크
- page frame : 가상메모리(물리메모리 = RAM+페이징파일)를 4096byte(4K) 단위로 나눈 후, 그 한단위를 페이지 프레임이라 한다.
- 페이지 테이블 : 가상주소공간과 가상메모리를 매핑한다. 프로세스 별로 각각 하나씩 존재한다.
- RAM의 프레임이 모두 차있을 때, 추가 요청이 들어오면 RAM에서는 교체 알고리즘에 따라서 프레임 하나를 `페이징파일`로 내리고, 새롭게 요청된 페이지에 비워진 프레임을 할당한다.
- 가상메모리 운영방식 : LRU(least, recently, uses - 최근 최소 사용). 필요한것만 RAM으로 가져오고 안쓰는건 하드디스크에 내려놓는다.

## 4. 프로세스 스케쥴링

- CPU는 하나인데 동시에 실행되어야 할 프로세스가 여러개??

  => CPU가 고속으로 여러 프로세스를 일정한 기준으로 순서를 정해서 실행한다.

- **스케쥴링(Scheduling)**

  - CPU 할당 순서 및 방법을 결정하는 일.(어떤 프로세스를 running으로 보낼까?)
  - 일정한 기준 : 스케쥴링 알고리즘을 통해서.

*대부분의 OS에서는 **우선순위(Priority algorithm) 알고리즘**과 **라운드 로빈(Round Robin) 알고리즘**을 혼합해서 스케쥴링*

## 5. 프로세스 상태변화

![image-20200729141825350-1596589351107](https://user-images.githubusercontent.com/58545240/89979418-a6d8d280-dcaa-11ea-8fdd-d0485a702caa.png)

프로세스의 상태는 ready(준비), blocked(대기), running(실행) 상태가 있다.

- 생성(new) -> 준비(ready)

  => new 상태에서 프로세스가 생성되게 되면 OS 커널에 존재하는 Ready Queue에 올라가게 된다.

- 준비(ready) -> 실행(running)

  => Ready Queue에 있는 프로세스들을 OS가 위에서 말한 프로세스 스케쥴링 알고리즘에 의해서 Running 상태로 가야할 프로세스를 CPU로 할당하게 된다. 그러면 프로세스는 실행(Running)상태가 된다.

- 실행(running) -> 준비(ready)

  => 현재 running 상태에 있는 프로세스A보다 Ready Queue에서 대기하고 있는 프로세스 B 우선순위가 높으면, preemptive schedule(선점형)인 경우 프로세스A는 ready상태로 오게되고 프로세스B가 running상태로 가서 CPU를 할당받는다.

- 실행(running) -> 대기(blocked)

  => 현재 running 상태에 있는 프로세스A에서 입출력(I/O) 이벤트가 발생했을 때 프로세스A가 blocked상태로 가게된다.

- 대기(blocked) -> 준비(ready)

  => 입출력(I/O) 이벤트가 종료된 프로세스는 다시 Ready상태로 오게된다.

- 실행(running) -> terminate(종료)

  => 프로세스 종료

*ready, blocked 상태에는 여러 프로세스가 존재할 수 있다.*

*하지만, **싱글코어CPU**에서, running상태의 프로세스는 단 하나만 존재한다.*

# **워치독 타이머(WDT)**

> Watchdog Timer

## 1. 고신뢰성 시스템을 위한, 워치독 타이머

### 가. WDT의 개념

- 비정상, 무한루프 등에 빠진 경우 시스템 통제가 불가능한 상황에서 자동으로 시스템을 리셋하는 하드웨어 기능
- 타임아웃이 되기 전 S/W명령으로 그 값을 clear시켜주지 않으면 MCU를 reset시켜 시스템을 정상적으로 동작하고 있는지 감시하고 지속적인 오동작을 방지 신뢰성 향상 기술

### 나. WDT의 필요성

1. 제어 실패 방지 메커니즘 필요
   - 불필요한 반복 또는 제어 실패를 방지하는 메커니즘 필요
2. 예상치 못한 실패 안전모드 필요
   - 시스템 일부가 예상 못한 제어 실패 시 안전모드로 전환 필요

## 2. WDT 개념도 및 구성요소

### 가. WDT 구성도

![image-20200807170209219](https://user-images.githubusercontent.com/58545240/89979546-fddea780-dcaa-11ea-9812-ccdb3034ef7c.png)

### 나. WDT 구성요소

- `Clock` : HW 디바이스를 동작시키는 외부 Clock Source
- `Clear(Res-tart/Kick)` : HW 디바이스가 정상 동작함을 알려주는 주기적 Alive 신호
- `Timeout` : 타이머가 종료되었음을 알려주는 Output신호
- `Reset` : HW 디바이스를 초기화 할 수 있는 입력 시그널

### 다. WDT 동작방식

- Watchdog 타이머는 HW를 주기적으로 감시하며 시간을 쟤는 계수 회로. 디바이스로부터 일정 시간동안 입력값을 받지 못 하는 경우 시스템의 오동작 상황으로 간주하고 초기화 수행

## 3. WDT 유형 및 사례

### 가. WDT의 유형

![image-20200807170451892](https://user-images.githubusercontent.com/58545240/89979560-06cf7900-dcab-11ea-8cae-09f913ee24de.png)

- 외부 워치독 타이머는 고가이므로 높은 신뢰성 요구하는 시스템에 주로 사용

### 나. WDT 구현 방법

![image-20200807170528165](https://user-images.githubusercontent.com/58545240/89979575-0e8f1d80-dcab-11ea-9903-75f8c6ab0eba.png)

- 워치독 타이머는 고정 또는 프로그래밍 가능한 시간 간격 가능, 다단계 워치독의 각 타이머는 각 다른 시간 간격 가능

## 4. WDT 하드웨어 내부구조

![image-20200807170626944](https://user-images.githubusercontent.com/58545240/89979593-1ea6fd00-dcab-11ea-9d03-509967d06e73.png)

- `Watchdog Control Register (WDCR)`
  - 워치독을 컨트롤 하는 레지스터
  - 리셋 상태 설정, 사용여부, 로직 체크
- `Watchdog Counter Register (WDCNTR)`
  - 워치독 카운터의 상태 레지스터
  - 현재까지 카운팅 된 값 확인 가능
- `Watchdog Reset Key Register (WDKEY)`
  - 워치독 카운터를 Clear 하는 역할
- `System Control and Status Register(SCSR)`
  - 워치독 카운터 출력 신호 결과를 리셋 / 인터럽트에 이용 여부 결정

## 5. WDT 소프트웨어

### 가. WDT SW 동작 방식

![image-20200807170817579](https://user-images.githubusercontent.com/58545240/89979602-2666a180-dcab-11ea-8d22-095cf6e2ac56.png)



- 워치독 소프트웨어는 타이머 만료 시 작업 정의 및 하드웨어 타이머 시작 후 주기적 타이머 초기화 수행

### 나. WDT SW 사례

![image-20200807171644205](https://user-images.githubusercontent.com/58545240/89979616-2cf51900-dcab-11ea-838a-edf314b19a38.png)



# **MUTEX를 이용한 쓰레드 동기화**

---

## 1. 공유자원에 대한 접근 제어

다수의 객체가 공유 자원에 접근하려고 하면, (공유 자원의 종류에 따라서) 접근 시점을 동기화 시켜줄 필요가 생긴다. 여기에서 동기화란 시간과 공간을 맞추어 준다는 의미로, 즉 공유 자원 영역(공간)에 접근하는 객체들의 진입 시간을 제어할 수 있어야 함을 의미한다.

`Multi Thread(멀티 쓰레드)` 프로그램 역시 공유 자원에 여러 개의 쓰레드가 접근할 수 있으므로 **공유 자원 영역**에 대한 동기화가 필요하다.

카운팅 프로그램을 예로 들어보자. 카운트 변수는 전역변수(:12)로 A,B 두개의 쓰레드가 공유하면서, 1씩 증가하는 카운팅 정보를 유지하기 위해 사용된다. 공유자원 영역 즉 **"count 값을 읽어 오고, 연산을 해서 저장하는"** 영역에 대한 쓰레드간 동기화가 이루어지지 않는다면 아래와 같은 일이 발생할 수 있따.

1. global int count = 0;
2. A 쓰레드가 count값 0을 읽는다.
3. B 쓰레드가 count값 0을 읽는다.
   - A 쓰레드가 카운팅 연산을 하기 전에 B 쓰레드가 접근해 버린 상황이다.
4. A 쓰레드가 count+1 연산을 하고 값을 쓴다. count = 1
5. B 쓰레드가 count+1 연산을 하고 값을 쓴다. count = 1

A와 B 쓰레드가 한번씩 카운팅 연산을 했으므로 count값은 2가 되어야 하겠지만 실제로는 1이 저장되어 버렸다.

이러한 문제의 해결을 위해 쓰레드를 동기화 시켜줄 필요가 있다!!

## 2. 동기화 달성의 방법

일반적으로 동기화는 "공간과 시간"을 제어하는 방식으로 이루어진다. 즉 **"접근 제어가 피요한 공간"을 지정하고 지정한 "공간에 진입 할 수 있는 시간"을 제어하는 방식**이다.

여기에서 "접근 제어가 필요한 공간"에는 **보호해야할 공유자원**이 놓인다. 보호 해야할 공유 자원이 있는 공간을 **임계 영역**이라고 한다. 

시간제어는 해당 **임계 영역**에 동 시간에 단지 하나의 쓰레드만 접근하도록 제한 하는 방식으로 이루어진다.

임계영역에 들어가기 위한 **하난의 키**를 가지고 경쟁하는 것으로 이해하면 된다. 임계영역에 들어가기 위한 키는 단지 하나 밖에 없으므로 어떤 쓰레드가 키를 얻어서 임계영역에 진입하면, 다른 쓰레드는 키를 얻을 때 까지 ( 앞서 임계영역에 진입한 프로세스가 키를 되돌려 줄 때까지 ) 기다려야 한다.

![image-20200819170012492](https://user-images.githubusercontent.com/58545240/90612300-cf307600-e242-11ea-9868-c547b8baf1bd.png)

위의 카운팅 프로그램을 예로 들어 보자. **임계 영역**은

1. count값을 읽어와서
2. 카운팅 연산을 하고
3. 연산 결과글 저장하는 

코드영역으로 지정할 수 있을 것이다.

**이 임계영역에는 오직 하나의 쓰레드만이 진입할 수 있다.** 즉 **쓰레드A**가 임계영역에 진입해서 코드를 수행 중에 있다면 **쓰레드 B**는 임계 영역 밖에서 기다려야 한다. 이렇게 쓰레드를 동기화 시킴으로써, 아래와 같이 제대로된 카운팅 연산을 보장할 수 있게 된다.

1. global int count = 0;
2. A쓰레드가 임계 영역에 진입
3. B쓰레드가 임계 영역 진입을 시도하지만, A쓰레드가 진입해 있으므로 임계영역 밖에서 대기한다.
4. A쓰레드가 count값을 일고 
5. 카운팅 연산을해서
6. 값을 저장한다. count = 1
7. A쓰레드가 임계영역에서 빠져나온다
8. 비로소 B쓰레드가 임계영역에 진입해서
9. count값 읽어서 카운팅 연산을 하고 저장한다. count = 2

## 3. MUTEX

뮤텍스는 `pthread`에서 제공하는 동기화 매커니즘으로 **공유 자원 공간**에 대한 접근 시간 제어로 동기화를 달성한다. 기본적인 메커니즘은 `세마포어(:12)`와 비슷하다. 

특히 **POSIX(:12) 세마포어**와 비슷하며, 동기화 매커니즘으로 뮤텍스 대신 세마포어를 사용할 수도 있다. 동기화 매커니즘의 핵심은 **상호 배제**로 다음과 같이 달성한다.

```C
global int v = 1;
lock(){
    while(1){
        if(v==1) break;
    }
    v = 0;
    return 1;
}

unlock(){
    v = 1;
    break;
}
```

어디까지나 매커니즘 상으로 그렇다는 얘기고, 세마포어와 마찬가지로 `busy wait` 상태에 놓이지 않음을 보장한다.

**상호 배제**는 잠금 형식으로 이루어진다. 쓰레드는 **잠금 v**를 얻어야 임계 영역에 진입할 수 있다. 임계 영역을 빠져나오면 잠금을 되돌려 줘서 다른 쓰레드가 잠금을 얻을 수 있도록 한다.

뮤텍스 메커니즘의 특징을 정리했다.

- **Atomicity** : mutex 잠금(lock)은 최소 단위 연적(atomic operation)으로 작동한다. 하나의 쓰레드가 `mutex`를 이용해서 잠금을 시도하는 도중에 다른 쓰레드가 `mutex` 잠금을 할 수 없도록 해준다는 뜻이다. 한번에 하나의 `mutex` 잠금을 하도록 보장해준다.
- **Singularity** : 만약 쓰레드가 mutex 잠금을 했다면, 잠금을 한 쓰레드(:12)가 mutex 잠금을 해제 하기 전까지 다른 어떠한 쓰레드도 mutex 잠금을 할 수 없도록 보장해준다.
- **Non-Busy Wait** : 바쁜대기 상태에 놓이지 않는다는 뜻으로, 하나의 쓰레드가 mutex 잠금을 시도하는 데 이미 다른 쓰레드가 mutex 잠금을 사용하고 있다면, 이 쎄르드는 다른 쓰레드가 락을 해제하기 전까지 해당 지점에 머물러 있으며 이 동안 어떠한 CPU 자원도 소비하지 않는다.(이를테면 `sleep`)

## 4. MUTEX 만들기

뮤텍스를 생성하기 위해서 우리는 먼저, 뮤텍스 정보를 저장하기 위한 타입인 **`pthread_mutex_t`**를 선언해주고 이것을 초기화 해주어야 한다.

선언과 초기화의 가장 간단한 방법은 `PTHREAD_MUTEX_INITIALIZER` 상수를 할당하는 것으로 아래와 같이 사용할 수 있다.

```c
pthread_mutex_t a_mutex = PHTREAD_MUTEX_INITIALIZER;
```

혹은 `phread_mutex_init(3)`함수로 뮤텍스를 생성할 수도 있다.

```C
#include <pthread.h>

int pthread_mutex_init(phtread_mutex_t *mutex, const phtread_mutex_attr *attr);
```

## 5. MUTEX 잠금, 잠금해제, 제거

뮤텍스 잠금을 위한 함수로는 `phtread_mutex_lock()`함수를 제공한다. 이 함수는 해당 뮤텍스에 대해서 잠금을 시도하는데, 만약 잠그려는 뮤텍스가 다른 쓰레드에 의해서 이미 잠겨있다면, 잠금을 얻을 수 있을때까지( 이미 잠근 다른 쓰레드가 뮤텍스의 잠금을 해제할 때까지 ) 봉쇄( block )되게 된다.

다음은 이러한 뮤텍스 잠금을 얻기 위한 지원함수들이다.

```C
int pthread_mutex_lock(phtread_mutex_t *mutex);
int pthread_mutex_trylock(pthread_mutex_t *mutex);
int pthread_mutex_destroy(pthread_mutex_t *mutex);
```

`pthread_mutex_trylock()`을 사용하면 잠금을 얻을 수 없을 경우 해당 코드에서 `블럭`되지 않고 바로 에러코드를 돌려준다. 즉, `pthread_mutex_lock`의 비봉쇄 버전이라고 생각하면 된다.

뮤텍스 잠금을 얻은 후 해당 영역에서의 작업을 마친 후 잠금을 해제하기 위해서 사용된다. 사용되는 함수는 `phtread_mutex_unlock(3)`이며 함수 원형은 다음과 같다.

```C
int phtread_mutex_unlock(pthread_mutex_t *mutex);
```

다음은 쓰레드간 공유되는 자원을 위해서 잠금을 어떻게 사용하는지를 보여주는 간단한 예제다.

```c
#include <stdio.h>
#include <unistd.h>
#include <pthread.h>

int ncount;		// 쓰레드간 공유되는 자원
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;		// 쓰레드 초기화

void* do_loop(void *data){
    int i;
    for(i=0; i<10; i++){
        pthread_mutex_lock(&mutex);			// 잠금을 생성한다.
        printf("loop1 : %d\n", ncount);
        ncount ++;
        if(i == 10) return;
        pthread_mutex_unlock(&mutex);		// 잠금을 해제한다.
        sleep(1);
	}
}

void* do_loop2(void *data){
    int i;
    
    // 잠금을 얻으려고 하지만 do_loop에서 이미 잠금을 얻었음으로 잠금이 해제될때까지 기다린다.
    for(i=0; i<10; i++){
        pthread_mutex_lock(&mutex);			// 잠금을 생성한다.
        printf("loop2 : %d\n", ncount);
        ncount++;
        pthread_mutex_unlock(&mutex);		// 잠금을 해제한다.
        sleep(2);
    }
}

int main(){
    int	thr_id;
    pthread_t p_thread[2];
    int status;
    int a = 1;
    
    ncount = 0;
    thr_id = pthread_create(&p_thread[0], NULL, do_loop, (void *)&a);
    sleep(1);
    thr_id = pthread_create(&p_thread[1], NULL, do_loop2, (void *)&a);
    
    pthread_join(p_thread[0], (void *)&status);
    pthread_join(p_thread[1], (void *)&status);
    
    status = pthread_mutex_destroy(&mutex);
    printf("code = %d\n", status);
    printf("programming is end");
    return 0;
}
```

위의 코드를 우선 mutex 잠금을 하지 않은 채 컴파일 후 실행 해보자. 간단하게 `pthread_mutex_lock`과 `pthread_mutex_unlock`부분만 주석처리하면 된다.

그러면 `do_loop2`과 `do_loop`이 일정 간격을 두고 ncount 자원에 접근하는 것을 볼 수 있을것이다. 그러나 우리는 `do_loop`가 ncount자원을 접근하고 있는 동안 다른 쓰레드가 접근하지 않기를 원할 때가 있을 것이다. 이럴 때 뮤텍스잠금을 사용하면 된다.

위의 코드에서 잠금 부분의 주석을 다시 풀고 컴파일 후 실행해보면 `do_loop`쓰레드가 ncount 증가 작업을 모두 마칠 때까지 `do_loop2`쓰레드는 해당영역에서 `block`됨을 알 수 있다. 이런 식으로 **하나의 쓰레드가 특정자원에 접근할 때 다른 쓰레드가 접근하지 못하도록(한번에 하나의 쓰레드만 해당 자원에 접근할 수 있도록) 제어**할 수 있다.

컴파일 방법은 `gcc -o mutex_lock mutex_lock.c -lpthread`이다.

더이상 뮤텍스를 사용할 일이 없다면 `pthread_mutex_destroy`를 이용해서 뮤텍스 자원을 제거(free)하도록 한다. 만일 뮤텍스 자원을 사용하는 쓰레드가 하나라도 존재한다면 에러코드(`EBUSY`)를 리턴한다. 그러므로 **모든 쓰레드의 뮤텍스에 대해서 `pthread_mutex_unlock`을 이용해서 잠겨져야만 뮤텍스 제거가 성공할 수 있다. 성공할 경우 `0`을 넘겨준다.**

# **Semaphore**

---

> 프로세스 간 메시지를 전송하거나, 공유메모리를 통해 특정 데이터를 공유하게 되는 경우 문제가 발생할 수 있다. 
>
> 즉, 공유된 자원에 여러 개의 프로세스가 동시에 접근하면서 문제가 발생하는 것으로써 공유된 자원 속 하나의 데이터는 한 번에 하나의 프로세스만 접근할 수 있도록 제한해 두어야 하는데 이를 위하여 고안된 것이 바로 **Semaphore(세마포어)**이다.

## Critical Section이란?

OS에서 `Critical Section`은 아주 중요한 부분이다.

다중 프로그래밍 운영체제에서 여러 프로세스가 데이터를 공유하면서 수행될 때 **각 프로세스에서 공유 데이터를 액세스하는 프로그램 코드 부분**을 가리키는 말이다.

공유 데이터를 여러 프로세스가 동시에 액세스하면 시간적인 차이 때문에 잘못된 결과를 만들어 낼 수 있기 때문에 한 프로세스가 위험 부분을 수행하고 있을 때, 즉 공유 데이터를 액세스하고 있을 때는 다른 프로세스들은 절대로 그 데이터를 액세스하지 못하도록 해야 한다.

### - 예제

컴퓨터가 여러 프로그램을 동시에 수행하는 다중 프로그래밍 시스템에서는 프로세스들간의 상호배제와 동기화를 위한 기본적인 연산이 필요하게 되고 세마포어는 여러 프로세스들에 의해 공유되는 변수로 정의됩니다.

그런데 이 변수는 보통의 방법으로는 액세스할 수 없고 오직 P와 V라는 연산으로만 다룰 수 있습니다.

P와 V연산의 정의는 아래와 같습니다.

```bash
# P
procedure P(S)            --> 최초 S값은 1

while S=0 do wait        --> S가 0이면 1이 될 때까지 wait

S := S-1                     --> S를 0로 만들어 다른 프로세스가 들어 오지 못하도록 함

end P
```

```bash
# V
procedure V(S)          --> 현재상태는 S가 0

S := S+1                  --> S를 1로 원위치시켜 해제하는 과정

end V                     -->이제는 다른 프로세스가 들어 올수 있음
```

즉 한 프로세스가 P나 V를 수행하고 있는 동안에는 프로세스가 인터럽트를 당하지 않게 됩니다. 이제 P와 V를 사용하면 다음과 같이 위험지역(cirtical section)에 대한 상호배제를 구현할 수 있게 됩니다.

```bash
P(S);

------------------------

위 험 지 역(Critical Section) = 임계영역

------------------------

V(S);
```

최초에 S의 값은 1이고, 위와 같은 위험지역을 포함하는 두개의 프로세스 A와 B가 있다고 할 때,

A와 B는 서로 독립적으로 수행되지만, 두 프로세스가 동시에 위험 지역으로 들어가서는 안된다.

위와 같이 세마포어를 사용하면 P(S)를 먼저 수행하는 프로세스가 S를 0으로 해놓고 위험지역에 들어가므로 나중에 도착하는 프로세스는 P에서 더이상 진행되지 못하고 기다리게 된다. 먼저 들어갔던 프로세스가 V(S)를 해주어야 비로서 P(S)에서 기다리던 프로세스가 위험지역에 들어갈 수 있고 따라서 상호배제가 실현된다. 

## 세마포어와 뮤텍스의 차이

### 세마포어란?

> - 세마포어(Semaphore) : 공유된 자원의 데이터를 여러 **프로세스**가 접근하는 것을 막는 것
> - 뮤텍스(Mutex) : 공유된 자원의 데이터를 여러 **쓰레드**가 접근하는 것을 막는 것

세마포어는 리소스의 상태를 나타내는 간단한 카운터로 생각할 수 있다. 일반적으로 비교적 긴 시간을 확보하는 리소스에 대해 이용하게 되며, 유닉스 시스템의 프로그래밍에서 세마포어는 운영체제의 리소스를 경쟁적으로 사용하는 다중 프로세스에서 행동을 조정하거나 또는 동기화 시키는 기술이다.

세마포어는 운영체제 또는 커널의 한 지정된 저장장치 내 값으로서, 각 프로세스는 이를 확인하고 변경할 수 있습니다. 확인되는 세마포어의 값에 따라, 그 프로세스가 즉시 자원을 사용할 수 있거나, 또는 이미 다른 프로세스에 의해 사용 중이라는 사실을 알게 되면 재시도하기 전에 일정 시간을 기다려야만 합니다. 세마포어는 이진수 (0 또는 1)를 사용하거나, 또는 추가적인 값을 가질 수도 있습니다. 세마포어를 사용하는 프로세스는 그 값을 확인하고, 자원을 사용하는 동안에는 그 값을 변경함으로써 다른 세마포어 사용자들이 기다리도록 해야합니다.

### 뮤텍스란?

Mutual Exclusion 으로 상호배제라고도 한다. Critical Section을 가진 쓰레드들의 Runnig Time이 서로 겹치지 않게 각각 단독으로 실행되게 하는 기술입니다. 다중 프로세스들의 공유 리소스에 대한 접근을 조율하기 위해 locking과 unlocking을 사용합니다. 

즉, 쉽게 말하면 뮤텍스 객체를 두 쓰레드가 동시에 사용할 수 없다는 의미입니다.



### Semaphore vs Mutex

1. Semaphore는 Mutex가 될 수 있지만 Mutex는 Semaphore가 될 수 없다.	

   (Mutex는 상태가 0, 1 두 개 뿐인 binary Semaphore)

2. Semaphore는 소유할 수 없는 반면, Mutex는 소유가 가능하며 소유주가 이에 대한 책임을 진다.

   (Mutex의 경우 상태가 두 개 뿐인 lock이므로 lock을 가질 수 있다.)

3. Mutex의 경우 Mutex를 소유하고 있는 쓰레드가 이 Mutex를 해제할 수 있다. 하지만 Semaphore의 경우 이러한 Semaphore를 소유하지 않는 쓰레드가 Semaphore를 해제할 수 있다.

4. Semaphore는 시스템 범위에 걸쳐져 있고 파일시스템상의 파일 형태로 존재한다. 반면 Mutex는 프로세스 범위를 가지며 프로세스가 종료될 때 자동으로 `clean up`된다.



**가장 큰 차이점은 관리하는 동기화 대상의 갯수이다. Mutex는 동기화 대상이 오직 하나 뿐일 때, Semaphore는 동기화 대상이 하나 이상일 때 사용한다.**

# **Loopback**

---

> **루프백(Loopback, loop-back)이란 전기신호의 라우팅, 디지털 ㅔ디어 스트림, 또는 품목의 흐름이 의도적인 가공이나 수정 없이 원래의 장치나 장비로 돌아가는 것**
>
> 주로 전송이나 수송 기반 시설을 테스트하는 수단으로 사용
>
> - 하나의 종단점(endpoint)만 가지는 커뮤니케잉션 채널, 이러한 채널에서 전송된 메시지는 어떤 것이라도 같은 채널로부터만 즉시 수신됨.
> - Serving switching center로부터 온 액세스 라인의 전송 테스트 수행시 served terminal에서 인력을 필요로 하지 않음
> - 두 라인이 사용되는 스테이션(반드시 인접할 필요는 없음)의 연결 테스트. 한 스테이션에서 그리고 멀리 떨어진 스테이션에서 상호 연결된 두 라인에서 이루어지는 테스트를 동반함. 일반적으로 상호연결된 회로가 다이얼링에 의해서 액세스 될 때 루프 어라운드(loop around)라고 불림
> - 루프-백(loop-back) 테스트를 용이하게 하는 패치 케이블

## 가상 루프백 인터페이스(TCP/IP)

[인터넷 프로토콜 스위트](https://ko.wikipedia.org/wiki/인터넷_프로토콜_스위트)(Internet Protocol Suite)의 구현은 가상 네트워크 인터페이스를 포함한다. 같은 기기에서 작동하는 네트워크 응용 프로그램 클라이언트와 서버는 이 인터페이스를 통해 통신할 수 있다. 이 인터페이스는 운영 체제의 네트워킹 소프트웨어 내에서 완전히 구현되며 네트워크 인터페이스 컨트롤러에 패킷을 보내지 않는다. 컴퓨터 프로그램이 루프백 IP 주소로 보낼 수 있는 어떠한 트래픽도 다른 장치로부터 수신한 것처럼 간단하고 빠르게 네트워크 소프트웨어 스택으로 다시 보내진다.

유닉스 계열 시스템에서는 보통 이것을 루프백 인터페이스 lo 또는 lo0라고 명명한다.

다양한 IETF 기준은 IPv4 주소 블록 127/8 (127.0.0.1가 가장 일반적으로 사용됨), the IPv6 주소 ::1, 그리고 이 목적을 위한 localhost 이름을 보유한다..

## 네트워크 장비

일부 네트워크 장비들은 관리 목적으로 사용되는 가상 인터페이스에 대해 루프백이라는 용어를 사용한다. 정상적인 의미의 루프백 인터페이스와 달리, 이 루프백 장치는 장치 스스로의 전송 및 수신을 하기 위해 사용되지는 않는다.

그러한 인터페이스는 네트워크 상의 관리 장비로부터 액세스 될 수 있는 주소에 할당되지만, 장치의 실제 인터페이스에는 할당되지 않는다. 이 루프백 주소는 알람과 같이 장비에서 유래한 관리 데이터그램에도 사용된다. 이 가상 인터페이스의 특별한 점은 이 인터페이스를 이용하는 응용 프로그램들이 트래픽이 통과하는 물리적 인터페이스 주소가 아닌 가상 인터페이스에 할당된 주소를 이용해서 트래픽을 전송하거나 수신한다는 것이다.

## 시리얼 인터페이스

시리얼 커뮤니케이션 송수신기(transceiver)는 기능을 테스트하기 위해 루프백을 이용할 수 있다. 예를 들어 장치의 수신 핀(receive pin)으로 연결되는 전송 핀(transmit pin)은 핀이 전송하는 것을 장치가 정확히 수신하도록 할 것이다. 이 루프 연결을 케이블의 remote end로 이동시킨 후 해당 케이블을 이 테스트에 추가한다. 그 연결을 모뎀 링크의 더 먼 지점으로 옮기면 테스트의 범위가 더욱 확장된다. 이것은 흔히 사용되는 문제 해결 기술이며, 특정한 패턴을 전송하고 반송되는 에러를 감지하는 특정 테스트 기기와 결합 되기도 한다 (비트 오류율 테스트-Bit Error Rate Test- 참조). 몇몇 기기들은 루프백이 가능한 장치를 내장하고 있다.

페이퍼클립 테스트(paperclip test)라고 불리는 간단한 시리얼 인터페이스 루프백 테스트는 때로 컴퓨터의 시리얼 포트를 알아내고 실행을 검증하기 위해 사용된다. 이 테스트는 터미널 에뮬레이터(terminal emulator) 응용 프로그램을 활용하여, 문자를 플로우 컨트롤 세트(flow control set)와 함께 시리얼 포트에 전송하고 같은 내용을 다시 수신한다. 이러한 목적을 위해 페이퍼클립은 D-서브 미니어처 DE-9 또는 DB-25 커넥터를 사용하는 표준 RS-232 인터페이스에서 핀 3(수신 핀과 전송 핀)에 대한 짧은 핀 2(short pin 2)로 사용된다.

## 통신

[통신](https://ko.wikipedia.org/wiki/통신)에서 루프백(짧게 루프라고 씀)이란 수신된 신호나 데이터를 전송자에게 피드(feed)하는 하드웨어나 소프트웨어 방법이다. 루프백은 물리적 연결 문제의 디버깅을 돕기 위해서 사용된다. 테스트로서 많은 데이터 커뮤니케이션 장치들이 인터페이스에서 특정 패턴(all ones와 같은)을 전송하기 위해 설정 될 수 있으며 같은 포트에서 이 신호들의 수신을 감지할 수 있다. 이것은 루프백 테스트라고 불리며 모뎀이나 송수신기내에서 아웃풋을 인풋과 연결시킴으로써 수행될 수 있다. 테스트 신호를 한 장소의 회로에 적용하고 다른 장소에 있는 네트워크 장치가 회로를 통해 신호를 되보내게 하여, 서로 다른 두 지점 사이의 회로를 테스트 할 수 있다. 만약 이 장치가 신호를 그대로 되돌려 받는다면 그 회로가 잘 작동하고 있다는 뜻이 된다.

하드웨어 루프는 수신 채널을 전송 채널에 물리적으로 연결하는 간단한 장치이다. X.21과 같은 네트워크 터미네이션 커넥터(network termination connector)의 경우, 간단히 커넥터의 핀들을 연결하는 것이 전형적이다. 분리된 전송과 수신 커넥터를 가지는 광섬유나 동축 케이블(coaxial cable) 같은 매개체들은 적절한 매개체들의 단선(single strand)으로 간단하게 루프될 수 있다.

모뎀은 원격 모뎀이나 로컬 터미널(local terminal)로부터 들어오는 신호를 루프하도록 설정될 수 있다. 이것은 루프백 또는 소프트웨어 루프라고 일컬어진다.

## 다른 응용 프로그램

명명된 파이프(named pipe) 또한 파일 시스템 단계에서 루프백으로 간주할 수 있다. 유닉스 도메인 소켓(Unix domain socket)과 네트워크 소켓이 프로세스간 커뮤니케이션을 위해 두 연결된 파일을 사용하는 동안, 명명된 파이프는 오로지 하나의 파일로 구성된다.

오디오 시스템인 OSS, **ALSA**, 그리고 PulseAudio 또한 응용 프로그램과 테스팅 목적의 음성 아웃풋을 녹음하기 위한 루프백 모듈을 가지고 있다. 물리적 루프백과 달리 이중 아날로그/디지털 변환이나 하드웨어 오작동으로 인한 중단이 없다.