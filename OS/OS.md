# O/S

> 이 글은 [운영체제 공룡책](https://www.inflearn.com/course/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EA%B3%B5%EB%A3%A1%EC%B1%85-%EC%A0%84%EA%B3%B5%EA%B0%95%EC%9D%98#) 강의와 [한재엽님 깃허브](https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS)를 보고 제게 필요한 지식을 정리한 내용입니다.

---

# [ 프로세스와 스레드의 차이 ]

> OS -> 프로세스 -> Thread
>
> OS에서 여러 개의 프로세스를 관리하고, 프로세스 안에서 여러 개의 Thread를 관리하는 것이 가능하고, 효율적이다.

## 프로세스

> **A Program in execution**
>
> : 실행중인 프로그램

프로세스는 실행 중인 프로그램으로 디스크로부터 메모리에 적재되어 CPU 의 할당을 받을 수 있는 것을 말한다. 운영체제로부터 주소 공간, 파일, 메모리 등을 할당받으며 이것들을 총칭하여 프로세스라고 한다. 구체적으로 살펴보면 프로세스는 함수의 매개변수, 복귀 주소와 로컬 변수와 같은 임시 자료를 갖는 프로세스 스택과 전역 변수들을 수록하는 데이터 섹션을 포함한다. 또한 프로세스는 프로세스 실행 중에 동적으로 할당되는 메모리인 힙을 포함한다.

### 프로세스의 주소공간

- `실행 스택(Stack)`
  - **호출된 프로시저(함수)의 복귀 주수와 지역 변수와 같이 일시적인 데이터를 저장하는 영역**
  - 프로시저를 호출할수록 (`push`) 영역이 커지고 프로시저를 반환할 때 (`pop`) 줄어든다.
- `실행 힙(Heap)`
  - **코드 영역과는 별도로 유지되는 자유 영역**
  - 프로세스 실행 중에 동적으로 할당되는 메모리 영역으로 시스템 호출을 통해 사용되다가 해지뇌는 등 자유자재로 사용된다.
- `데이터(Data)`
  - 프로세스 실행 중에 동적으로 할당받는 영역으로 **전역 또는 정적 변수를 저장**한다.
  - 읽고 쓰기가 가능하다.
- `코드(Code)`
  - **프로세서(CPU)**가 실행하는 코드를 저장하는 영역
  - 프로그램이 코드 영역을 침범하여 기록하려고 하면 오류가 발생하고 프로그램은 종료된다.

### 프로세스 제어 블록

> **`PCB` (Process Control Block)**

PCB 는 특정 **프로세스에 대한 중요한 정보를 저장** 하고 있는 운영체제의 자료구조이다. 운영체제는 프로세스를 관리하기 위해 **프로세스의 생성과 동시에 고유한 PCB 를 생성** 한다. 프로세스는 CPU 를 할당받아 작업을 처리하다가도 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU 를 반환해야 하는데, 이때 작업의 진행 상황을 모두 PCB 에 저장하게 된다. 그리고 다시 CPU 를 할당받게 되면 PCB 에 저장되어있던 내용을 불러와 이전에 종료됐던 시점부터 다시 작업을 수행한다.

*PCB 에 저장되는 정보*

- `프로세스 식별자(Process ID, PID)` : 프로세스 식별번호
- `프로세스 상태` : new, ready, running, waiting, terminated 등의 상태를 저장
- `프로그램 카운터` : 프로세스가 다음에 실행할 명령어의 주소
- `CPU 레지스터`
- `CPU 스케쥴링 정보` : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
- `메모리 관리 정보` : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함
- `입출력 상태 정보` : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
- `어카운팅 정보` : 사용된 CPU 시간, 시간제한, 계정번호 등



## 스레드

> **Thread란 CPU를 구성하는 기본 실행 단위이다.**
>
> **Thread ID(`tid`), Program Count(`pc`), Register Stack 및 Stack으로 구성되어 있다.**

### 스레드의 구조

- 스레드 실행시 상태
- **실행 스택(stack)**
- 지역 변수와 스레드의 특정 데이터를 저장하기 위한 스레드별 정적 저장소
- 프로세스의 다른 스레드가 공유하는 메모리와 자원에 대한 접근 같은 **스레드 실행 환경 정보(Context Information)**
- **PC(Program Counter), SR(Sequence Register), SP(Stack Pointer)**

### 스레드의 이점

- 사용자에 대한 응답성 증가
  - 다중 스레드 환경에서는 하나의 스레드가 blocked 상태인 동안(예를 들어 입출력을 하는 동안) 다른 스레드가 실행되어 다른 작업을 빨리 처리하면서 사용자와 상호작용이 가능하다.
- 프로세스의 자원과 메모리 공유 가능
  - 스레드는 한 프로세스의 자원을 공유하기 때문에 하나의 같은 주소 공간에서 여러 개의 스레드를 실행해 시스템 성능을 향상시킨다. **`병렬성`**, **`성능향상`**
- 경제성
  - 스레드는 한 프로세스의 자원을 공유하기 때문에, 메모리와 자원을 할당해 프로세스를 생성하는 것보다 스레드끼리 문맥 교환하는 것이 오버헤드가 적다.
- 다중 프로세서(CPU) 구조 활용 가능
  - 다중 프로세서 구조에서 각 스레드는 다른 프로세성에서 병렬로 실행될 수 있다.



한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 주소 공간이나 자원을 공유할 수 있다. 

같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 그리고 열린 파일이나 신호와 같은 운영체제 자원들을 공유한다. 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상시키는 것을 멀티스레딩이라고 한다. 이 경우 각각의 스레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC 레지스터 값을 갖고 있다.



#### Stack을 스레드마다 독립적으로 할당하는 이유

- stack은 프로시저의 복귀 주소나, 지역 변수 같이 일시적이고 독립적인 실행환경을 제공한다.
- **스레드는 하나의 독립적인 실행 단위이기 때문에 각각 해당 실행에 대한 독립적 stack을 가진다**

스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고 이는 독립적인 실행 흐름이 추가되는 것이다. 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.

#### PC Register 를 스레드마다 독립적으로 할당하는 이유

- 스레드는 프로세스와 같이 CPU를 할당받고, 선점당할 수 있다.
- 따라서 문맥교환이 발생하게 되므로 **실행하고 있는 코드의 지점을 저장하는 PC Register는 스레드마다 독립적으로 할당**되어야 한다.

PC 값은 스레드가 명령어의 어디까지 수행하였는지를 나타나게 된다. 스레드는 CPU 를 할당받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다. 따라서 PC 레지스터를 독립적으로 할당한다.

---

# [ 프로세스간 통신 ]

## IPC

> Inter Process Communication

각 프로세스들이 통신하는 모든 형태를 일컫는다. 이에는 다양한 형태의 메세지 전달 방식이 포함된다.

### 종류

- `Shared Memory`
  - 프로세스간 공유되는 메모리 영역을 만들어 사용하는 방법
  - 프로세스들은 읽기/쓰기를 통해 공유영역을 수정할 수 있다.
  - 주로 부모/자식 프로세스 간에 사용한다.
- `Message Passing`
  - 다른 프로세스에 **message** 를 보내 정보를 교환하는 방법
  - 주로 작은 데이터를 교환하며 구현이 쉽다.
  - **system call**이 잦아 자칫 느려질 수 있다.
- `Sockets`
  - Network Communication의 Endpoint 간의 통신이다.
  - **IP Address, Port**를 이용해 직접 통신한다.
- `Pipe`
  - Message나 Shared Memory는 서로 다른 process간 memory에서 구조체 또는 데이터를 주고받았지만
  - Pipi는 양방향 간의 버퍼를 통해서 데이터를 읽거나 쓰는 구조이다.
  - 연속적인 **byte stream** 을 교환할 때 많이 사용된다.



## RPC

> Remote Procedure Call

IPC방식 중 한 가지이다.

메서드 호출 내부 간의 내부 통신을 숨겨주며, 별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행할 수 있게 하는 프로세스간 통신 기술이다.

클라이언트는 다른 머신에 존재할 수 있는 원격 서버와 IPC를 처리하는 로컬 메소드를 호출한다.

다시 말해, 원격 프로시저 호출을 이용하면 프로그래머는 함수가 실행 프로그램에 로컬 위치에 있든 원격 위치에 있든 동일한 코드를 이용할 수 있다.

객체 지향의 원칙을 사용하는 소프트웨어의 경우 원격 프로시저 호출을 **원격호출(remote invocation)** 또는 **원격 메소드 호출(remote method invocation)**이라고 일컫는다.

*안드로이드 서비스 호출 패턴은 RPC를 구현하고 있다.*

### 종류

- `RMI (Remote Method Invocation)`
  - RPC를 객체지향으로 구현
  - 서버와 클라이언트 모두 **helper**가 필요하다. (**서버 측은 Skeleton, 클라이언트 측은 Stub**)
- `Stub`
  - 원격지에 위치해 있는 프로그램을 대리하는 작은 루틴이다.
  - RPC를 사용하는 프로그램이 컴파일되면 요청된 절차를 제공하는 프로그램의 대역을 한다.
  - 클라이언트에서 요청하는 데이터를 Marshaling하고 작업이 완료된 데이터를 다시 UnMarshaling하는 역할
- `Skeleton`
  - Stub과 비슷한 역할로 서버의 보조 객체이다.
  - 클라이언트의 Stub에서 데이터가 Marshaling되어 전송되면 Seleton에서 UnMarshaling하여 원래의 형태로 복원한다.
- `Marshaling /  Unmarshaling`
  - Marshaling은 데이터를 바이트로 쪼개서 `TCP/IP`같은 통신 채널을 통해 전송될 수 있는 형태롤 바꿔주는 과정
  - UnMarshaling은 반대로 전송 받은 바이트를 원래의 형태로 복원하는 과정

---

# [ 멀티 스레드 ]

멀티 쓰레드 모델을 살펴보기 전에 먼저 **User Thread**와 **Kernel Thread**에 관해 살펴보자.

말 그대로 **User Thread**는 User level의 Thread 라이브러리를 통해 관리되는 Thread를 말하며 **Kernel Thread**는 운영체제가 제공하고 직접 관리하는 Thread를 말한다

Multi-Thread에는 총 네 가지 모델이 있다.

1. `Many-to-One Model`

   ![image-20210503175702103](https://user-images.githubusercontent.com/58545240/116858546-80dccf00-ac39-11eb-85aa-9faac71e3855.png)

   - Kernel Thread가 다수의 User Thread를 처리하는 구조이다.
   - 이러한 구조는 User Thread를 처리하던 중 System call에 의해 blocking이 된다면 **전체 프로세스가 막히는 병목현상이 일어나게 되는 문제점**을 갖고 있다.

2. `One-to-One Model`

   ![image-20210503175749799](https://user-images.githubusercontent.com/58545240/116858575-8c2ffa80-ac39-11eb-885a-f2866aa8edba.png)

   - One-to-One model로 처리해야 할 User Thread 한 개당 Kernel Thread를 대응시켜 작업을 진행하는 구조입니다.
   - 이러한 일대일 대응 구조는 **Kernel Thread 생성에 과도한 생성의 문제**를 가져오게 된다

3. `Many-to-Many Model`

   ![image-20210503175827655](https://user-images.githubusercontent.com/58545240/116858590-9225db80-ac39-11eb-9f4b-b3399fd6b4db.png)

   - 그리하여 어느 정도 보완된 모델이 바로 Many-to-Many model이고 그림과 같이 **다수의 User Thread를 다수의 Kernel Thread가 처리**하는 구조인데 
   - Kernel Thread의 숫자는 User Thread의 숫자보다 같거나 작게 할당이 되어야 합니다.

4. `Two-Level Model`

   ![image-20210503175855489](https://user-images.githubusercontent.com/58545240/116858605-9a7e1680-ac39-11eb-8875-cf138a1b1be3.png)

   - 그리고 최종적으로 보완된 모델이 Many-to-Many model을 더욱 보완하여 만든 Two-level model이다.
   -  Many-to-Many model과 One-to-One model을 합친 구조로 **중요한 작업은 One-to-One 구조**를 통해 처리하고 
   - **나머지는 Many-to-Many 구조를 통해 처리**함으로써 혹시나 있을 중요한 작업에서의 기다림 현상을 줄일 수 있다.

   

## 멀티 스레딩의 장점

프로세스를 이용하여 동시에 처리하던 일을 스레드로 구현할 경우 메모리 공간과 시스템 자원 소모가 줄어들게 된다. 스레드 간의 통신이 필요한 경우에도 별도의 자원을 이용하는 것이 아니라 전역 변수의 공간 또는 동적으로 할당된 공간인 Heap 영역을 이용하여 데이터를 주고받을 수 있다. 그렇기 때문에 프로세스 간 통신 방법에 비해 스레드 간의 통신 방법이 훨씬 간단하다. 심지어 스레드의 context switch 는 프로세스 context switch 와는 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다. 따라서 시스템의 throughtput 이 향상되고 자원 소모가 줄어들며 자연스럽게 프로그램의 응답 시간이 단축된다. 이러한 장점 때문에 여러 프로세스로 할 수 있는 작업들을 하나의 프로세스에서 스레드로 나눠 수행하는 것이다.



## 멀티 스레딩의 문제점

멀티 프로세스 기반으로 프로그래밍할 때는 프로세스 간 공유하는 자원이 없기 때문에 동일한 자원에 동시에 접근하는 일이 없었지만 멀티 스레딩을 기반으로 프로그래밍할 때는 이 부분을 신경써줘야 한다. 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다.

그렇기 때문에 멀티스레딩 환경에서는 동기화 작업이 필요하다. 동기화를 통해 작업 처리 순서를 컨트롤 하고 공유 자원에 대한 접근을 컨트롤 하는 것이다. 하지만 이로 인해 병목현상이 발생하여 성능이 저하될 가능성이 높다. 그러므로 과도한 락으로 인한 병목현상을 줄여야 한다.



## 멀티 스레드 vs 멀티 프로세스

멀티 스레드는 멀티 프로세스보다 적은 메모리 공간을 차지하고 문맥 전환이 빠르다는 장점이 있지만, 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 점과 동기화 문제를 안고 있다. 반면 멀티 프로세스 방식은 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다는 장점이 있지만, 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지한다는 단점이 존재한다. 이 두 가지는 동시에 여러 작업을 수행한다는 점에서 같지만 적용해야 하는 시스템에 따라 적합/부적합이 구분된다. 따라서 대상 시스템의 특징에 따라 적합한 동작 방식을 선택하고 적용해야 한다.

---

# [ 스케쥴러 ]

*프로세스를 스케줄링하기 위한 Queue 에는 세 가지 종류가 존재한다.*

- Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
- Ready Queue : 현재 메모리 내에 있으면서 CPU 를 잡아서 실행되기를 기다리는 프로세스의 집합
- Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합

각각의 Queue 에 프로세스들을 넣고 빼주는 스케줄러에도 크게 **세 가지 종류가** 존재한다.



## 장기스케줄러

> **Long-term Scheduler or Job Scheduler**

메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool 에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue 로 보낼지 결정하는 역할을 한다.

간단히 말해서 장기스케쥴러는 시스템의 다중 프로그래밍 정도를 결정한다.

- 메모리와 디스크 사이의 스케줄링을 담당.
- 프로세스에 memory(및 각종 리소스)를 할당(admit)
- degree of Multiprogramming 제어
  (실행중인 프로세스의 수 제어)
- 프로세스의 상태
  new -> ready(in memory)

*cf) 메모리에 프로그램이 너무 많이 올라가도, 너무 적게 올라가도 성능이 좋지 않은 것이다. 참고로 time sharing system 에서는 장기 스케줄러가 없다. 그냥 곧바로 메모리에 올라가 ready 상태가 된다.*



## 단기스케줄러

> **Short-term Scheduler or CPU Scheduler**

초기에 주 메모리에 많은 프로세스가 있을 때, 모든 프로세스가 준비 대기열에 있기 된다.

이 때 모든 프로세스 중에서 단일 프로세스를 선택하여 실행하고 이러한 결정을 수행한다.

- CPU 와 메모리 사이의 스케줄링을 담당.
- Ready Queue 에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정.
- 프로세스에 CPU 를 할당(scheduler dispatch)
- 프로세스의 상태
  ready -> running -> waiting -> ready

### 디스패쳐 

> **Dispatcher**

디스패처는 스케쥴러 이후에 작동하는 특수한 프로그램이다. 스케쥴러가 프로세스를 선택하면 해당 프로세스를 원하는 상태 / 대기열로 가져가는 것이 **Dispatcher**이다. 단기스케쥴러에서 CPU를 선택한 후 CPU에 대한 프로세스 제어를 제공하는 모듈이다.

- Switching Context
- Switching to User mode
- Jumping to the proper location in the user program to restart that program

### 스케쥴러와 디스패쳐의 차이점

다양한 프로세스가 실행 대기중인 Ready Queue에서 상주하고 있는 상황을 고려해보자. CPU는 이러한 모든 프로세스를 동시에 실행할 수 없으므로 운영체제는 스케쥴링 알고리즘을 기반으로 특정 프로세스를 선택해야 한다. 따라서 **다양한 프로세스 중에서 프로세스를 선택하는 이 절차는 `Scheduler`에 의해 수행된다.** 스케쥴러가 **대기열에서 프로세스를 선택하면 `Dispatcher`가 나타나고 `Ready Queue`에서 해당 프로세스를 가져와 실행 중 상태로 이동하는 것은 `Dispatcher`이다.**

따라서 스케쥴러는 디스패처가 시간이 지남에 따라 CPU로 이동하는 순서가 지정된 프로세스 목록을 디스패처에게 제공하게 된다.



## 중기스케줄러

> **Medium-term scheduler or Swapper**

대부분의 경우 실행중인 프로세스에는 CPU가 필요없는 I/O 작업이 필요하다. 따라서, I/O 작업이 필요한 프로세스를 실행하는 동안 운영체제는 해당 프로세스를 `Ready Queue`에서 `Blocked Queue`로 보낸다.

프로세스가 I/O 작업을 완료하면 다시 준비 대기열로 이동해야 하고 이러한 결정을 수행한다. (스와핑!)

- 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄 (swapping)
- 프로세스에게서 memory 를 deallocate
- degree of Multiprogramming 제어
- 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러.
- 프로세스의 상태
  ready -> suspended

### Process state - suspended

Suspended(stopped) : 외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미한다. 프로세스 전부 디스크로 swap out 된다. blocked 상태는 다른 I/O 작업을 기다리는 상태이기 때문에 스스로 ready state 로 돌아갈 수 있지만 이 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다.

---

# [ CPU 스케쥴러 ]

> 여러 프로세스를 concurrent하게 쓰는게 멀티프로그래밍과 멀티쓰레딩이었고, 그 전제조건으로 바로 CPU Scheduling이 필요하다.

*스케줄링 대상은 **Ready Queue** 에 있는 프로세스들이다.*

(이 Ready Queue는 `LinkedList or Binary Tree or FIFO Queue or PriorityQueue`를 사용하여 만들어진다.)

들어가기 전에 먼저 용어 정리 부터 하겠다.

> **`선점(preemptive)`** : 우선순위가 높은 작업이 오거나, 해당 작업이 더 우선되어야 한다고 판단되면 해당 작업에게서 CPU를 빼앗을 수 있다.
> **`비선점(non-preemptive)`** : 일단 CPU를 할당받으면 해당 프로세스가 끝날때까지 CPU를 빼앗기지 않는다.

## 스케쥴링 알고리즘에 대한 성능 척도

- `프로세서 이용율 (CPU Utilization)`
  
  - **시간당 CPU를 사용한 시간의 비율** 
  - 프로세서를 실행상태로 항상 유지하여 유휴상태가 되지 않도록 한다. 가능하면 입출력(I/O) 중심의 작업보다 프로세서 중심의 작업을 실행해야 한다.
- `처리율 (Throughput)`
  - **시간당 처리한 작업의 비율**
  - 단위 시간당 완료되는 작업수가 많도록 짧은 작업을 우선 처리하거나 인터럽트 없이 작업을 실행한다.
- `반환시간 또는 소요시간 (Turnaround Time)`
  - **CPU burst time**(쓰고 나갈때까지의 시간, 누적되지 않음)
  - 작업이 시스템에 맡겨져서 메인 메모리에 들어가기까지의 시간, 준비 큐에 있는 시간, 실행시간, 입출력시간 등 작업 제출 후 완료되는 순간까지의 소요시간이 최소화되도록 일괄 처리 작업을 우선 처리한다.
- `대기시간 (Waiting Time)`
  - **대기열에 들어와 CPU를 할당받기까지 기다린 시간**
  - 작업의 실행시간이나 입출력시간에는 실제적인 영향을 미치지 못하므로 준비 큐애서 기다리는 시간이 최소화되도록 사용자 수를 제한한다.
- `반응시간 또는 응답시간 (Response Time)`
  - **대기열에서 처음으로 CPU를 얻을때까지 걸린시간**
  - 반응시간은 의뢰한 시간에서부터 반응이 시작되는 시간까지의 간격으로 대화형 시스템에서 중요한 사항이다. 따라서 대화식 작업을 우선 처리하고 일괄 처리 작업은 대화식 작업의 요구가 없을때까지 처리한다.
  
  

## FCFS

> **First Come First Served**

### 특징

- 먼저 온 고객을 먼저 서비스해주는 방식, 즉 먼저 온 순서대로 처리.
- `비선점형(Non-Preemptive) 스케줄링`
  일단 CPU 를 잡으면 CPU burst 가 완료될 때까지 CPU 를 반환하지 않는다. 할당되었던 CPU 가 반환될 때만 스케줄링이 이루어진다.

### 문제점

- `convoy effect(똥차 효과)`
  소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 발생한다.



## SJF

> **Shortest - Job - First**

### 특징

- 다른 프로세스가 먼저 도착했어도 **CPU burst time** 이 짧은 프로세스에게 우선 할당한다
- 일종의 우선순위 기법이라고 볼 수 있고, `비선점형(SJF)과 선점형(SRTF) 방식 모두 있다.`
- 최소 평균 대기 시간을 보장한다.
- 이론적으로 다른 알고리즘과 비교하기 위한 최적의 알고리즘일뿐, 직접 구현해서 쓰진 않는다.

### 문제점

- `starvation`
  효율성을 추구하는게 가장 중요하지만 특정 프로세스가 지나치게 차별받으면 안되는 것이다. 이 스케줄링은 극단적으로 CPU 사용이 짧은 job 을 선호한다. 그래서 사용 시간이 긴 프로세스는 거의 영원히 CPU 를 할당받을 수 없다.



## SRTF

> **Shortest Remaining Time First**

### 특징

- SJF의 선점형 스케쥴링 방식
- 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어진다.
- `선점형 (Preemptive) 스케줄링`
  현재 수행중인 프로세스의 남은 burst time 보다 더 짧은 CPU burst time 을 가지는 새로운 프로세스가 도착하면 CPU 를 뺏긴다.

### 문제점

- `starvation`
- 새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU burst time(CPU 사용시간)을 정확히 예측하기 어렵다.



## Priority Scheduling

### 특징

- 우선순위가 가장 높은 프로세스에게 CPU 를 할당하는 스케줄링이다. 우선순위란 정수로 표현하게 되고 작은 숫자가 우선순위가 높다.
- `선점형 스케줄링(Preemptive) 방식`
  더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU 를 선점한다.
- `비선점형 스케줄링(Non-Preemptive) 방식`
  더 높은 우선순위의 프로세스가 도착하면 Ready Queue 의 Head 에 넣는다.

### 문제점

- `starvation`
- `무기한 봉쇄(Indefinite blocking)`
  실행 준비는 되어있으나 CPU 를 사용못하는 프로세스를 CPU 가 무기한 대기하는 상태

### 해결책

- `aging`
  아무리 우선순위가 낮은 프로세스라도 오래 기다리면 우선순위를 높여주자.



## Round Robin

### 특징

- 현대적인 CPU 스케줄링으로 시분할 시스템을 위해 설계되었다.
- `선점형 스케줄링(Preemptive) 방식`
- 각 프로세스는 **동일한 크기의 할당 시간(time quantum)**을 갖게 된다. -> *이 time slice를 어떻게 하느냐에 따라 성능 차이가 난다.*
- 할당 시간이 지나면 프로세스는 선점당하고 `ready queue` 의 제일 뒤에 가서 다시 줄을 선다.
- **어떠한 프로세스도 `q time unit` 이상 기다리지 않는다. -> 공정한 알고리즘!**
- `RR`은 CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
- `RR`이 가능한 이유는 프로세스의 **context** 를 save 할 수 있기 때문이다.

### 장점

- `Response time`이 빨라진다.
  n 개의 프로세스가 ready queue 에 있고 할당시간이 q(time quantum)인 경우 각 프로세스는 q 단위로 CPU 시간의 1/n 을 얻는다. 즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.
- 프로세스가 기다리는 시간이 CPU 를 사용할 만큼 증가한다.

### 주의할 점

설정한 `time quantum`이 너무 커지면 `FCFS`와 같아진다. 또 너무 작아지면 스케줄링 알고리즘의 목적에는 이상적이지만 **잦은 context switch** 로 overhead(`dispatcher latency`) 가 발생한다. 그렇기 때문에 적당한 `time quantum`을 설정하는 것이 중요하다.



## MLQ 

> **Multi Level Queue**

### 특징

- `선점형 스케쥴링`
- 작업들을 여러 종류의 그룹으로 분할 (ex. 데이터, 사운드, 화면, 전화, 카톡, ...)
- 여러 개의 레디큐를 이용해 상위 단계 작업에 의해 하위 단계 작업이 선점된다.
- `Ready Queue`를 여러 종류로 분할한다.(작업 분류별 묶음) **-> 각각의 priority를 따로 배정한다.**
- 다른 큐로 작업 이동이 불가
- 각각의 `Ready Queue`는 자신만의 독자적인 스케쥴링을 가진다.
- 상위 우선순위의 큐가 Empty이면 하위 우선순의 큐의 프로세스가 수행된다.



## MLFQ 

> **Multi Level FeedBack Queue**

### 특징

- `선점형 스케쥴링`
- 입출력 위주와 CPU위주인 프로세스의 특성에 따라 큐 마다 서로 다른 **`CPU Time Slice(Time Quantum)`**을 부여한다.
- 새로운 프로세스는 높은 우선순위, 프로세스의 실행시간이 길어질수록 점점 낮은 우선순위 큐로 이동한다.
- **제일 마지막 단계에서는 `RR/FCFS`로 처리한다.**
- **우선순위가 높은 프로세스에게는 불이익을, 우선순위가 낮은 프로세스에게는 이익을 제공한다.**
- 기본적으로 가장 우선순위가 낮은 큐를 제외 하고는 모두 `RR` 스케쥴링을 사용한다.
- 하위 단계일 수록 할당 시간은 증가(공평성 부여)
- `기아(stravation)` 상태를 예방하기 위해 `Aging처리`를 이용한다.
- ***현대 OS에서 RR방식과 함께 가장 많이 사용되는 스케쥴링 기법이다.***



## 마무리

실제로는 쓰레드 스케쥴링을 하는데 쓰레드 스케쥴링은 어려워 프로세스에서 배운 것(CPU Scheduling)이다.

유저쓰레드는 일반적으로 `Thread` 라이브러리로 관리하게 되고 OS는 `many to many model`로 유저 쓰레드에게 이를 서비스한다.

++

> soft RTOS : 아주 조금의 오차정도는 허용된다.
>
> hard RTOS : 어떤 오차도 허용되면 안되고, 반드시 허용된 시간안에 task가 수행되어야 한다. (우선순위가 역전되면 안되!)

---

# [ 동기와 비동기 ]

## 동기

> **Synchronous**

동기는 말 그대로 동시에 일어난다는 뜻이다. 요청과 그 결과가 동시에 일어난다는 약속이다.

바로 요청을하면 시간이 얼마가 걸리던지 요청한 자리에서 결과가 주어져야 한다.

- 요청과 결과가 한 자리에서 동시에 일어남
- A노드와 B노드 사이의 작업 처리 단위(`transaction`)을 동시에 맞추겠다.
- **설계가 매우 간단하고 직관적**이지만 **결과가 주어질 때까지 아무것도 못하고 대기해야 하는 단점이 있다.**



## 비동기

> **Asynchoronous**

비동기는 동시에 일어나지 않는다를 의미한다. 요청과 그 결과가 동시에 일어나지 않을거라는 약속이다.

- 요청한 그 자리에서 결과가 주어지지 않음
- 노드 사이의 작업 처리 단위를 동시에 맞추지 않아도 된다.
- **동기보다 복잡하지만 결과가 주어지는데 시간이 걸리더라도 그 시간 동안 다른 작업을 할 수 있으므로 자원을 효율적으로 사용할 수 있다는 장점**이 있다.



## 비유를 통한 쉬운 설명

해야할 일(task)가 빨래, 설거지, 청소 세 가지가 있다고 가정한다. 이 일들을 동기적으로 처리한다면 빨래를 하고 설거지를 하고 청소를 한다. 비동기적으로 일을 처리한다면 빨래하는 업체에게 빨래를 시킨다. 설거지 대행 업체에 설거지를 시킨다. 청소 대행 업체에 청소를 시킨다. 셋 중 어떤 것이 먼저 완료될지는 알 수 없다. 일을 모두 마친 업체는 나에게 알려주기로 했으니 나는 다른 작업을 할 수 있다. 이 때는 백그라운드 스레드에서 해당 작업을 처리하는 경우의 비동기를 의미한다.



## Sync vs Async

일반적으로 동기와 비동기의 차이는 메소드를 실행시킴과 `동시에` 반환 값이 기대되는 경우를 **동기** 라고 표현하고 그렇지 않은 경우에 대해서 **비동기** 라고 표현한다. 동시에라는 말은 실행되었을 때 값이 반환되기 전까지는 `blocking`되어 있다는 것을 의미한다. 비동기의 경우, `blocking`되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task 를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않는다.

> 비동기 방식의 예제를 통해서 **블록(Block)과 논블록(NonBlock)**의 차이를 간략하게 설명하자면, 빨래 업체에게 빨래를 시킨 후 가만히 앉아 빨래완료 라는 연락만을 기다린다면 **블록** 상태이다. 하지만 빨래가 완료되었다는 전송을 받기 전까지 다른 설거지나 청소를 하게되면 학생의 상태는 **논블록** 상태 라고한다.

---

# [ 프로세스 동기화 ]

## Critical Section

> 임계영역

멀티 스레딩에 문제점에서 나오듯, 동일한 자원을 동시에 접근하는 작업(e.g. 공유하는 변수 사용, 동일 파일을 사용하는 등)을 실행하는 코드 영역을 Critical Section 이라 칭한다.



## Critical Section Problem

> 임계영역 문제

프로세스들이 Critical Section 을 함께 사용할 수 있는 프로토콜을 설계하는 것이다.



## Requirements

> 해결을 위한 기본 조건

- `Mutual Exclusion(상호 배제)`
  -   프로세스 P1 이 Critical Section 에서 실행중이라면, 다른 프로세스들은 그들이 가진 Critical Section 에서 실행될 수 없다.
- `Progress(진행)` -> **No Deadlock**
  -   Critical Section 에서 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스들만 Critical Section 진입 후보로서 참여될 수 있다.
  -   임계영역에 어떤 스레드의 접근도 없을 때 항상 접근이 가능해야 한다.
- `Bounded Waiting(한정된 대기)` -> **No Starvation**
  -   P1 가 Critical Section 에 진입 신청 후 부터 받아들여질 때가지, 다른 프로세스들이 Critical Section 에 진입하는 횟수는 제한이 있어야 한다.
  -   모든 프로세스가 임계영역에 들어가기 위해 기회를 가질 수 있어야 한다.



## Peterson's algorithm

피터슨 알고리즘은 상호 배제를 위한 `병렬 프로그래밍 알고리즘`으로 공유 메모리를 활용하여 여러 개의 프로세스가 하나의 자원을 사용할 때 문제가 발생하지 않도록 한다. 당시의 알고리즘은 프로세스가 2개인 경우에서만을 제한한다.

지금은 일반화 되어서 3개 이상의 프로세스들 사이에서도 이 방법이 통용된다고 한다.

`Pi` `Pj` 프로세스로 표시하며 이 알고리즘의 가장 큰 특징은 `booelan flag`과 `int turn`이라고 하는 두 개의 변수를 이용한다.

예를 들어 만나면 싸우기만 하는 두 개가 있다. 보다 못한 주인은 우리집 개가 산책할 때는 너희집 개는 집에 있으라고 한다. 우리집 개가 산책을 떠나면 집에서 깃발을 뽑고, 우리집 개가 산책을 마치고 돌아오면 집에 깃발을 다시 꽂음으로서 상대 집 개에게 알려주는 것이다. 

이런식으로 서로 `*producer()`와 `*consumer()`가 주고받는 티키타카 구조를 구현하는 것이다.

하지만 이는 `while (flag[1] && turn ==1 )`의 과정에서 **`context switch`**가 일어나면 피터슨 솔루션의 동작은 올바르게 수행되지 않는다. **그럼에도 이를 배우는 이유는 위에서 언급한 세가지 요구 사항을 개념적으로 완벽하게 증명하기 때문이다.**

사실 sw가 아니라 hw instruction을 가지고 동기화를 수행하는 것이 가장 좋다.

그 중에서 더이상 쪼갤 수 없는 성질인 **`Atomicity`**를 구현하는 것이다. 바로 HW Instruction을 Atoic instruction으로 구현하여 `a++`, `i<->j`와 같은 행위를 세번으로 나누지 말고 단 **원 클락**으로 구현하도록 만드는 것이다. 

우리는 SW엔지니어로서 이를 자바를 피터슨 솔루션을 구현할 것이다.

`java.util.concurrent.atomic.Atomicboolean`을 사용한다.

```java
static Atomicboolean[] falg;

Producer implements Runnable {
    public void run() {
        flag[1].set(true);
        turn = 1;
        for (int k = 0; k < 1000; k++) {
            while (flag[1].get() && turn == 1) {
                ;
            }
        }
        ...
    }
}
```

이와 같이 구현한다면 `flag[1].get()`이 **atomic variable**이기 때문에 while에서 **`context switch`**가 일어나지 않고 상호배제를 구현할 수 있게 된다.

위에서 언급한 동기화의 가장 기본적인 방법 세가지를 모두 만족하는 것은 힘들다.

그러므로 우리는 상호배제만 구현해볼 것인데 이를 위해서 바로 **`Mutex`, `Semaphore`, `Monitor`를 이용할 것이다.**



## ==== 해결책 ====

앞서 총 두 가지의 임계영역 문제의 솔루션을 알아보았다.

1. SW 솔루션 : `Peterson's Algorithm`
2. HW 솔루션 : "`test-and-set`" , "`compare-and-swap`" 을 이용한 **Atomic Variable** HW instruction이다.

이제 조금 더 SW에서 고급 레벨의 솔루션을 알아 볼 것이다.

1. Mutex (`Binary Semaphore`) : 가장 간단한 동기화 툴 (locking : 열쇠)
2. Semaphore(`Counting Semaphore`) : 더욱 편리하고 효과적
3. Monitor : 뮤텍스와 세마포어의 단점을 극복 --> **Java에서 생각하는 locking은 모두 Monitor이다.**

## Lock

- 하드웨어 기반 해결책으로써, 동시에 공유 자원에 접근하는 것을 막기 위해 Critical Section 에 진입하는 프로세스는 Lock 을 획득하고 Critical Section 을 빠져나올 때, Lock 을 방출함으로써 동시에 접근이 되지 않도록 한다.

### 한계

- 다중처리기 환경에서는 시간적인 효율성 측면에서 적용할 수 없다.



## Semaphores

- 신호기!
- 소프트웨어상에서 Critical Section 문제를 해결하기 위한 동기화 도구

OS 는 Counting/Binary 세마포를 구분한다

### - Binary Semaphore

MUTEX 라고도 부르며, 상호배제의 (Mutual Exclusion)의 머릿글자를 따서 만들어졌다. 이름 그대로 0 과 1 사이의 값만 가능하며, 다중 프로세스들 사이의 Critical Section 문제를 해결하기 위해 사용한다.

`acquire()`와 `release()`를 **atomically**하게 구현한다. 이는 운영체제 커널을 만드는 사람이 `compare_and_swap()`과 같은 기능을 이용해 만들것이다.

하지만 뮤텍스도 단점이 있는데 **Busy Waiting**이라는 문제가 생긴다.

**`Busy Waiting`**이란 어떤 임계영역에 들어가기 위해 무한루프에 들어가게 되는 것을 말한다. 멀티 프로그래밍에서는 이것이 단점이 된다. 다른 프로세스가 생산적으로 쓸 수 있는 CPU 자원을 CPU 싸이클을 통해 쓸데 없이 낭비하게 되기 때문이다.

### - Counting Semaphore

`wait()`와 `signal()`을 **atomically**하게 구현한다.

**가용한 개수를 가진 자원** 에 대한 접근 제어용으로 사용되며, 세마포는 그 가용한 **자원의 개수**(`count`) 로 초기화 된다. 자원을 사용하면 세마포가 감소(**wait()** :: `count--`), 반납하면 세마포가 증가(**signal()** :: `count++`) 한다.

count가 0일 때는 모든 리소스가 사용하고 있기 때문에 누군가가 반납하기 전까지 자원을 사용하지 못한다.

```bash
### 세마포어의 busy waiting 문제를 해결하는 방법 ###

굳이 세마포어가 무한루프를 돌지 않고 wait()로 suspend 시켜서 waiting queue에 대기하고 있다가, 다른 프로세스가 signal()을 호
출하면 다시 ready queue에 들어가도록 하면 busy waiting 문제를 해결할 수 있다.
```

`Counting Semaphore`를 쓴다 하더라도 (ex. `int sum = 987`) 변수 하나만으로는 상호배제를 피할 수 없다. 왜냐하면 각각의 세마포어는 각각의 **`instance`**를 취급해야 하기 때문에 `int sum[n]`으로 할당하여 각각의 세마포어에게 서로 다른 `instance`를 할당하여야 한다.



### Spin Lock

스핀락은 말 그대로, 다른 스레드가 lock(열쇠)을 소유하고 있다면 그 lock(열쇠)이 반환될 때 까지 계속 확인하며 기다리는 것이다. **"조금만 기다리면 바로 쓸 수 있는데 굳이 컨텍스트 스위칭으로 부하를 줄 필요가 있나?"** 라는 컨셉으로 개발된 것으로 임계영역에 진입이 불가할 때 `Context Switch`를 하지 않고 잠시 루프를 돌면서 재시도를 하는 것이다.

Lock과 UnLock을 하는 과정이 매우 짧아서 락하는 경우가 드문경우 유용하게 사용할 수 있다. 특징을 알아보자.

- Lock을 얻을 수 없다면 계속해서 Lock을 확인하며 얻을 때까지 기다린다. 이른바 바쁘게 기다리는 **busy waiting**이다.
- 바쁘게 기다린다는 것은 무한 루프를 돌면서 최대한 다른 스레드에게 CPU를 양보치 않는 것이다.
- Lock이 곧 사용가능해 질경우 `Context Switch`를 줄여 CPU의 부담을 덜어준다. 하지만, 어떤 스레드가 Lock을 오랫동안 유지한다면 오히려 CPU 시간을 많이 소모할 가능성이 있다.
- **하나의 CPU나, 하나의 코어만 있는 경우에는 유용하지 않다.** 이유는, 만약 다른 스레드가 Lock을 가지고 있고 그 스레드가 Lock을 풀어 주려면 싱글 CPU 시스템에서는 어차피 `Context Swtich`가 일어나야 하기 때문이다.
- 스핀락을 잘못 사용할 경우 CPU 사용을 100%로 만드는 상황이 발생하므로 주의해야 한다. 스핀락은 기본적으로 무한루프를 돌면서 Lock을 기다리므로 하나의 쓰레드가 Lock을 오래 가지고 있다면 다른 블락킹된 쓰레드는 **busy waiting**하게 되므로 CPU를 쓸데없이 낭비한다.

### 단점

- Busy Waiting(바쁜 대기)
  Spin lock이라고 불리는 Semaphore 초기 버전에서 Critical Section 에 진입해야하는 프로세스는 진입 코드를 계속 반복 실행해야 하며, CPU 시간을 낭비했었다. 이를 Busy Waiting이라고 부르며 특수한 상황이 아니면 비효율적이다. 일반적으로는 Semaphore에서 Critical Section에 진입을 시도했지만 실패한 프로세스에 대해 Block시킨 뒤, Critical Section에 자리가 날 때 다시 깨우는 방식을 사용한다. 이 경우 Busy waiting으로 인한 시간낭비 문제가 해결된다.

### Deadlock(교착상태)

- 세마포가 Ready Queue 를 가지고 있고, 둘 이상의 프로세스가 Critical Section 진입을 무한정 기다리고 있고, Critical Section 에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되야만 빠져나올 수 있는 상황을 지칭한다.



## 모니터

- 고급 언어의 설계 구조물로서, 개발자의 코드를 상호배제 하게끔 만든 추상화된 데이터 형태이다.
- 공유자원에 접근하기 위한 키 획득과 자원 사용 후 해제를 모두 처리한다. (세마포어는 직접 키 해제와 공유자원 접근 처리가 필요하다. )

---