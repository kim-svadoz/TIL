

# O/S

> 이 글은 [운영체제 공룡책](https://www.inflearn.com/course/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EA%B3%B5%EB%A3%A1%EC%B1%85-%EC%A0%84%EA%B3%B5%EA%B0%95%EC%9D%98#) 강의와 [한재엽님 깃허브](https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS)를 보고 제게 필요한 지식을 정리한 내용입니다.

---

# [ 프로세스와 스레드의 차이 ]

> OS -> 프로세스 -> Thread
>
> OS에서 여러 개의 프로세스를 관리하고, 프로세스 안에서 여러 개의 Thread를 관리하는 것이 가능하고, 효율적이다.

## 프로세스

> **A Program in execution**
>
> : 실행중인 프로그램

프로세스는 실행 중인 프로그램으로 디스크로부터 메모리에 적재되어 CPU 의 할당을 받을 수 있는 것을 말한다. 운영체제로부터 주소 공간, 파일, 메모리 등을 할당받으며 이것들을 총칭하여 프로세스라고 한다. 구체적으로 살펴보면 프로세스는 함수의 매개변수, 복귀 주소와 로컬 변수와 같은 임시 자료를 갖는 프로세스 스택과 전역 변수들을 수록하는 데이터 섹션을 포함한다. 또한 프로세스는 프로세스 실행 중에 동적으로 할당되는 메모리인 힙을 포함한다.

### 프로세스의 메모리 구조

> 리눅스 구조로 1GB Kernel 영역, 3GB User 영역

![image-20210513135339703](https://user-images.githubusercontent.com/58545240/118079210-be3c1c00-b3f2-11eb-87b3-38978c3c54ff.png)

- **`text(code) 영역`**

  -  코드 자체를 구성하는 메모리 영역으로 Hex파일이나 BIN파일 메모리
  - 프로그램 명령이 위치하는 곳으로 기계어로 제어되는 메모리 영역

- **`data 영역`**

  - 전역변수(global), 정적변수(static), 배열(array), 구조체(structure) 등이 저장된다.
  - 초기화 된 데이터는 data 영역에 저장되고, 초기화 되지 않은 데이터는 `BSS(Block Stated Symbol)`에 저장된다.
  - 프로그램이 실행될 때 생성되고 프로그램이 종료되면 시스템에 반환
  - 함수 내부에 선언된 Static 변수는 프로그램이 실행될 때 공간만 할당하고, 그 함수를 실행 될 때 초기화

  ```bash
  # data영역와 bss 영역을 구분하는 이유?
  초기화가 되지 않는 변수는 프로그램이 실행될때 영역만 잡아주면 되고 그 값을 프로그램에 저장하고 있을 필요는 없으나 초기화가 되는 변수는 그 값도 프로그램에 저장하고 있어야 하기때문에 두가지를 구분해서 영역을 잡는것이다. 이것이 bss영역을 구분하는 이유이다. 따라서 이러한 bss영역 변수들은 많아져도 프로그램의 실행코드 사이즈를 늘리지 않는다.
  ```

- **`heap 영역`**

  - 필요에 의해 동적으로 메모리를 할당 하고자 할 때 위치하는 메모리 영역으로 동적 데이터 영역이라고 부르며, 메모리 주소 값에 의해서만 참조되고 사용되는 영역이다.
  - 이 영역에 데이터를 저장 하기 위해서 C는 malloc(), C++은 new() 함수를 사용한다.

- **`stack 영역`**

  -  프로그램이 자동으로 사용하는 임시 메모리 영역이다.
  - 지역(local) 변수, 매개변수(parameter), 리턴 값 등 잠시 사용되었다가 사라지는 데이터를 저장하는 영역이다.
  - 함수 호출 시 생성되고, 함수가 끝나면 시스템에 반환 된다.
  - 스택 사이즈는 각 프로세스마다 할당 되지만 프로세스가 메모리에 로드 될 때 스택 사이즈가 고정되어 있어, 런타임 시에 스택 사이즈를 바꿀 수는 없다.
  - 명령 실행시 자동 증가/감소 하기 때문에 보통 메모리의 마지막 번지를 지정 한다.

  ```bash
  # HEAP overflow - heap이 위에서부터 주소값을 채워져 내려오다가 stack영역을 침범하는 경우.
  # STACK overflow - stack영역이 heap을 침범.
  ```



### 프로세스 상태

![image-20210513135941476](https://user-images.githubusercontent.com/58545240/118079629-7ff32c80-b3f3-11eb-8618-7405e2c8180d.png)

- **`New`** : 프로세스가 생성 중 (`log on`, `프로그램의 실행`)
- **`Running`** : 프로세스가 실행 중 (프로세서에 상주하고 있는 상태)
- **`Waiting`** : 프로세스가 어떤 사건을 기다리고 있는 상태
- **`Ready`** : 프로세스가 프로세서에 할당되기를 기다리고 있는 상태
- **`Terminated`** : 프로세스의 실행이 종료된 상태



### 프로세스의 주소공간

- `실행 스택(Stack)`
  - **호출된 프로시저(함수)의 복귀 주수와 지역 변수와 같이 일시적인 데이터를 저장하는 영역**
  - 프로시저를 호출할수록 (`push`) 영역이 커지고 프로시저를 반환할 때 (`pop`) 줄어든다.
- `실행 힙(Heap)`
  - **코드 영역과는 별도로 유지되는 자유 영역**
  - 프로세스 실행 중에 동적으로 할당되는 메모리 영역으로 시스템 호출을 통해 사용되다가 해지뇌는 등 자유자재로 사용된다.
- `데이터(Data)`
  - 프로세스 실행 중에 동적으로 할당받는 영역으로 **전역 또는 정적 변수를 저장**한다.
  - 읽고 쓰기가 가능하다.
- `코드(Code)`
  - **프로세서(CPU)**가 실행하는 코드를 저장하는 영역
  - 프로그램이 코드 영역을 침범하여 기록하려고 하면 오류가 발생하고 프로그램은 종료된다.

### 프로세스 제어 블록

> **`PCB` (Process Control Block)**

PCB 는 특정 **프로세스에 대한 중요한 정보를 저장** 하고 있는 운영체제의 자료구조이다. 운영체제는 프로세스를 관리하기 위해 **프로세스의 생성과 동시에 고유한 PCB 를 생성** 한다. 프로세스는 CPU 를 할당받아 작업을 처리하다가도 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU 를 반환해야 하는데, 이때 작업의 진행 상황을 모두 PCB 에 저장하게 된다. 그리고 다시 CPU 를 할당받게 되면 PCB 에 저장되어있던 내용을 불러와 이전에 종료됐던 시점부터 다시 작업을 수행한다.

*PCB 에 저장되는 정보*

- `프로세스 식별자(Process ID, PID)` : 프로세스 식별번호
- `프로세스 상태` : new, ready, running, waiting, terminated 등의 상태를 저장
- `프로그램 카운터` : 프로세스가 다음에 실행할 명령어의 주소
- `CPU 레지스터`
- `CPU 스케쥴링 정보` : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
- `메모리 관리 정보` : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함
- `입출력 상태 정보` : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
- `어카운팅 정보` : 사용된 CPU 시간, 시간제한, 계정번호 등



## 스레드

> **Thread란 CPU를 구성하는 기본 실행 단위이다.**
>
> **Thread ID(`tid`), Program Count(`pc`), Register Stack 및 Stack으로 구성되어 있다.**

### 스레드의 구조

- 스레드 실행시 상태
- **실행 스택(stack)**
- 지역 변수와 스레드의 특정 데이터를 저장하기 위한 스레드별 정적 저장소
- 프로세스의 다른 스레드가 공유하는 메모리와 자원에 대한 접근 같은 **스레드 실행 환경 정보(Context Information)**
- **PC(Program Counter), SR(Sequence Register), SP(Stack Pointer)**

### 스레드의 이점

- 사용자에 대한 응답성 증가
  - 다중 스레드 환경에서는 하나의 스레드가 blocked 상태인 동안(예를 들어 입출력을 하는 동안) 다른 스레드가 실행되어 다른 작업을 빨리 처리하면서 사용자와 상호작용이 가능하다.
- 프로세스의 자원과 메모리 공유 가능
  - 스레드는 한 프로세스의 자원을 공유하기 때문에 하나의 같은 주소 공간에서 여러 개의 스레드를 실행해 시스템 성능을 향상시킨다. **`병렬성`**, **`성능향상`**
- 경제성
  - 스레드는 한 프로세스의 자원을 공유하기 때문에, 메모리와 자원을 할당해 프로세스를 생성하는 것보다 스레드끼리 문맥 교환하는 것이 오버헤드가 적다.
- 다중 프로세서(CPU) 구조 활용 가능
  - 다중 프로세서 구조에서 각 스레드는 다른 프로세성에서 병렬로 실행될 수 있다.



한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 주소 공간이나 자원을 공유할 수 있다. 

같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 그리고 열린 파일이나 신호와 같은 운영체제 자원들을 공유한다. 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상시키는 것을 멀티스레딩이라고 한다. 이 경우 각각의 스레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC 레지스터 값을 갖고 있다.



#### Stack을 스레드마다 독립적으로 할당하는 이유

- stack은 프로시저의 복귀 주소나, 지역 변수 같이 일시적이고 독립적인 실행환경을 제공한다.
- **스레드는 하나의 독립적인 실행 단위이기 때문에 각각 해당 실행에 대한 독립적 stack을 가진다**

스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고 이는 독립적인 실행 흐름이 추가되는 것이다. 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.

#### PC Register 를 스레드마다 독립적으로 할당하는 이유

- 스레드는 프로세스와 같이 CPU를 할당받고, 선점당할 수 있다.
- 따라서 문맥교환이 발생하게 되므로 **실행하고 있는 코드의 지점을 저장하는 PC Register는 스레드마다 독립적으로 할당**되어야 한다.

PC 값은 스레드가 명령어의 어디까지 수행하였는지를 나타나게 된다. 스레드는 CPU 를 할당받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다. 따라서 PC 레지스터를 독립적으로 할당한다.

---

# [ 프로세스간 통신 ]

## IPC

> Inter Process Communication

각 프로세스들이 통신하는 모든 형태를 일컫는다. 이에는 다양한 형태의 메세지 전달 방식이 포함된다.

### 종류

- `Shared Memory`
  - 프로세스간 공유되는 메모리 영역을 만들어 사용하는 방법
  - 프로세스들은 읽기/쓰기를 통해 공유영역을 수정할 수 있다.
  - 주로 부모/자식 프로세스 간에 사용한다.
- `Message Passing`
  - 다른 프로세스에 **message** 를 보내 정보를 교환하는 방법
  - 주로 작은 데이터를 교환하며 구현이 쉽다.
  - **system call**이 잦아 자칫 느려질 수 있다.
- `Sockets`
  - Network Communication의 Endpoint 간의 통신이다.
  - **IP Address, Port**를 이용해 직접 통신한다.
- `Pipe`
  - Message나 Shared Memory는 서로 다른 process간 memory에서 구조체 또는 데이터를 주고받았지만
  - Pipi는 양방향 간의 버퍼를 통해서 데이터를 읽거나 쓰는 구조이다.
  - 연속적인 **byte stream** 을 교환할 때 많이 사용된다.



## RPC

> Remote Procedure Call

IPC방식 중 한 가지이다.

메서드 호출 내부 간의 내부 통신을 숨겨주며, 별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행할 수 있게 하는 프로세스간 통신 기술이다.

클라이언트는 다른 머신에 존재할 수 있는 원격 서버와 IPC를 처리하는 로컬 메소드를 호출한다.

다시 말해, 원격 프로시저 호출을 이용하면 프로그래머는 함수가 실행 프로그램에 로컬 위치에 있든 원격 위치에 있든 동일한 코드를 이용할 수 있다.

객체 지향의 원칙을 사용하는 소프트웨어의 경우 원격 프로시저 호출을 **원격호출(remote invocation)** 또는 **원격 메소드 호출(remote method invocation)**이라고 일컫는다.

*안드로이드 서비스 호출 패턴은 RPC를 구현하고 있다.*

### 종류

- `RMI (Remote Method Invocation)`
  - RPC를 객체지향으로 구현
  - 서버와 클라이언트 모두 **helper**가 필요하다. (**서버 측은 Skeleton, 클라이언트 측은 Stub**)
- `Stub`
  - 원격지에 위치해 있는 프로그램을 대리하는 작은 루틴이다.
  - RPC를 사용하는 프로그램이 컴파일되면 요청된 절차를 제공하는 프로그램의 대역을 한다.
  - 클라이언트에서 요청하는 데이터를 Marshaling하고 작업이 완료된 데이터를 다시 UnMarshaling하는 역할
- `Skeleton`
  - Stub과 비슷한 역할로 서버의 보조 객체이다.
  - 클라이언트의 Stub에서 데이터가 Marshaling되어 전송되면 Seleton에서 UnMarshaling하여 원래의 형태로 복원한다.
- `Marshaling /  Unmarshaling`
  - Marshaling은 데이터를 바이트로 쪼개서 `TCP/IP`같은 통신 채널을 통해 전송될 수 있는 형태롤 바꿔주는 과정
  - UnMarshaling은 반대로 전송 받은 바이트를 원래의 형태로 복원하는 과정

---

# [ 멀티 스레드 ]

멀티 쓰레드 모델을 살펴보기 전에 먼저 **User Thread**와 **Kernel Thread**에 관해 살펴보자.

말 그대로 **User Thread**는 User level의 Thread 라이브러리를 통해 관리되는 Thread를 말하며 **Kernel Thread**는 운영체제가 제공하고 직접 관리하는 Thread를 말한다

Multi-Thread에는 총 네 가지 모델이 있다.

1. `Many-to-One Model`

   ![image-20210503175702103](https://user-images.githubusercontent.com/58545240/116858546-80dccf00-ac39-11eb-85aa-9faac71e3855.png)

   - Kernel Thread가 다수의 User Thread를 처리하는 구조이다.
   - 이러한 구조는 User Thread를 처리하던 중 System call에 의해 blocking이 된다면 **전체 프로세스가 막히는 병목현상이 일어나게 되는 문제점**을 갖고 있다.

2. `One-to-One Model`

   ![image-20210503175749799](https://user-images.githubusercontent.com/58545240/116858575-8c2ffa80-ac39-11eb-885a-f2866aa8edba.png)

   - One-to-One model로 처리해야 할 User Thread 한 개당 Kernel Thread를 대응시켜 작업을 진행하는 구조입니다.
   - 이러한 일대일 대응 구조는 **Kernel Thread 생성에 과도한 생성의 문제**를 가져오게 된다

3. `Many-to-Many Model`

   ![image-20210503175827655](https://user-images.githubusercontent.com/58545240/116858590-9225db80-ac39-11eb-9f4b-b3399fd6b4db.png)

   - 그리하여 어느 정도 보완된 모델이 바로 Many-to-Many model이고 그림과 같이 **다수의 User Thread를 다수의 Kernel Thread가 처리**하는 구조인데 
   - Kernel Thread의 숫자는 User Thread의 숫자보다 같거나 작게 할당이 되어야 합니다.

4. `Two-Level Model`

   ![image-20210503175855489](https://user-images.githubusercontent.com/58545240/116858605-9a7e1680-ac39-11eb-8875-cf138a1b1be3.png)

   - 그리고 최종적으로 보완된 모델이 Many-to-Many model을 더욱 보완하여 만든 Two-level model이다.
   -  Many-to-Many model과 One-to-One model을 합친 구조로 **중요한 작업은 One-to-One 구조**를 통해 처리하고 
   - **나머지는 Many-to-Many 구조를 통해 처리**함으로써 혹시나 있을 중요한 작업에서의 기다림 현상을 줄일 수 있다.

   

## 멀티 스레딩의 장점

프로세스를 이용하여 동시에 처리하던 일을 스레드로 구현할 경우 메모리 공간과 시스템 자원 소모가 줄어들게 된다. 스레드 간의 통신이 필요한 경우에도 별도의 자원을 이용하는 것이 아니라 전역 변수의 공간 또는 동적으로 할당된 공간인 Heap 영역을 이용하여 데이터를 주고받을 수 있다. 그렇기 때문에 프로세스 간 통신 방법에 비해 스레드 간의 통신 방법이 훨씬 간단하다. 심지어 스레드의 context switch 는 프로세스 context switch 와는 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다. 따라서 시스템의 throughtput 이 향상되고 자원 소모가 줄어들며 자연스럽게 프로그램의 응답 시간이 단축된다. 이러한 장점 때문에 여러 프로세스로 할 수 있는 작업들을 하나의 프로세스에서 스레드로 나눠 수행하는 것이다.



## 멀티 스레딩의 문제점

멀티 프로세스 기반으로 프로그래밍할 때는 프로세스 간 공유하는 자원이 없기 때문에 동일한 자원에 동시에 접근하는 일이 없었지만 멀티 스레딩을 기반으로 프로그래밍할 때는 이 부분을 신경써줘야 한다. 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다.

그렇기 때문에 멀티스레딩 환경에서는 동기화 작업이 필요하다. 동기화를 통해 작업 처리 순서를 컨트롤 하고 공유 자원에 대한 접근을 컨트롤 하는 것이다. 하지만 이로 인해 병목현상이 발생하여 성능이 저하될 가능성이 높다. 그러므로 과도한 락으로 인한 병목현상을 줄여야 한다.



## 멀티 스레드 vs 멀티 프로세스

멀티 스레드는 멀티 프로세스보다 적은 메모리 공간을 차지하고 문맥 전환이 빠르다는 장점이 있지만, 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 점과 동기화 문제를 안고 있다. 반면 멀티 프로세스 방식은 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다는 장점이 있지만, 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지한다는 단점이 존재한다. 이 두 가지는 동시에 여러 작업을 수행한다는 점에서 같지만 적용해야 하는 시스템에 따라 적합/부적합이 구분된다. 따라서 대상 시스템의 특징에 따라 적합한 동작 방식을 선택하고 적용해야 한다.

---

# [ 스케쥴러 ]

*프로세스를 스케줄링하기 위한 Queue 에는 세 가지 종류가 존재한다.*

- Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
- Ready Queue : 현재 메모리 내에 있으면서 CPU 를 잡아서 실행되기를 기다리는 프로세스의 집합
- Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합

각각의 Queue 에 프로세스들을 넣고 빼주는 스케줄러에도 크게 **세 가지 종류가** 존재한다.



## 장기스케줄러

> **Long-term Scheduler or Job Scheduler**

메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool 에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue 로 보낼지 결정하는 역할을 한다.

간단히 말해서 장기스케쥴러는 시스템의 다중 프로그래밍 정도를 결정한다.

- 메모리와 디스크 사이의 스케줄링을 담당.
- 프로세스에 memory(및 각종 리소스)를 할당(admit)
- degree of Multiprogramming 제어
  (실행중인 프로세스의 수 제어)
- 프로세스의 상태
  new -> ready(in memory)

*cf) 메모리에 프로그램이 너무 많이 올라가도, 너무 적게 올라가도 성능이 좋지 않은 것이다. 참고로 time sharing system 에서는 장기 스케줄러가 없다. 그냥 곧바로 메모리에 올라가 ready 상태가 된다.*



## 단기스케줄러

> **Short-term Scheduler or CPU Scheduler**

초기에 주 메모리에 많은 프로세스가 있을 때, 모든 프로세스가 준비 대기열에 있기 된다.

이 때 모든 프로세스 중에서 단일 프로세스를 선택하여 실행하고 이러한 결정을 수행한다.

- CPU 와 메모리 사이의 스케줄링을 담당.
- Ready Queue 에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정.
- 프로세스에 CPU 를 할당(scheduler dispatch)
- 프로세스의 상태
  ready -> running -> waiting -> ready

### 디스패쳐 

> **Dispatcher**

디스패처는 스케쥴러 이후에 작동하는 특수한 프로그램이다. 스케쥴러가 프로세스를 선택하면 해당 프로세스를 원하는 상태 / 대기열로 가져가는 것이 **Dispatcher**이다. 단기스케쥴러에서 CPU를 선택한 후 CPU에 대한 프로세스 제어를 제공하는 모듈이다.

- Switching Context
- Switching to User mode
- Jumping to the proper location in the user program to restart that program

### 스케쥴러와 디스패쳐의 차이점

다양한 프로세스가 실행 대기중인 Ready Queue에서 상주하고 있는 상황을 고려해보자. CPU는 이러한 모든 프로세스를 동시에 실행할 수 없으므로 운영체제는 스케쥴링 알고리즘을 기반으로 특정 프로세스를 선택해야 한다. 따라서 **다양한 프로세스 중에서 프로세스를 선택하는 이 절차는 `Scheduler`에 의해 수행된다.** 스케쥴러가 **대기열에서 프로세스를 선택하면 `Dispatcher`가 나타나고 `Ready Queue`에서 해당 프로세스를 가져와 실행 중 상태로 이동하는 것은 `Dispatcher`이다.**

따라서 스케쥴러는 디스패처가 시간이 지남에 따라 CPU로 이동하는 순서가 지정된 프로세스 목록을 디스패처에게 제공하게 된다.



## 중기스케줄러

> **Medium-term scheduler or Swapper**

대부분의 경우 실행중인 프로세스에는 CPU가 필요없는 I/O 작업이 필요하다. 따라서, I/O 작업이 필요한 프로세스를 실행하는 동안 운영체제는 해당 프로세스를 `Ready Queue`에서 `Blocked Queue`로 보낸다.

프로세스가 I/O 작업을 완료하면 다시 준비 대기열로 이동해야 하고 이러한 결정을 수행한다. (스와핑!)

- 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄 (swapping)
- 프로세스에게서 memory 를 deallocate
- degree of Multiprogramming 제어
- 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러.
- 프로세스의 상태
  ready -> suspended

### Process state - suspended

Suspended(stopped) : 외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미한다. 프로세스 전부 디스크로 swap out 된다. blocked 상태는 다른 I/O 작업을 기다리는 상태이기 때문에 스스로 ready state 로 돌아갈 수 있지만 이 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다.

---

# [ CPU 스케쥴러 ]

> 여러 프로세스를 concurrent하게 쓰는게 멀티프로그래밍과 멀티쓰레딩이었고, 그 전제조건으로 바로 CPU Scheduling이 필요하다.

*스케줄링 대상은 **Ready Queue** 에 있는 프로세스들이다.*

(이 Ready Queue는 `LinkedList or Binary Tree or FIFO Queue or PriorityQueue`를 사용하여 만들어진다.)

들어가기 전에 먼저 용어 정리 부터 하겠다.

> **`선점(preemptive)`** : 우선순위가 높은 작업이 오거나, 해당 작업이 더 우선되어야 한다고 판단되면 해당 작업에게서 CPU를 빼앗을 수 있다.
> **`비선점(non-preemptive)`** : 일단 CPU를 할당받으면 해당 프로세스가 끝날때까지 CPU를 빼앗기지 않는다.

## 스케쥴링 알고리즘에 대한 성능 척도

- `프로세서 이용율 (CPU Utilization)`
  
  - **시간당 CPU를 사용한 시간의 비율** 
  - 프로세서를 실행상태로 항상 유지하여 유휴상태가 되지 않도록 한다. 가능하면 입출력(I/O) 중심의 작업보다 프로세서 중심의 작업을 실행해야 한다.
- `처리율 (Throughput)`
  - **시간당 처리한 작업의 비율**
  - 단위 시간당 완료되는 작업수가 많도록 짧은 작업을 우선 처리하거나 인터럽트 없이 작업을 실행한다.
- `반환시간 또는 소요시간 (Turnaround Time)`
  - **CPU burst time**(쓰고 나갈때까지의 시간, 누적되지 않음)
  - 작업이 시스템에 맡겨져서 메인 메모리에 들어가기까지의 시간, 준비 큐에 있는 시간, 실행시간, 입출력시간 등 작업 제출 후 완료되는 순간까지의 소요시간이 최소화되도록 일괄 처리 작업을 우선 처리한다.
- `대기시간 (Waiting Time)`
  - **대기열에 들어와 CPU를 할당받기까지 기다린 시간**
  - 작업의 실행시간이나 입출력시간에는 실제적인 영향을 미치지 못하므로 준비 큐애서 기다리는 시간이 최소화되도록 사용자 수를 제한한다.
- `반응시간 또는 응답시간 (Response Time)`
  - **대기열에서 처음으로 CPU를 얻을때까지 걸린시간**
  - 반응시간은 의뢰한 시간에서부터 반응이 시작되는 시간까지의 간격으로 대화형 시스템에서 중요한 사항이다. 따라서 대화식 작업을 우선 처리하고 일괄 처리 작업은 대화식 작업의 요구가 없을때까지 처리한다.
  
  

## FCFS

> **First Come First Served**

### 특징

- 먼저 온 고객을 먼저 서비스해주는 방식, 즉 먼저 온 순서대로 처리.
- `비선점형(Non-Preemptive) 스케줄링`
  일단 CPU 를 잡으면 CPU burst 가 완료될 때까지 CPU 를 반환하지 않는다. 할당되었던 CPU 가 반환될 때만 스케줄링이 이루어진다.

### 문제점

- `convoy effect(똥차 효과)`
  소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 발생한다.



## SJF

> **Shortest - Job - First**

### 특징

- 다른 프로세스가 먼저 도착했어도 **CPU burst time** 이 짧은 프로세스에게 우선 할당한다
- 일종의 우선순위 기법이라고 볼 수 있고, `비선점형(SJF)과 선점형(SRTF) 방식 모두 있다.`
- 최소 평균 대기 시간을 보장한다.
- 이론적으로 다른 알고리즘과 비교하기 위한 최적의 알고리즘일뿐, 직접 구현해서 쓰진 않는다.

### 문제점

- `starvation`
  효율성을 추구하는게 가장 중요하지만 특정 프로세스가 지나치게 차별받으면 안되는 것이다. 이 스케줄링은 극단적으로 CPU 사용이 짧은 job 을 선호한다. 그래서 사용 시간이 긴 프로세스는 거의 영원히 CPU 를 할당받을 수 없다.



## SRTF

> **Shortest Remaining Time First**

### 특징

- SJF의 선점형 스케쥴링 방식
- 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어진다.
- `선점형 (Preemptive) 스케줄링`
  현재 수행중인 프로세스의 남은 burst time 보다 더 짧은 CPU burst time 을 가지는 새로운 프로세스가 도착하면 CPU 를 뺏긴다.

### 문제점

- `starvation`
- 새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU burst time(CPU 사용시간)을 정확히 예측하기 어렵다.



## Priority Scheduling

### 특징

- 우선순위가 가장 높은 프로세스에게 CPU 를 할당하는 스케줄링이다. 우선순위란 정수로 표현하게 되고 작은 숫자가 우선순위가 높다.
- `선점형 스케줄링(Preemptive) 방식`
  더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU 를 선점한다.
- `비선점형 스케줄링(Non-Preemptive) 방식`
  더 높은 우선순위의 프로세스가 도착하면 Ready Queue 의 Head 에 넣는다.

### 문제점

- `starvation`
- `무기한 봉쇄(Indefinite blocking)`
  실행 준비는 되어있으나 CPU 를 사용못하는 프로세스를 CPU 가 무기한 대기하는 상태

### 해결책

- `aging`
  아무리 우선순위가 낮은 프로세스라도 오래 기다리면 우선순위를 높여주자.



## Round Robin

### 특징

- 현대적인 CPU 스케줄링으로 시분할 시스템을 위해 설계되었다.
- `선점형 스케줄링(Preemptive) 방식`
- 각 프로세스는 **동일한 크기의 할당 시간(time quantum)**을 갖게 된다. -> *이 time slice를 어떻게 하느냐에 따라 성능 차이가 난다.*
- 할당 시간이 지나면 프로세스는 선점당하고 `ready queue` 의 제일 뒤에 가서 다시 줄을 선다.
- **어떠한 프로세스도 `q time unit` 이상 기다리지 않는다. -> 공정한 알고리즘!**
- `RR`은 CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
- `RR`이 가능한 이유는 프로세스의 **context** 를 save 할 수 있기 때문이다.

### 장점

- `Response time`이 빨라진다.
  n 개의 프로세스가 ready queue 에 있고 할당시간이 q(time quantum)인 경우 각 프로세스는 q 단위로 CPU 시간의 1/n 을 얻는다. 즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.
- 프로세스가 기다리는 시간이 CPU 를 사용할 만큼 증가한다.

### 주의할 점

설정한 `time quantum`이 너무 커지면 `FCFS`와 같아진다. 또 너무 작아지면 스케줄링 알고리즘의 목적에는 이상적이지만 **잦은 context switch** 로 overhead(`dispatcher latency`) 가 발생한다. 그렇기 때문에 적당한 `time quantum`을 설정하는 것이 중요하다.



## MLQ 

> **Multi Level Queue**

### 특징

- `선점형 스케쥴링`
- 작업들을 여러 종류의 그룹으로 분할 (ex. 데이터, 사운드, 화면, 전화, 카톡, ...)
- 여러 개의 레디큐를 이용해 상위 단계 작업에 의해 하위 단계 작업이 선점된다.
- `Ready Queue`를 여러 종류로 분할한다.(작업 분류별 묶음) **-> 각각의 priority를 따로 배정한다.**
- 다른 큐로 작업 이동이 불가
- 각각의 `Ready Queue`는 자신만의 독자적인 스케쥴링을 가진다.
- 상위 우선순위의 큐가 Empty이면 하위 우선순의 큐의 프로세스가 수행된다.



## MLFQ 

> **Multi Level FeedBack Queue**

### 특징

- `선점형 스케쥴링`
- 입출력 위주와 CPU위주인 프로세스의 특성에 따라 큐 마다 서로 다른 **`CPU Time Slice(Time Quantum)`**을 부여한다.
- 새로운 프로세스는 높은 우선순위, 프로세스의 실행시간이 길어질수록 점점 낮은 우선순위 큐로 이동한다.
- **제일 마지막 단계에서는 `RR/FCFS`로 처리한다.**
- **우선순위가 높은 프로세스에게는 불이익을, 우선순위가 낮은 프로세스에게는 이익을 제공한다.**
- 기본적으로 가장 우선순위가 낮은 큐를 제외 하고는 모두 `RR` 스케쥴링을 사용한다.
- 하위 단계일 수록 할당 시간은 증가(공평성 부여)
- `기아(stravation)` 상태를 예방하기 위해 `Aging처리`를 이용한다.
- ***현대 OS에서 RR방식과 함께 가장 많이 사용되는 스케쥴링 기법이다.***



## 마무리

실제로는 쓰레드 스케쥴링을 하는데 쓰레드 스케쥴링은 어려워 프로세스에서 배운 것(CPU Scheduling)이다.

유저쓰레드는 일반적으로 `Thread` 라이브러리로 관리하게 되고 OS는 `many to many model`로 유저 쓰레드에게 이를 서비스한다.

++

> soft RTOS : 아주 조금의 오차정도는 허용된다.
>
> hard RTOS : 어떤 오차도 허용되면 안되고, 반드시 허용된 시간안에 task가 수행되어야 한다. (우선순위가 역전되면 안되!)

---

# [ 동기와 비동기 ]

## 동기

> **Synchronous**

동기는 말 그대로 동시에 일어난다는 뜻이다. 요청과 그 결과가 동시에 일어난다는 약속이다.

바로 요청을하면 시간이 얼마가 걸리던지 요청한 자리에서 결과가 주어져야 한다.

- 요청과 결과가 한 자리에서 동시에 일어남
- A노드와 B노드 사이의 작업 처리 단위(`transaction`)을 동시에 맞추겠다.
- **설계가 매우 간단하고 직관적**이지만 **결과가 주어질 때까지 아무것도 못하고 대기해야 하는 단점이 있다.**



## 비동기

> **Asynchoronous**

비동기는 동시에 일어나지 않는다를 의미한다. 요청과 그 결과가 동시에 일어나지 않을거라는 약속이다.

- 요청한 그 자리에서 결과가 주어지지 않음
- 노드 사이의 작업 처리 단위를 동시에 맞추지 않아도 된다.
- **동기보다 복잡하지만 결과가 주어지는데 시간이 걸리더라도 그 시간 동안 다른 작업을 할 수 있으므로 자원을 효율적으로 사용할 수 있다는 장점**이 있다.



## 비유를 통한 쉬운 설명

해야할 일(task)가 빨래, 설거지, 청소 세 가지가 있다고 가정한다. 이 일들을 동기적으로 처리한다면 빨래를 하고 설거지를 하고 청소를 한다. 비동기적으로 일을 처리한다면 빨래하는 업체에게 빨래를 시킨다. 설거지 대행 업체에 설거지를 시킨다. 청소 대행 업체에 청소를 시킨다. 셋 중 어떤 것이 먼저 완료될지는 알 수 없다. 일을 모두 마친 업체는 나에게 알려주기로 했으니 나는 다른 작업을 할 수 있다. 이 때는 백그라운드 스레드에서 해당 작업을 처리하는 경우의 비동기를 의미한다.



## Sync vs Async

일반적으로 동기와 비동기의 차이는 메소드를 실행시킴과 `동시에` 반환 값이 기대되는 경우를 **동기** 라고 표현하고 그렇지 않은 경우에 대해서 **비동기** 라고 표현한다. 동시에라는 말은 실행되었을 때 값이 반환되기 전까지는 `blocking`되어 있다는 것을 의미한다. 비동기의 경우, `blocking`되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task 를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않는다.

> 비동기 방식의 예제를 통해서 **블록(Block)과 논블록(NonBlock)**의 차이를 간략하게 설명하자면, 빨래 업체에게 빨래를 시킨 후 가만히 앉아 빨래완료 라는 연락만을 기다린다면 **블록** 상태이다. 하지만 빨래가 완료되었다는 전송을 받기 전까지 다른 설거지나 청소를 하게되면 학생의 상태는 **논블록** 상태 라고한다.

---

# [ 프로세스 동기화 ]

## Critical Section

> 임계영역

멀티 스레딩에 문제점에서 나오듯, 동일한 자원을 동시에 접근하는 작업(e.g. 공유하는 변수 사용, 동일 파일을 사용하는 등)을 실행하는 코드 영역을 Critical Section 이라 칭한다.

다른 프로세스와 공동으로 사용하는 변수, 테이블, 파일 등을 변경하는 부분이다.

---

## Critical Section Problem

> 임계영역 문제

프로세스들이 Critical Section 을 함께 사용할 수 있는 프로토콜을 설계하는 것이다.

- **`Race Conditoin`**
  - 여러 프로세스가 공통된 데이터를 조작할 때 결과가 조작의 타이밍이나 접근 순서에 의해 결정되는 현상

---

## Requirements

> 해결을 위한 기본 조건

- `Mutual Exclusion(상호 배제)`
  -   프로세스 P1 이 Critical Section 에서 실행중이라면, 다른 프로세스들은 그들이 가진 Critical Section 에서 실행될 수 없다.
  -   ***한 프로세스가 임계구역에서 실행하고 있으면 어떤 프로세스도 그 임계구역에 진입할 수 없어야 한다. SW로 가능하지만 매우 복잡하여 대부분 HW로 보조한다.***
- `Progress(진행)` -> **No Deadlock**
  -   Critical Section 에서 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스들만 Critical Section 진입 후보로서 참여될 수 있다.
  -   임계영역에 어떤 스레드의 접근도 없을 때 항상 접근이 가능해야 한다.
  -   ***임계 구역을 실행하고 있는 프로세스가 없을 때, 몇 개의 프로세스가 임계 구역에 진입하고자 하면 이들의 진입 순서는 이들에 의해서만 결정되어야 한다. 또한, 이 선택은 무한정 연기되어서는 안된다.***
- `Bounded Waiting(한정된 대기)` -> **No Starvation**
  -   P1 가 Critical Section 에 진입 신청 후 부터 받아들여질 때가지, 다른 프로세스들이 Critical Section 에 진입하는 횟수는 제한이 있어야 한다.
  -   모든 프로세스가 임계영역에 들어가기 위해 기회를 가질 수 있어야 한다.
  -   ***한 프로세스가 자신의 임계 구역에 진입하고자 요청을 한 후부터 이 요청이 허용될 때까지 다른 프로세스가 그들의 임계구역에 진입할 수 있는 회수가 제한되어야 한다.***

---

## Peterson's algorithm

피터슨 알고리즘은 상호 배제를 위한 `병렬 프로그래밍 알고리즘`으로 공유 메모리를 활용하여 여러 개의 프로세스가 하나의 자원을 사용할 때 문제가 발생하지 않도록 한다. 당시의 알고리즘은 프로세스가 2개인 경우에서만을 제한한다.

지금은 일반화 되어서 3개 이상의 프로세스들 사이에서도 이 방법이 통용된다고 한다.

`Pi` `Pj` 프로세스로 표시하며 이 알고리즘의 가장 큰 특징은 `booelan flag`과 `int turn`이라고 하는 두 개의 변수를 이용한다.

예를 들어 만나면 싸우기만 하는 두 개가 있다. 보다 못한 주인은 우리집 개가 산책할 때는 너희집 개는 집에 있으라고 한다. 우리집 개가 산책을 떠나면 집에서 깃발을 뽑고, 우리집 개가 산책을 마치고 돌아오면 집에 깃발을 다시 꽂음으로서 상대 집 개에게 알려주는 것이다. 

이런식으로 서로 `*producer()`와 `*consumer()`가 주고받는 티키타카 구조를 구현하는 것이다.

하지만 이는 `while (flag[1] && turn ==1 )`의 과정에서 **`context switch`**가 일어나면 피터슨 솔루션의 동작은 올바르게 수행되지 않는다. **그럼에도 이를 배우는 이유는 위에서 언급한 세가지 요구 사항을 개념적으로 완벽하게 증명하기 때문이다.**

사실 sw가 아니라 hw instruction을 가지고 동기화를 수행하는 것이 가장 좋다.

그 중에서 더이상 쪼갤 수 없는 성질인 **`Atomicity`**를 구현하는 것이다. 바로 HW Instruction을 Atoic instruction으로 구현하여 `a++`, `i<->j`와 같은 행위를 세번으로 나누지 말고 단 **원 클락**으로 구현하도록 만드는 것이다. 

우리는 SW엔지니어로서 이를 자바를 피터슨 솔루션을 구현할 것이다.

`java.util.concurrent.atomic.Atomicboolean`을 사용한다.

```java
static Atomicboolean[] falg;

Producer implements Runnable {
    public void run() {
        flag[1].set(true);
        turn = 1;
        for (int k = 0; k < 1000; k++) {
            while (flag[1].get() && turn == 1) {
                ;
            }
        }
        ...
    }
}
```

이와 같이 구현한다면 `flag[1].get()`이 **atomic variable**이기 때문에 while에서 **`context switch`**가 일어나지 않고 상호배제를 구현할 수 있게 된다.

위에서 언급한 동기화의 가장 기본적인 방법 세가지를 모두 만족하는 것은 힘들다.

그러므로 우리는 상호배제만 구현해볼 것인데 이를 위해서 바로 **`Mutex`, `Semaphore`, `Monitor`를 이용할 것이다.**

---

## == 해결책 ==

앞서 총 두 가지의 임계영역 문제의 솔루션을 알아보았다.

1. SW 솔루션 : `Peterson's Algorithm`
2. HW 솔루션 : "`test-and-set`" , "`compare-and-swap`" 을 이용한 **Atomic Variable** HW instruction이다.

이제 조금 더 SW에서 고급 레벨의 솔루션을 알아 볼 것이다.

1. Mutex (`Binary Semaphore`) : 가장 간단한 동기화 툴 (locking : 열쇠)
2. Semaphore(`Counting Semaphore`) : 더욱 편리하고 효과적
3. Monitor : 뮤텍스와 세마포어의 단점을 극복 --> **Java에서 생각하는 locking은 모두 Monitor이다.**

## Lock

- 하드웨어 기반 해결책으로써, 동시에 공유 자원에 접근하는 것을 막기 위해 Critical Section 에 진입하는 프로세스는 Lock 을 획득하고 Critical Section 을 빠져나올 때, Lock 을 방출함으로써 동시에 접근이 되지 않도록 한다.

### 한계

- 다중처리기 환경에서는 시간적인 효율성 측면에서 적용할 수 없다.

---

## Semaphores

- 신호기!
- 소프트웨어상에서 Critical Section 문제를 해결하기 위한 동기화 도구

OS 는 Counting/Binary 세마포를 구분한다

### - Binary Semaphore

MUTEX 라고도 부르며, 상호배제의 (Mutual Exclusion)의 머릿글자를 따서 만들어졌다. 이름 그대로 0 과 1 사이의 값만 가능하며, 다중 프로세스들 사이의 Critical Section 문제를 해결하기 위해 사용한다.

`acquire()`와 `release()`를 **atomically**하게 구현한다. 이는 운영체제 커널을 만드는 사람이 `compare_and_swap()`과 같은 기능을 이용해 만들것이다.

하지만 뮤텍스도 단점이 있는데 **Busy Waiting**이라는 문제가 생긴다.

**`Busy Waiting`**이란 어떤 임계영역에 들어가기 위해 무한루프에 들어가게 되는 것을 말한다. 멀티 프로그래밍에서는 이것이 단점이 된다. 다른 프로세스가 생산적으로 쓸 수 있는 CPU 자원을 CPU 싸이클을 통해 쓸데 없이 낭비하게 되기 때문이다.

### - Counting Semaphore

`wait()`와 `signal()`을 **atomically**하게 구현한다.

**가용한 개수를 가진 자원** 에 대한 접근 제어용으로 사용되며, 세마포는 그 가용한 **자원의 개수**(`count`) 로 초기화 된다. 자원을 사용하면 세마포가 감소(**wait()** :: `count--`), 반납하면 세마포가 증가(**signal()** :: `count++`) 한다.

count가 0일 때는 모든 리소스가 사용하고 있기 때문에 누군가가 반납하기 전까지 자원을 사용하지 못한다.

```bash
### 세마포어의 busy waiting 문제를 해결하는 방법 ###

굳이 세마포어가 무한루프를 돌지 않고 wait()로 suspend 시켜서 waiting queue에 대기하고 있다가, 다른 프로세스가 signal()을 호
출하면 다시 ready queue에 들어가도록 하면 busy waiting 문제를 해결할 수 있다.
```

`Counting Semaphore`를 쓴다 하더라도 (ex. `int sum = 987`) 변수 하나만으로는 상호배제를 피할 수 없다. 왜냐하면 각각의 세마포어는 각각의 **`instance`**를 취급해야 하기 때문에 `int sum[n]`으로 할당하여 각각의 세마포어에게 서로 다른 `instance`를 할당하여야 한다.



```bash
# Mutex vs Semaphore
- 세마포어는 뮤텍스가 될 수 있지만 뮤텍스는 세마포어가 될 수 없다.
- 세마포어는 소유할 수 없는 반면, 뮤텍스는 소유가 가능하며 소유주가 이에 대한 책임을 진다.
- 뮤텍스의 경우 뮤텍스를 소유하고 있는 스레드가 이 뮤텍스를 해제할 수 있다. 하지만 세마포어의 경우 이러한 세마포어를 소유하지 않는 스레드가 세마포어를 해제할 수 있다.
- 세마포어는 시스템 범위에 걸쳐 있고 파일 시스템 상의 파일 형태로 존재한다. 반면 뮤텍스는 프로세스 범위를 가지며 프로세스가 종료될 때 자동으로 clean up 된다.
- 가장 큰 차이점은 관리하는 동기화 대상의 갯수 이다.(뮤텍스는 오직 하나, 세마포어는 하나 이상)
```

### Spin Lock

> `busy waiting`을 하는 semaphore

스핀락은 말 그대로, 다른 스레드가 lock(열쇠)을 소유하고 있다면 그 lock(열쇠)이 반환될 때 까지 계속 확인하며 기다리는 것이다. **"조금만 기다리면 바로 쓸 수 있는데 굳이 컨텍스트 스위칭으로 부하를 줄 필요가 있나?"** 라는 컨셉으로 개발된 것으로 임계영역에 진입이 불가할 때 `Context Switch`를 하지 않고 잠시 루프를 돌면서 재시도를 하는 것이다.

Lock과 UnLock을 하는 과정이 매우 짧아서 락하는 경우가 드문경우 유용하게 사용할 수 있다. 특징을 알아보자.

- Lock을 얻을 수 없다면 계속해서 Lock을 확인하며 얻을 때까지 기다린다. 이른바 바쁘게 기다리는 **busy waiting**이다.
- 바쁘게 기다린다는 것은 무한 루프를 돌면서 최대한 다른 스레드에게 CPU를 양보치 않는 것이다.
- Lock이 곧 사용가능해 질경우 `Context Switch`를 줄여 CPU의 부담을 덜어준다. 하지만, 어떤 스레드가 Lock을 오랫동안 유지한다면 오히려 CPU 시간을 많이 소모할 가능성이 있다.
- **하나의 CPU나, 하나의 코어만 있는 경우에는 유용하지 않다.** 이유는, 만약 다른 스레드가 Lock을 가지고 있고 그 스레드가 Lock을 풀어 주려면 싱글 CPU 시스템에서는 어차피 `Context Swtich`가 일어나야 하기 때문이다.
- 스핀락을 잘못 사용할 경우 CPU 사용을 100%로 만드는 상황이 발생하므로 주의해야 한다. 스핀락은 기본적으로 무한루프를 돌면서 Lock을 기다리므로 하나의 쓰레드가 Lock을 오래 가지고 있다면 다른 블락킹된 쓰레드는 **busy waiting**하게 되므로 CPU를 쓸데없이 낭비한다.

### 단점

- `Busy Waiting(바쁜 대기)`
  Spin lock이라고 불리는 Semaphore 초기 버전에서 Critical Section 에 진입해야하는 프로세스는 진입 코드를 계속 반복 실행해야 하며, CPU 시간을 낭비했었다. 이를 Busy Waiting이라고 부르며 특수한 상황이 아니면 비효율적이다. 일반적으로는 Semaphore에서 Critical Section에 진입을 시도했지만 실패한 프로세스에 대해 Block시킨 뒤, Critical Section에 자리가 날 때 다시 깨우는 방식을 사용한다. 이 경우 Busy waiting으로 인한 시간낭비 문제가 해결된다.

### Deadlock(교착상태)

- 세마포가 Ready Queue 를 가지고 있고, 둘 이상의 프로세스가 Critical Section 진입을 무한정 기다리고 있고, Critical Section 에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되야만 빠져나올 수 있는 상황을 지칭한다.

---

## 모니터

> 세마포어나 뮤텍스를 잘못 사용해서 일어나는 에러가 발생할 수 있다.
>
> 따라서 자바에서는 더욱 심플한 동기화 툴인 **"모니터"**를 제공한다.
>
> - 고급 언어의 설계 구조물로서, 개발자의 코드를 상호배제 하게끔 만든 추상화된 데이터 형태이다.
> - 공유자원에 접근하기 위한 키 획득과 자원 사용 후 해제를 모두 처리한다. (세마포어는 직접 키 해제와 공유자원 접근 처리가 필요하다.

### - 모니터의 개념

- 하나의 데이터(객체)마다 하나의 모니터를 결합할 수 있으며, 모니터는 그것이 결합된 데이터(객체)가 동시에 두 개 이상의 스레드에 의해 접근할 수 없도록 막는 **잠금(lock)**기능을 제공함으로써, 동기화를 수행하는 동기화 도구이다.
- 즉, 데이터(객체)에 모니터를 결합하면 하나의 스레드가 그 데이터를 사용하는 동안에는 다른 스레드들이 그 데이터를 사용할 수 없게 된다.
- 자바에서는 **`synchronized` 메소드**가 선언된 객체와 **`synchronized` 블럭**에 의해 동기화 되는 모든 객체에 고유한 모니터가 결합이 되어 동기화 작업을 수행한다.

### - 모니터의 구성

- 스레드 단위로 모니터락을 획득(**`acquire lock`**)하거나 반환(**`release lock`**)한다.
- 동기화 코드(동기화메소드나 블럭)을 수행할 때에는 동기화 대상 인스턴스와 결합된 `Monitor Lock`을 획득한 후에 집입이 가능하며, 동기화 코드를 벗어날 때에는 `Monitor Lock`을 반환한다.
- 동기화 댕상 인스턴스 별로 이와 결합된 Monitor가 존재하며 해당 모니터는 현재 락을 획득한 스레드와 Lock Count 정보를 관리한다.
- 모니터가 Lock Count정보를 유지한다는 것은 동일 스레드가 중복해서 lcok을 걸 수 있다는 의미이다.

### - 상호배제 임계영역 구현

- 모니터 타입은 상호배제를 제공해주는 `ADT`이다. 쉽게 말해서 클래스이다.

  - 여기서 **`ADT`**란 `Abstract Data Type` 으로 추상 자료형이다.
  - **객체지향의 클래스와 같이 기능의 구현 부분을 나타내지 않고, 데이터의 형태와 그 데이터의 연산들을 정의 해놓은 자료형이다.**
  - 우리가 알고 있는 **자료구조**(Data Structure)는 추상 자료형이 정의한 연산들을 구현한 구현체를 가리킨다.
  - 즉, 추상 자료형은 구현 방법을 명시하고 있지 않다0는 점에서 자료구조와 다르다.
  - 자바로 치면 클래스인지 인터페이스인지 확인하면 된다.
  - **스택이나 큐**는 구현 방법이 전혀 정의되어 있지 않으니 `추상자료형`이고, **배열**은 연속적으로 저장되어 있도록 구현되어 있어야 하므로 `자료구조`이며, **연결리스트**도 다음 데이터의 위치를 저장하는 방식으로 정해져 있으니 `자료구조`이다.

- ```JAVA
  synchronized block {
      // 임계영역에 해당하는 코드 블럭을 선언할 때 사용한다.
      // 해당 임계영역에는 모니터 락을 획득해야 진입할 수 있다.
      // 모니터 락을 가진 객체 인스턴스를 지정할 수 있다.
      // 메소드에 선언하면 메소크 블록 전체가 임계영역으로 지정된다.
      // 이 때 모니터락을 가진 객체 인스턴스는 this 객체 인스턴스이다.
  }
  
  synchronized (object) {
      // critical section
  }
  ```

- 지금 까지 어렵게 상호배제를 구현한 것을, `JAVA VM`은 위와 같이 심플하게 끝낼 수 있다.

- 여기까지는 임계영역을 선언한 것이고 동기화는 되지 않은 것이다.

### - 동기화 구현

- 동기화를 하기 위해선 **`wait()`**와 **`notify()`** 메소드가 필요하다.
- 위 메소드는 `java.lang.Object Class`에 선언 되었다 (이 말은 모든 자바 객체가 가진 메소드이다.)
- 쓰레드가 어떤 객체의 `wait()` 메소드를 호출하면 해당 객체의 모니터락을 획득하기 위해 대기 상태로 진입한ㄷ.
- 쓰레드가 어떤 객체의 `notify()` 메소드를 호출하면 해당 객체의 모니터에 대기중인 쓰레드 하나를 깨운다.
- `notify()` 대신 `notifyAll()`을 사용하면 해당 객체 모니터에 대기중인 **모든** 쓰레드를 깨운다.

```java
static class Counter {
    public static int count = 0;
    synchronized public static void increment() {
        // critical section
        count++;
    }
}

/* 이렇게 method 앞에 modifed로 선언하는 것이 현하긴 하지만 내가 정하고 싶은 블록만 동기화 하기 위해선  이렇게도 가능하다. */
private static Object object = new Object();
synchronized (object) {
    count++;
}

/* 여기서 this는 자기 참조 변수 이기 때문에 각각의 쓰레드의 this를 참조 하는 것이다. */
/* -> 이 말은 모니터가 다 따로 존재한다는 의미로, 쓰레드 끼리 독립적이다. */
/* -> 이는 static으로 선언했기 때문에 ! */
synchronized (this) {
    counter.count++;
}

/* 하나의 인스턴스를 생성하고, 이를 쓰레드의 인자로 넘겨주면 같은 Counter()라는 동기화 블록이 동기화 된다. */
Counter count = new Counter();
for (...) {
    thread[i] = new Thread(new MyRunnable(counter));
    thread[i].start();
}
```

지금까지 배운 `mutex, semaphore, monitor`는 **상호배제**만 해결한 동기화 도구이다.

그래서 그러한 문제도 해결해보자고 최근에 나온것이 바로 `Liveness`이다.

#### Priority Inversion & Priority Inheritance

> **우선순위 역전**과 **우선순위 상속**

이제 한번 progress(No Deadlock)하고, bounded-waiting(No Prioity Inversion)의 문제까지 해결해보자.

- **데드락** : 두 개 이상의 프로세스가 영원히 기다려야 한다.
- **우선순위 역전** : 높은 우선순위의 프로세스가 낮은 우선순위 프로세스에게 밀리는 현상

```bash
## 예시
예를 들어 집에서 우선순위가 가장 높은 아빠가 TV를 보기 위해 막내에게 나가라고 한다. 근데 막내가 리모컨을 들고 나가면, 자발적으로 리모컨을 내려 놓을 때까지 티비를 보지 못한다.
```

- priority가 높음에도 불구하고 waiting queue에서 계속해서 기다리게 된다.
- 이를 **`priority-Inheritance` 프로토콜**를 이용해서 해결할 수 있다.
  - 우선순위 (높음) A > B > C (낮음)
  - Priority Inversion의 상황과 다르게 A 쓰레드가 lock을 얻가 실패하는 경우 현재 해당 리소스 lock을 얻어 동작하는 스레드 C의 우선순위를 A 스레드와 같이 높은 우선순위로 상속시키면서, 그 보다 낮은 우선순위의 B 스레드에게 선점되지 않게 막는다.
  - 그렇게 제일 낮은 우선순위를 잠시동안 가장 높이고, 그다음에 자원을 반납하고 나면 다시 원래대로 우선순위를 되돌리는 프로세스이다.
  - 결국 A스레드는 보다 빠르게 공유된 S자원의 할당을 받아 처리할 수 있다.
  - 리눅스 커널은 RT Task들 사이에서 사용되며, RT Mutex API를 통해 구현되었다.

---

## 전통적인 동기화 문제

### 1. Producer-Consumer Problem

> 생산자-소비자 문제

![image-20210513134200791](https://user-images.githubusercontent.com/58545240/118079247-cd22ce80-b3f2-11eb-93d3-eb823baeb8d2.png)

**데이터를 생산하는 쪽이 생산자, 소비하는 쪽이 소비자**이다.

생산자-소비자 문제란 생산자가 데이터를 생성하여 버퍼에 저장하고, 소비자가 버퍼에서 데이터를 가져와 소비하는 과정에서 발생할 수 있는 문제이다.

대표적으로 공유 자원에 대한 임계구역 문제와, busy waiting문제가 있으며 프로세스 동기화로 이 문제를 해결한다.



### 2. Readers - Writers Problem

> 독자-저자 문제

![image-20210513134232478](https://user-images.githubusercontent.com/58545240/118079268-d613a000-b3f2-11eb-9b18-3fbed62a7553.png)

**독자(Reader)는 데이터를 읽기만**하는 프로세스, **저자(Write)는 읽고 수정**하는 프로세스이다. 따라서 이들의 차이점은 데이터를 수정할 수 있느냐, 없느냐이다.

독저-저자 문제란 다수의 독자와 다수의 저자가 하나의 공통 데이터베이스를 사용할 떄 발생할 수 있는 문제를 뜻하며, 이는 프로세스 동기화로 해결할 수 있다.

효율적인 프로세스를 위해서 Reader들만 서로 공통 베이스에 동시접근할 수 있도록 허용하고 Write는 그대로 상호배제를 적용한다.



### 3. Dining Philosopher Problem

> 철학자들의 저녁식사 문제
>
> *철학자 다섯이서 원형 식탁에 둘러앉아 생각에 빠지다가, 배고플 땐 밥을 먹는다. 그들의 양쪽엔 각각 젓가락 한 짝씩 놓여있고, 밥을 먹으려 할 땐 다음의 과정을 따른다.*
> **철학자 : 프로세스**
> **젓가락 : 자원**

**1.** 왼쪽 젓가락부터 집어든다. 다른 철학자가 이미 왼쪽 젓가락을 쓰고 있다면 그가 내려놓을 때까지 생각하며 대기한다.

**2.** 왼쪽을 들었으면 오른쪽 젓가락을 든다. 들 수 없다면 1번과 마찬가지로 들 수 있을 때까지 생각하며 대기한다.

**3.** 두 젓가락을 모두 들었다면 일정 시간동안 식사를 한다.

**4.** 식사를 마쳤으면 오른쪽 젓가락을 내려놓고, 그 다음 왼쪽 젓가락을 내려놓는다.

**5.** 다시 생각하다가 배고프면 1번으로 돌아간다.



이 문제는 **`교착상태(Deadlock)`**의 대표적인 예제이다.

프로그램이 잘 돌아가다가 어느순간 멈춰버리는데, 이 문제가 데드락 발생의 **4가지 필요 조건**을 모두 만족하기 때문인다.

#### 교착상태의 4가지 필요조건

1. **상호배타 (Mutual Exclusion)**
   - 젓가락은 한번에 한 철학자만 사용할 수 있다.
2. **보유 및 대기 (Hold and Wait)**
   - 집어든 젓가락은 계속 들은채로 사용중인 반대쪽 젓가락을 기다린다.
3. **비선점 (No Preemption)**
   - 이미 누군가 집어든 젓가락을 강제로 뺏을 수 (선점할 수) 없다.
4. **환형대기 (Circular Wait)**
   - 모든 철학자들이 자신의 오른쪽에 앉은 철학자가 젓가락을 놓기를 기다린다.

*이 네 가지 조건 중 하나만 어겨도 데드락이 발생하지 않는다.*



예시로, **환형대기**를 해결하여 교착상태를 해결해 보자면, id가 짝수인 철학자는 왼쪽부터, id가 홀수인 철학자는 오른쪽부터 젓가락을 들게하면 교착상태가 일어나지 않는다. (이는 왼쪽 젓가락부터 집어드는 프로시저에 변화를 준 것이다.)

이 예시는, starvation 등을 고려한 것이 아니라 `deadlock`의 해결에 초점을 맞춘 예시이다.

---

## Deadlock

### RAG

>   Resource Allocation Graph (자원 할당 그래프)
>
>   자원할당 그래프란, 프로세스의 자원 할당 상태를 표현해주는 그래프이다.

![image-20210515123800139](https://user-images.githubusercontent.com/58545240/118347835-143eca00-b581-11eb-8dd8-2e455df502e9.png)

-   동그라미는 프로세스, 네모는 자원, 점은 자원의 Instance를 의미한다.
-   프로세스 -> 자원 : 프로세스가 해당 자원을 요청하는 것을 의미한다.
-   자원 -> 프로세스 : 프로세스가 해당 자원을 소유하는 것을 의미한다.
-   **위 `RAG`는 Deadlock이 아니다.**
-   P3가 작업을 마치고 자원 R3을 반납한다면, P2는 R3를 할당받아 잡업을 수행할 수 있다.

![image-20210515124059431](https://user-images.githubusercontent.com/58545240/118347849-1d2f9b80-b581-11eb-9cfc-414fc4fcef21.png)

-   `RAG`에 **Cycle**이 존재 하지 않으면 Deadlock이 아니다.
-   `RAG`에 **Cycle**이 존재 한다면, Deadlock일 수도, 아닐수도 있다.
-   위의 두 `RAG`모두 Cycle이 존재하지만, 왼쪽 그래프만 Deadlock이다.
-   오른쪽 `RAG`는 P2가 자원 R1을 반납하면, P1은 R1을 할당받아 작업을 수행한다. 마찬가지로 P4가 자원 R2를 반납하면 P3가 R2를 할당받아 작업을 수행한다.
-   왼쪽 `RAG`는 모든 프로세스가 서로의 자원을 요구하면서 무한정 대기한다.



그럼 이제 본격적으로 데드락을 해결하기 위한 방법들을 알아보자.

### Deadlock Prevention

위에서 알아 본 네가지 조건이 **동시에** 만족해야만 데드락이 발생하기 때문에 최소 하나 이상을 절대 발생하지 않도록 하는 방법이다.

1.  `Mutual Exclusion` (현실성 X)
    -   자원을 서로 동시에 사용하지 못하도록 하는 것이다. **Prevention**을 위해 Mutual Exclusion을 허용하지 않으면 공유를 가능하도록 만들어 준다는 것인데, 이 때 공유 불가능한 자원 자체가 존재하게 되는 경우 이 자원을 공유 가능하도록 만들어주는 것은 불가능 하므로 실행 불가능 이다.
2.  `Hold and Wait` (현실성 떨어짐)
    -   자원을 소유(**hold**)하면서 다른 자원을 요구하면서 기다리는 것을 방지하려면 `One shot Allocation`의 방법이 있는데 이는 프로세스가 자신에게 필요한 자원들을 한꺼번에 요구하고 동시에 허용될 때까지 프로세스를 보류시킴으로써 방지시키는 방법이다.
    -   다른 방법으로 프로세스가 자원을 전혀 갖고 있지 않을 때만 자원을 요청할 수 있도록 허용하는 방법이 있다.
    -   `One Shot Allocation`의 단점은 많은 자원을 동시에 요구하는 것은 제한적이며, 모든 자원을 얻어야 실행하므로 성능이 안 종하지며(**Low Throughtput**), 자원의 활용도가 떨어지며 **Starvation**의 문제가 발생할 수 있다.
3.  `No preemption` (현실성 떨어짐)
    -   프로세스가 필요한 자원을 가진 프로세스로부터 그것을 잠시 빼앗는다.
    -   하지만 Hold and Wait와 마찬가지로 빼앗긴 프로세스의 실행이 지연될 수 있는 문제(**Starvation**)가 발생할 수 있다.
4.  `Circular Wait` (그나마 현실성 있음)
    -   모든 **Resource Type**(ex. file, memory, sdd, print, ...)마다 번호를 매겨서(**Ordering**) 소스를 요청할 때 내가 점유하고 있는 것 보다 번호가 높은 것만 요청하는 것이다. (내가 가진 order보다 높은 order의 자원만 요청한다.)
    -   이렇게 Cycle이 형성되는 것을 막아 Deadlock으로 부터 보호한다.
    -   하지만 데드락은 안걸리겠지만 **Stravation**는 발생할 수 있다.
    -   이 Ordering은 Deadlock Preemption을 완벽히 보장할 수 없다.

***이 `Deadlock Prevention`은 자원의 자원의 활용도가 떨어지고 시스템 성능이 안좋아 질 수 있다.***



### Deadlock Avoidance

따라서 우리는 데드락을 예방(Prevention) 하지말고, 피해버리자(Avoid). 이를 Banker's Algorithm으로 할 생각이다.

기본적인 생각은 Deadlock이 될 수 있는 자원 할당 요청을 허락하지 않음으로써, Deadlock을 피하는 것이다.

![image-20210515123337463](https://user-images.githubusercontent.com/58545240/118347856-26b90380-b581-11eb-8a7a-69e079b7892f.png)

-   **Safe State** (안전 상태)
    -   안전상태에 있는 경우가 Deadlock에 발생하지 않는 상태이고, **Unsafe State**로 넘어가지 않도록 해야한다.
    -   동적으로 데드락이 발생하지 않는 **Cycle**을 찾아내어 자원을 할당하는 순서(**Safe Sequence**)를 정하여 데드락을 피한다.
    -   시스템 초기  상태는 항상 safe state이다.

#### > Resource-Allocation-Graph Algorithm

>   자원당 instance가 하나일 때 (Single Instance of Each Resource Type) 사용하는 알고리즘

![image-20210515125053166](https://user-images.githubusercontent.com/58545240/118347860-32a4c580-b581-11eb-95f0-5a87cb01bb8b.png)

-   위에서 살펴본 `RAG`에서 는 `Assignment Edge`와 `Request Edge`를 사용했는데 추가로 점선으로 표시한  **`Claim Edge`**를 사용한다.
-   이 **Claim Edge**는 프로세스가 자원을 요구할 가능 성이 있을 때 나타내주는 것으로 사전 정보를 가지고 표현한다.
-   이 3종류의 Edge로 **Cycle**이 만들어지지 않았으므로 위 그래프는 **Safe State**이다.

![image-20210515125251705](https://user-images.githubusercontent.com/58545240/118347867-39cbd380-b581-11eb-92b2-984d2932a359.png)

-   위 그래프는 3종류의 Edge로 **Cycle**이 만들어 졌으므로 **Unsafe State**이며 Deadlock은 아니지만 발생가능성이 있으므로 피해주어야 한다.
-   결론적으로 P2가 R2의 자원을 할당받는 것을 막아줌으로 피할 수 있는 방법이 있다.
-   이는 N개의 프로세스에 대해 **O(N<sup>2</sup>)**의 Time Complexity를 가진다.

#### > Banker's Algorithm

>   자원당 instance가 두개 이상(Multiple Instance of Each Resource Type) 일 때는 cycle detectoin만으로는 판별할 수 없다. 이에 따라 나온것이 은행원 알고리즘

![image-20210515125906564](https://user-images.githubusercontent.com/58545240/118347874-43553b80-b581-11eb-9989-a8b4d34d5280.png)

이 은행원 알고리즘을 위해서는 사전 정보가 필요하다.

-   `Allocation` : 현재 프로세스에 할당 되어 있는 자원 량
-   `Max` : 프로세스가 요 구할 수 있는 최대 자원량
-   `Available` : 현재 가용 자원량
-   `Need` : 프로세스가 현재 추가로 요구할 수 있는 자원량 (Max - Allocation)

여기서 P0는 추가적으로 A 7개, B 4개 C 3개를 요청할 수 있다.

P1이 A 2개 B 2개 C 2개를 요청했다고 가정할 때 현재 가용 자원으로 충분히 할당할 수 있지만 P1이 요구할 수 있는 최대 자원량보다 현재 가용자원량이 적으므로 자원을 할당하지 않는다.

이런 방법으로 순서(**Sequnce**)를 찾아보면 `P1 -> P3 -> P4 -> P2(or P0) -> P0(or P2)` 의 순서로 자원을 요청한다면, 모든 요청을 충족할 수 있고, 이는 **Safe State**가 된다.

***하지만 매번 Request가 하나씩 올 때마다 알고리즘을 사용한다면 시스템 오버헤드가 증가하게 되고 이는 비효율적이다.***



### Deadlock Detection

>   **-> Recovery Algorithm**

따라서 우리는, `Avoidance`보다 효율적인 `Detection`을 사용해보자. 이는 Deadlock을 감지하는 것으로 Deadlock이 발생한 것에 대해서 회복을 시키는 정도로 하는 것이다.

매 요청 마다 `Detection Algorithm`을 돌리는 것은 비효율적이고 상당한 Overhead를 야기하므로 언제 사용되어야 할지 잘 결정하는 것이 중요하다. (쓰레드가 얼마나 돌아가고 있느냐, 쓰레드의 개수에 따라 deadlock cycle이 증가할 수 있으므로)

얼마나 자주 데드락이 일어날지 예상하여, **deadlock detection**을 걸어주면 된다. (ex. 1년에 한번 데드락이 발생한다? -> 1달에 한번 detection)

가장 좋은 것이 바로 그냥 데드락을 걸리게 냅두자!!! -> **그렇게 해서 데드락이 감지되면 어떻게 하는가?**

1.  껐다 킨다.

2.  중요한 시스템이 있다면 **`Recovery(복원)`** 한다.

    *Recovery에는 두 가지 방법이 있다.*

    1.  데드락이 발견되면 정지된 프로세스를 끊어버린다.(**Process Termination**)
        -   Deadlock Cycle 중 의심 스러운 프로세스를 데드락이 해결될 때까지 하나씩 끊어본다. (비용이 크다.)
        -   우선순위에 따라, 실행된지 오래된 프로세스는 죽이지 않고 프로세스가 많은 프로세스를 죽이는게 효율적일 것이다.
        -   이처럼 프로세스를 어떻게 선택할지에 대해 효율성을 따져서 프로세스를 죽인다.
    2.  자원 선점 (**Recoure Preemption**)
        -   Deadlock Cycle이 없어질 때까지 자원을 선점하여 다른 프로세스에게 제공하는 방법이다.
            1.  **희상자 선택 (`Victim Select`)** : 원상태로 되돌리는데 비용을 적게 하도록 프로세스나 자원의 선점 순서를 결정
            2.  **복귀 (`Roolback`)** : 선점당하는 프로세스가 정상 상태로 복귀
            3.  **기아상태(`Starvation`)** : 동일한 프로세스가 계속해서 선점당하는 문제 (복귀 횟수를 비용 요소에 포함시킴으로써 해결 가능)

---

# [ 메모리 관리 전략 ]

>   메모리 관리 전략에 대한 내용은 https://jhnyang.tistory.com/ 를 일부 참고하였습니다.

프로세스는 실행중인 프로그램이고, 각각의 **프로세스**는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, **운영체제**만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않는다.

따라서 우리가 컴퓨터를 잘 활용하려면, 가능한 가장 효율적인 방법으로 메인 메모리를 분할하고 할당해야 한다.

## Dynamic Loading

**Loading**이란, 데이터를 메모리에 옮기는 것이다.
프로그램을 실행시키면, `.exe`에 있는 파일이 메모리에 올라가야 실행이 되는 것과 같이 데이터를 메모리에 옮기는 것을 로딩 즉, 메모리에 적재 한다고 한다.

**Dynamic Loading(동적 적재)**이란, 프로세스가 시작될 때 그 프로세스의 주소 공간 전체를 메모리에 올려놓는 것이 아니라, 메모리를 좀 더 효율적으로 사용하기 위해 필요한 루틴이 호출될 때 해당 루틴을 메모리에 적재하는 방식.

즉, 필요한 시점에만 올리니까 메모리를 더 효율적으로 쓰이는게 가능하다.

특징은, 필요할 때만 적재되서 코드 양이 많을 때 자주 호출되지 않는 루틴(에러처리 루틴)에 효율적이며 `OS`의 특별한 자원을 필요로 하지 않고 프로그래머의 재량에 따라 구현이 가능하다.

하지만 이는 옛날에 메모리가 부족했을때 사용된 방법이고, **`Virtual Memory Management`**가 나오고 나서는 더이상 필요하기 않게 되었다.

---

## Static Linking vs Dynamic Linking

먼저 **`Linking`(링킹)**에 대해 이해를 해보자

링킹은, 프로그램을 빌드하는 과정 (즉 컴파일 과정에서 거치는 단계) 이뤄지는 과정이다.

![image-20210516132238958](https://user-images.githubusercontent.com/58545240/118391861-6828dc00-b671-11eb-8dde-81546af88694.png)

이 전체를 크게 **컴파일 과정**이라고 한다.

작은 의미의 컴파일은 `Compile` 과정이고, 큰 의미의 컴파일은 `Compiling + Linking` 전 구간을 의미한다.

프로그래머들이 이해하기 쉬운 `C/C++`로 코드를 짜면  `Source.cpp`처러 소스파일이 생성된다.

그리고 이를 Build(빌드) 하게 되면 **`Compiling + Linking`** 과정을 거친 후 `.exe`파일을 내보내게 된다.

작은 의미의 컴파일인 Compiling만을 거치게 되면 **Object File(목적 파일)**인  `Source.obj`가 생성되게 되고 실제로 링킹과정까지 거치게 되면 `.exe`파일로 나오게 되는 것이다.

소스파일은 우리가 이해하기 쉬운 언어들이지 컴퓨터가 이해할 수 있는 단어는 아니다. 따라서 컴퓨터가 실제로 이해하고 실행하기 위해서는 Low Level언어(어셈블리어) , 이진수 파일로 변환해줘야 하는 과정을 거친다.

이렇게 변환하는 것을 **Compiling**이라 하고 변환해주는 애를 **Compiler**라고 한다. 이렇게 컴파일 과정 뒤에 생긴 Low Level언어의 파일이 **Object File(목적파일)**이다.

![image-20210516133505278](https://user-images.githubusercontent.com/58545240/118391868-724ada80-b671-11eb-87ea-148b40e2c635.png)

이 목적파일은 기계어로 작성된 로직과 실행하는데 필요한 부가 정보들(디버깅 정보, Symbol 정보)들로 이루어져 있다. 목적파일(Object File)은 실행파일(`temp.exe`)과 소스(`Source.cpp`)의 중간단계 인 것이다.

![image-20210516133447440](https://user-images.githubusercontent.com/58545240/118391878-7971e880-b671-11eb-8f22-3fb4c58fbe15.png)

이렇게 만들어진 Object File들을 링커가 링킹해서 실행파일로 만든다.

그림과 같이 Object File(목적 파일)과 Library Files를 **Link(더한게)** Executable File(실행파일) 이다.

효율적인 파일 관리를 위해 파일들을 분리해서 관리하는데 링커라는 프로그램은

1.  여러 소스코드 파일을 하나로 합친다. 즉 Object파일들을 하나로 합친다.
2.  여기에 Library를 합친다.

의 작업을 통해 실행파일을 만들어 준다.

예를 들어 `cout`이라는 클래스 라이브러리를 쓰기 때문에 `#include <iostream>`을 사용할 수 잇는 것처럼 `.exe`파일들을 하나로 링크하고 있다가, 이 `.exe`파일에다가 라이브러리를 집어넣어서(합쳐서, 링크해서) 실행파일을 완성하는 것이 바로 **`linking`**이다. 정확히는 **static linking**



### Static Linking

**Static Linking**은 말 그대로 실행파일을 만들 때 라이브러리를 같이 포함시켜 `.exe` 파일을 만드는 것을 정적 링킹이라고 한다.

-   장점
    1.  정적 라이브러리를 사용해 컴파일을 하면 링커가 프로그램이 필요로 하는 부분을 라이브러리에서 찾아 실행파일에 바로 복사를 한다.
    2.  실행파일에 다 들어가있기 때문에 **라이브러리가 필요가 없다**.
    3.  미리 컴파일 되어 있기 때문에 **컴파일 시간이 단축**된다.
    4.  직접 구현한 코드를 라이브러리화 시켜 **기술 유출 방지**로 사용 가능하다.
-   단점
    1.  실행 파일 내에 라이브러리 코드가 저장되기 때문에 **메모리를 어마어마하게 잡아먹는다.**
    2.  특히, 멀티유저시스템인 **LINUX, UNIX** `OS`의 경우 1번은 더욱 심각하다.

예를 들어, 100명의 유저가 `LINUX`, `UNIX` 서버에 접속해 동시에 "Hello World"를 출력한다고 가정해보자.

리눅스 에서는 실행파일이 hello 니까 (hello.exe가 아니다.) hello라는 프로그램을 실행시켰는데, 얘가 정적링킹으로 만들어진 실행파일이다.

즉,여기서 출력하는데 사용된 cout이라는 클래스 라이브러리가 정적으로 링킹되어 있다는 것은, hello라는 프로그램에 cout  클래스 라이브러리 코드가 전부 다 들어가있다는 것이다.
즉, hello를 동시에 100명이 실행시키면 메모리에 cout 정보만 100개가 존재하는 것이므로 매우 비 효율 적이다. 그래서 만든 것이 바로 **`Dynamic Linking`**이다.



### Dynamic Linking

그러면 **`Dynamic Linking`**은 무엇일까.

정적 링킹을 쓰니까 메모리에 쓸데 없이 똑같은게 너무 많이 들어있는게 아닌가.

그래서 이 cout과 같이 많이 쓰는 라이브러리는 메모리에 하나만 올리자!

그리고 이 프로그램이 cout을 호출할 때는 메모리에 있는 cout으로 점프해 그쪽으로 간 후에 실행한 다음에 다시 돌아 오게 하자는 것이 **Dynamic Lingking**이다.

현재 `Linux`, `Unix`, 뿐만 아니라 `Windows`에서도 별다른 옵션을 주지 않으면 Linking은 **Dynamic Linking(동적 링킹)**을 사용하게 된다.



이 동적 링크 라이브러리를 바로 **`DLL`(Dynamic Link Library)**라고 한다. 즉 윈도우에서 동적링킹할 때 사용되는 라이브러리 인데 이 `dll`파일들은 보통 windows 시스템 디렉토리에 존재한다.

```bash
# DLL(Winodws) == Shared Library(Linux, Unix)
Linux나 Unix에서는 DLL이라 부르지 않고 Shared Library라고 부른다.
따라서 .so라고 쓰거나 .sa라고 쓴다.
```

만약 "Hello World"를 C++ 라이브러리랑 같이 링킹을 해서 실행을 했는데 메모리에 `dll`파일이 없다. 그러면 실행을 못하니 운영체제가 메모리에 `dll`파일을 `load`시켜주는 것이다. 이렇게 메모리에 한번 적재되고 나면 그 다음부터는 적재된 `dll`파일이 수행되는 것이다.

*따라서 동적 라이브러리는 프로그램이 실행될때 링크된다.*

```bash
# Stub(스텁) 이란?
- 라이브러리가 메모리에 존재하지 않을 때, 라이브러리가 메모리에 상주할 수 있도록 라이브러리 루틴을 적절히 적재하는 방법을 알려주는 작은 코드 조각을 `stub`이라고 한다.
- 스텁은 모든 라이브러리 루틴에 들어 있는데 A라이브러리의 a루틴이 호출되면 stub이 루틴 주소로 대체 되어 그 다음에 그 코드가 한번 더 실수행 될 때는 Dynamic Linking 없이 바로 주소를 참조해 실행할 수 있게 되는 것.
- 런타임시 해당 루틴이 불리면 그 스텁은 자신을 그 루틴이 들어있는 주소값과 바꿔치기 하는 것이다.
- 한 번 스텁이 불리게 되면 스텁이 있었다는 사실은 사라지고 주소가 되어 한몸이 되는 것.
- 단 한개의 원본을 사용하게 해주어 코드가 중복 적재 되지 않아 메모리 절감 효과를 일으킨다.
```

-   장점
    1.  메모리 요구사항이 훨씬 적다.
-   단점
    1.  프로그램 영역에서 라이브러리가 저장되어 있는 주소로 점프를 하게 되어 성능상 약간의 overhead가 발생한다.
    2.  Dynamic Linking을 위한 불필요한 코드가 추가된다.(점프 해야 하니까)

***성능상에서는 정적 링킹이 좋지만, 메모리 관리 차원에서는 동적 링킹이 좋다.***

추가로 동적링킹이 좋은 점은, 우리가 direct X라는 게임 라이브러리를 활용한 게임을 즐긴다고 할 때, 이 게임에 성능이 업그레이드 되면 그 게임을 다시 사는 것이 아니라 Library의 버전만 up하면 되는 것이다. 그냥 업데이트만 해주면 되는 것!

dll 파일은 따로 그대로 저장되기 때문에 원래 코드와 라이브러리가 별도로 있는 것이므로 블랙코드는 그대로 있고, **library만 버전업되면 그거에 대한 성능응 그대로 받을 수 있게 되는 것이다.**

---

## 연속 메모리 할당

>   Contiiguous Memory Allocation

메모리는 크게 **운영체제를 위한 저장공간**과, **사용자 프로세스들을 위한 공간** 두 파티션으로 이루어져 있다.

운영체제는 인터럽트와 큰 상관관계가 있다. 사실 운영체제 데이터를 0번지 등의 메모리 하단에 위치시켜도 되고, 윗단에 위치시켜도 되는데, 보통은 밑단에 있다. 그 이유는 **인터럽트 벡터**가 주로 낮은 메모리에 위치되어 있다. 그래서 앞으로 운영체제는 메모리 주소 하단에 저장되어 있다 가정할 것이다.

-   **`MMU`** : CPU 코어 안에 탑재 되어서 가상 주소를 실제 메모리 주소로 변환 해주는 장치

기준점의 위치가 다르더라도 `offset`은 같기 때문에, 더하기를 통해서 물리적 주소도 논리적 주소처럼 연속적으로 배치되게 된다.

=> 이게 바로 연속적 메모리 할당 이라고 하는 `contiguous allocation`이다.

***즉, `Contiguous allocation 연속 메모리 할당이란 "logical address가 연속적이면 physical address도 연속적으로 배치된다" 라는 것이다.***



### Memory Protection

운영체제에는 CPU 관리, 메모리 관리, I/O 관리의 세 가지 기능이 있다.

CPU 관리를 위해선 `CPU Protection`이,
메모리 관리를 위해선 `Memory Protectioin`이,
IO 관리를 위해선 `I/O Protection`이 있다.

만약 `Memory Protection`이 없다면 (가정) 실제 램 memory 주소는 1000까지이고 base memory가 400번지라고 해보자. 근데 offset이 700이다. 그러면 400 + 700 해서 1100으로 우리가 갖고 있는 실제 메모리 주소 크기보다 벗어나면 문제가 발생할 수 있다.

***따라서 이렇게 잘못된 메모리 번지를 참조하지 않도록 막아주는 게 `Memory Protection`이다.***

그러면 내가 참조할 수 있는 범위인지 아닌지 어떻게 체크할 수 있을까? 

바로 **`limit register`(상한 레지스터)**가 추가 되었다. 상한 레지스터 보다 가상 주소 값이 크면 `Memory Protection fault`를 발생시킨다.

상한 값은 RAM 메모리 크기가 될 수도 있지만 현재는 그렇게 쓰이지 않는다. 멀티프로그래밍 시스템일 경우 각 프로세스들이 서로 메모리를 침범하면 안된다. 기본적으로 각각의 필요한 메모리를 보호해준다.



#### - memory protection fault란?

CPU 가 명령어를 수행하는데 이게 가상 주소가 1100000이었고, 얘가 참조할 수 있는 address는 100만 이었다고 합시다. 근데 얘가 110만번을 참조하고 그래요. 그러면 CPU는 이 명령어를 수행하면 안되지만 CPU가 하는 일은 CPU명령을 수행하는거지 판단을 하진 않는다.

그래서 실행을 하려 하는데 이게 참조하려는 메모리 크기보다 크니까 올바른 명령어가 아닐 때 **운영체제에게 도움을 요청**한다.

CPU가 자기 자신한테 인터럽트를 거는 것을 **`Exception`** 혹은 **`trap`**, **`fault`**이라고 한다.

`fault`는 조금 더 일반적인 명사를 의미하며 CPU가 자기 자신한테 인터럽트를 걸어서 이거는 내가 처리할 수 있는 명령어가 아니니, 운영체제보고 처리해달라고 요청을 하는 것이다.



### Memory Allocatoin

Process가 실행되기 위해서는 Memory에 적재되어야 하고, 자신만의 space를 가져야 한다. 그럼 어떻게 memory를 더욱 효율적으로 사용할 수 있을까?

고정된 영역만 memory에 할당하는 `static memory allocation`과는 다르게 `dynamic memory allocation`은 프로세스가 돌아가는 runtime 내에 영역의 크기를 알려줌으로써 영역을 확보하는 방법이다.

프로세스가 실행되고 종료되면서 충분히 들어갈 여러 공간이 있을 때, 현재 프로세스가 어떤 공간에 들어가는게 효율적일까? 라고 고민에 대한 세 가지 전략이 있다.

-   **Fisrt-Fit** (최초 적합)
    -   Linked List
    -   가장 최초로 발견되는 hole에 할당
    -   남은 메모리를 순차적으로 앞에서부터 탐색하는데, 이 프로세스가 들어갈 수 있는 hole중 최초에 발견된 hole에 배치
-   **Best-Fit** (최적 적합)
    -   Priority Queue
    -   여기다 넣을지 저기다 넣을지 다 한번씩 대보는 것이다.
    -   어차피 공간에 자투리이 생기긴 하지만, 가장 작은 자투리가 생기는 hole에 배치
-   **Worst-Fit** (최악 적합)
    -   Priority Queue
    -   가장 큰 공간, 즉 가장 남는 공간에다가 배치
    -   왜 이런 생각을 했을까? -> 자투리를 크게 만들어야 다른 프로세스가 거기 들어갈 확률이 있는 것 아니냐

***Dynamic Memory Allocation은어떤 Fit을 쓰건 결국 Externel Fragmentation(외부 단편화) 문제를 일으킨다.*** 

-   장점
    -   더하기 하나만 하면 되니까 `MMU`가 매우 간단하다.
    -   memory protectoin fault 체크 할 때 '이 값이 어떤 값보다 넘어섰냐 아니냐'만 체크하면 된다.
    -   즉, 하드웨어 만들기가 매우 쉽다.
    -   하지만, 안쓰이는 데는 이유가 있는법?!

### External Fragmentation

>   조각, 단편화

연속 메모리 할당은 MMU가 간단해지지만, 안쓰는 이유가 무엇인가. 그에 대해 알아본다.

프로세스들이 연속적으로 배치되고, 실행 후 종료가 되면 그 사이 사이에 공간(**Hole**)이 생긴다.

**External Fragmentation**이란 총 공간을 계산해 봤을 때 요청알 만족할만한 충분한 메모리가 있음에도 불구하고, 가능한 공간들이 연속적이지 않아 발생하는 문제이다.
(즉, 저장공간들이 많고 작은 hole들로 조각조각 나 있을 때)



![image-20210516141544430](https://user-images.githubusercontent.com/58545240/118391886-84c51400-b671-11eb-900d-0acd5e710c18.png)

이해를 위한 그림으로 여기서 프로세스 1과 5가 종료되어 메모리 공간이 있음에도 불구하고 실제로 할당할 수 없는 문제가 발생한다.

메모리는 엄청나게 비싼 자원인데 이런 문제로 메모리가 낭비되는것이다.

뭐 예를들어 남은 프로세스들을 한쪽으로 쭉 밀면 메모리 공간이 발생하게 되지만, `secondary stroage`인 하드디스크에다가 임시로 복사하고 저장하고, 하는 과정은 효율적이지 못해 실효성이 없는 방법이다.

이렇게 비어있는 공간을 연속적인 공간으로 만들고 움직이는 작업을 **compaction**이라고 한다.

이 방법은 `external fragmentation`을 줄일 수 있는 방법이긴 하지만, 메모리를 copy는 과정에서 반드시 **I/O Problem**을 일으키게 되므로 좋은 방법이 되지 않는다.

지금까지 배운방법은 **프로세스 크기** 별로 메모리를 할당하는데, 이를 가변 분할 이라고 한다. (모든 프로세스 크기는 다르니까)

그래서 메모리를 고정된 크기로 할당시키는 고정 분할 **`Paging`**이라는 기법을 배우게 된다. (여기서 내부 단편화가 발생한다)

---

## 단순 Paging

프로세스를 연속 메모리 할당(Contiguous Memory Allocation) 을 하게 되면, 외부 단편화(External Framentation)이 발생하게 되고, 값 비싼 메모리 자원의 1/3 까지 손실될 수 있는 현상을 타파하고자 나온것이 **`Paging`(페이징)**이다.

하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없앤다.

외부단편화와 압축(Compaction) 작업을 해소하기 위해 생긴 방법론으로, 물리 메모리(Physical Memory)는 **Frame**이라는 고정 크기로 분리되어 있고, 논리 메모리(프로세스가 점유하는)(Logical Memory)는 **Page**라 불리는 고정 크기의 블록으로 분리된다.

페이징 기법을 사용함으로써 논리 메모리는 물리 메모리에 저장될 때, 연속되어 저장할 필요가 없고 물리 메모리의 남은 프레임에 적절히 배치된다.



### 페이지의 크기와 논리적 주소 구성

```bash
# Logical Address (논리적 주소) : CPU에 의해 생성되는 주소체계
# Physical Address(물리적 주소) : RAM에 실질적으로 로드되는 주소
```

-   **page number(`p`)**
    -   Page Table의 Index로 사용되며, 각 page별 Physical Memory에서 시작 주소를 포함한다.
-   **page size**
    -   페이지 크기는 대게 512bytes에서 8192bytes까지 될 수 있는데, 4096bytes가 보통 전형적인 값이다.
    -   4096bytes(**4KB**)면 4 * 1024로 2의 12승이므로 **페이지 하나당 `12bits`를 차지한다**
-   **page offsert(`d`)**
    -   Base Address와 합쳐져서 Physical Memory Address로 변환된다.
    -   하나의 페이지가 4KB일 때 `page0`도 4KB가 된다. 결국 `page0`은 주소로 따지면 0번지에서 2<sup>12</sup>까지의 값의 번지까지 있는것이다.
    -   그렇게 해서 page번호 말고 page 내의 번호를 offset이라고 한다.
    -   `page0`의 0번 오프셋이라 하면 2<sup>12</sup> 위치의 논리주소가 되는 것이고,
    -   `page1`의 0번 오프셋이라 하면 2<sup>13</sup>번지에 위치한 주소를 가리키게 된다.

#### - 하나의 프로세스가 가질 수 있는 최대 크기?

만약 내가 사용하고 있는 운영체제가 32비트 프로세서이고, 페이지  크기가 4KB라고 가정한다면

![image-20210516175220749](https://user-images.githubusercontent.com/58545240/118391892-8db5e580-b671-11eb-8295-5f19c70857e2.png)

한 번에 CPU가 2의 20승 개수의 페이지 번호를 구분할 수 있게 된다.

![image-20210516175242216](https://user-images.githubusercontent.com/58545240/118391897-927a9980-b671-11eb-9d52-d91f2641a012.png)

2<sup>20</sup>개 이상의 페이지일 경우 `32bits`를 넘어가기 때문에 표현할 수 없다.

즉, **32비트 프로세서일 때 하나의 프로세스가 가질 수 있는 logical address 전체 크기는 2<sup>32</sup> , 페이지의 최대 개수는 2<sup>20</sup>이 된다.**

32bit 프로세서에서는 프로세스 하나의 크기가 4기가(2<sup>32</sup>)를 넘으면 안된다는 것!
근데 4기가짜리 프로세스는 사실 없지만, 32bit processor는 논리적으로 4기가 까지가 가능하다는 것이다.

### logical address -> physical address

![image-20210516145650482](https://user-images.githubusercontent.com/58545240/118391903-9b6b6b00-b671-11eb-811f-64a2b65c055e.png)

-   위 그림은 논리적 주소를 물리적 주소로 변환하는 Flow를 나타낸다.
-   p는 페이지 번호(page number), f는 프레임 번호(frame number), d는 페이지 오프셋(page offset)이다.
-   논리 메모리 앞 20bits에서 페이지 번호를 페이지테이블에서 검색하면 프레임번호가 나온다.
-   page의 크기하고 frame의 크기는 똑같기 때문에 offset은 똑같이 가면 된다.
-   **즉, 논리메모리에서 p페이지의 d오프셋 위치는 f프레임의 d에 적재되어 있다는 것이다**
-   Process의 PCB 내에 Page Table이 존재해야 한다.
-   Virutal Address를 Page Size로 나누어 Page Number를 구하고, 나머지 값은 offset이 된다.
-   Physical Memory의 주소를 구하기 위해서 Page Number를 통해서 Page Table을 뒤져본 후 Frame Number를 찾아낸다. 찾아낸 Frame Number를 Frame Size크기만큼 곱하게 되면 이는 Physical Memory의 시작주소가 되며, 여기에 Virtual Address를 Page Size로 나눈 나머지인 offset의 값을 더해주면 Physical Memory를 구할 수 있다.

```bash
1. Virtual Address / Page Size = Page Number
2. Virtual Address % Page Size = offset
3. Physical Address = Frame number * Frame Size + offset
```

예를들어 물리주소인 (0xf~~~~)를 쓸 필요가 없고 2(`p`)번 페이지에 23(`d`)번 주소를 access하자는 것이다.

이게 바로 logical address가 되는 것이다.

![image-20210516145616366](https://user-images.githubusercontent.com/58545240/118391908-a1f9e280-b671-11eb-9814-233038533469.png)

위 그림은 페이지 테이블의 구조를 나타낸다.

page0은 frame1에 있고, page1은 frame4, page2는 frame3, page3은 frame7에 있다고 알려준다.

**결국 페이지 테이블은 배열과 같다.**

배열처럼, 인덱스가 페이지 번호를 가르키고, 그 배열에 담고 있는 숫자가 매핑할 프레임 번호인 것이다.



![image-20210516145549689](https://user-images.githubusercontent.com/58545240/118391916-aaeab400-b671-11eb-9af7-0e720c3c6408.png)

각 운영체제는 페이지 테이블을 저장하기 위한 고유의 방법을 가지고 있다. 디스패처가 어떤 프로세스를 시작 시킬 때 이 레지스터들을 다시 적재하면 페이지 테이블도 함께 사용 할 수 있게 된다.

페이지 테이블은 레지스터의 집합으로 구현되기도 한다. 메모리의 모든 액세스는 이 페이징 맵을 통해야 하므로 매핑의 효율은 매우 중요하다. 디스패처는 이들 레지스터를 채우며 운영체제가 이를 담당한다.

페이지 테이블에 레지스터를 사용하는 것은 페이지 테이블이 작은 경우 적합하다. 하지만 대부분의 컴퓨터들은 수백만 항목에 이를 만큼 매우 크다. 이러한 컴퓨터의 페이지 테이블을 구현하기 위해서 빠른 레지스터를 사용하는 것은 부적절하다.(레지스터 비용이 비싸기 때문이다.) 

그래서 대부분의 컴퓨터는 페이지 테이블을 주 메모리에 저장하고 **페이지 테이블 기준 레지스터(PTBR, Page-Table Base Register)**로 하여금 페이지 테이블을 가리키도록 한다. 다른 페이지 테이블을 사용하려면 단지 이 레지스터만 변화시키면 되기 때문에 문맥 교환시간을 줄일 수 있다.

PTBR의 문제점은 메모리의 접근 시간이다. 원하는 주소에 접근하기 위해서는 페이지 테이블에 접근해야 하는데 요청한 번지에 접근하기 위해서는 **[프레임 번호 + 페이지 변위를 통한 실제 주소 의 접근]**으로 **2번의 접근**이 필요하기 때문이다. 이런 지연이 반복되면 너무 느리기 때문에 스와핑 방법이 유리 할 수도 있다.

PTBR의 메모리 속도 문제를 해결하기 위해 TLB(Translation Look-aside Buffer)이라 불리는 캐시가 사용된다. TLB는 매우 빠른 연관 메모리(associative memory)로 구성된다. TLB 내의 각 항목은 키(key)와 값(value)의 두 부분으로 구성 된다.

![image-20210516165725115](https://user-images.githubusercontent.com/58545240/118391923-b50cb280-b671-11eb-93d1-2cdb49fa5cb5.png)

TLB는 비싸므로 페이지 테이블의 일부분 밖에 가지고 있을 수 없다. CPU에 의해 논리 주소가 생성되면 그 페이지 번호를 TLB에 제시한다. 

사용하려는 페이지를 찾으면 그 프레임 번호를 알 수 있으며 메모리로 접근하는데 사용할 수 있다. **페이지 번호가 TLB에서 발견 되는 비율을 적중률(hit ratio)**라 부른다. 90%의 적중률은 TLB에서 원하는 페이지 번호를 발견할 횟수가 90%라는 것을 의미한다.



### Memory Protection

그럼 페이지화된 환경에서의 메모리 보호는 어떻게 이루어지는가? 

각 페이지에 붙은 보호 비트(**protectioni bit**)에 의해 구현된다.

이 비트들은 보통 페이지 테이블에 속해 있고, 메모리에 대한 모든 접근은 페이지 테이블을 거치므로 이 때 주소의 매핑과 함께 쓰기가 허용되는지 검사도 할 수 있다.

![image-20210516170309081](https://user-images.githubusercontent.com/58545240/118391926-bb029380-b671-11eb-982c-ccfc7d38a96c.png)

또한, 페이지 테이블의 각 항목에는 **`valid`한지 `invalid`한지 판별하는 비트**가 더 존재한다. 이 비트가 유효로 설정되면, 관련된 페이지가 합법적인 페이지이며 무효로 판전된다면 그 프로세스는 논리 주소 공간에 속하지 않는다.

이 비트를 이용해 페이지의 접근을 제한할 수 있다.



대부분의 프로세스들은 일정한 시각에 일정 부분의 주소 범위만 사용한다. 이런 경우 모든 페이지에 페이지 테이블 항목을 배정하는 것은 낭비이다. 일부 시스템은 페이지 테이블의 크기를 나타내기 위해 **페이지 테이블 길이 레지스터(PTLR, Page Table Length Register)**라는 레지스터를 제공 한다.

페이지는 공유를 쉽게 할 수 있다. 여러 프로세스들이 동시에 같은 코드를 수행 할 수 있으며 코드 부분을 공유하더라도 프로세스들은 레지스터의 복사 값과 프로세스가 저장소는 따로 가지고 있다. 물론 서로 프로세스의 자료는 다르다. 공유가 가능한 프로그램으로는 컴파일러, 시스템, 실시간 라이브러리, 데이터베이스시스템 등이 있다.

공유를 위해서는 반드시 **Reentrance Code(코드 재진입)**이 가능해야 하며 공유 코드의 읽기 전용 특징만으로는 코드의 정확성을 보장할 수 없기 때문에 운영체제에서 이를 보호해 주어야 한다.

```bash
# Reentrant Code
non-self modifying code
실행 중에 자기코드 변경이 없는 코드
```



![image-20210516145802919](https://user-images.githubusercontent.com/58545240/118391932-c35ace80-b671-11eb-9c59-c9638be39673.png)

-   위 그림은 비어있는 Frame에 대한 List에 대해서 page를 할당하는 과정이다.
-   그말은 즉, **OS는 비어있는 Frame에 대한 정보를 가지고 있다.**
-   **Frame Table**
    -   OS마다 Struct Type으로 Frame에 대한 정보를 가지고 있는 테이블이 존재한다.
    -   어떤 Frame이 위치하고 있는지, 존재하는 Total Frame의 개수 등의 정보를 가지고 있다.
-   A copy of Page Table
    -   OS는 프로세스의 PCB 내에 Struct Type으로 Page Table을 복사하고 유지한다.
    -   모든 Logical Address는 Physical Address로 변환되기 위해서 Page Table과 Mapping되어야 한다.
    -   Paging은 Context swtich Time을 증가시킬 수 있다.



### Internal Fragmentation

>   내부 단편화

**메모리를 할당할 때, 프로세스가 필요한 양보다 더 큰 메모리가 할당**되어서 프로세스에서 사용하는 공간이 낭비되는 현상이다.

Page size가 2048 bytes라고 가정하고, 프로세스의 size가 72,76 bytes라면, 35개의 page + 1086의 bytes가 사용되는 것이다. 이 말은 즉, 36개의 프레임이 사용되고 있지만 962 bytes가 내부 단편화로 낭비되고 있다는 것이다.

따라서 내부 단편화를 줄이기 위해서 Page의 Size가 작을수록 좋지만, 너무 작아져 버리면 Page Table의 Entry가 커지는 등 Overhead가 많이 발생하기 때문에 적당한 Size의 Page를 설정하는 것이 필요하다.

*때문에 요즘의 Page는 4KB 또는 8KB의 값을 갖는것이 일반적이다.*



### Swapping

**`Swapping`**이란 메모리의 관리를 위해 사용되는 기법으로, 표준 Swapping 방식으로는 `round-robin`과 같은 스케쥴링의 다중 프로그래밍 환경에서 CPU 할당 시간이 끝난 프로세스의 메모리를 보조 기억장치(하드 디스크)로 내보내고 다른 프로세스의 메모리를 불러들이는 것이다.

위에서 보았듯, 물리적 주소공간과 논리적 주소공간을 분리 시켜놓으니까 내가 만든 프로그램이 물리적 주소공간보다 훨씬 커져도 상관이 없다.

어차피 페이지를 쪼갰으니까!

![image-20210516151216849](https://user-images.githubusercontent.com/58545240/118391939-cb1a7300-b671-11eb-8391-42f514c5cad3.png)

CPU의 명령어와 그게 access하는 데이터는 메모리에 상주해야 하는데, 메인 메모리(`RAM`)에 불러올 때 `swap-in`이라 하고, 필요없으면 보조 기억장치로 보내는 것을 `swap-out`이라 한다. 이 과정이 **Swapping**이다.

전체 프로세스를 Swapping하는 것은 부담이 크지만, Paging 단위로 하면 부담이 적다.

이렇게 되면 Physical Memory와 Logical Memory의 분리는 발생할 수 있지만, 아주 작은 단위의 스와핑 까지 가능하기 때문에 오늘날 스와핑이라고 하면, `Swapping with Paging`이라고 한다. 따라서 `swap-out/swap-in` 보다 `page-in/page-out`이라고 할 수도 있다.

이러한 페이징 기법은 뒤에 배울 **Virtual Memory**에서 **`Demand Paging`**을 위한 기반 개념이 된다.

---

## 가상 메모리 Paging

다중 프로그래밍을 실현하기 위해서는 많은 프로세스들을 동시에 메모리에 올려두어야 한다. 가상메모리는 **프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법** 이며, 프로그램이 물리 메모리보다 커도 된다는 주요 장점이 있다.

실행되는 **코드의 전부를 물리 메모리에 존재시켜야** 했고, **메모리 용량보다 큰 프로그램은 실행시킬 수 없었다.** 또한, 여러 프로그램을 동시에 메모리에 올리기에는 용량의 한계와, 페이지 교체등의 성능 이슈가 발생하게 된다. 또한, 가끔만 사용되는 코드가 차지하는 메모리들을 확인할 수 있다는 점에서, 불필요하게 전체의 프로그램이 메모리에 올라와 있어야 하는게 아니라는 것을 알 수 있다.

-   프로그램의 일부분만 메모리에 올릴 수 있다면...
    -   물리 메모리 크기에 제약받지 않게 된다.
    -   더 많은 프로그램을 동시에 실행할 수 있게 된다. 이에 따라 `응답시간`은 유지되고, `CPU 이용률`과 `처리율`은 높아진다.
    -   **swap**에 필요한 입출력이 줄어들기 때문에 프로그램들이 빠르게 실행된다.



![image-20210519132212813](https://user-images.githubusercontent.com/58545240/118761695-d1962e00-b8af-11eb-8c44-926393a425c3.png)

위 그림과 같이 프로세스간의 페이지 공유가 가능하다.

-   `시스템 라이브러리`가 여러 프로세스들 사이에 공유될 수 있도록 한다. 각 프로세스들은 `공유 라이브러리`를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가있는 `물리 메모리 페이지`들은 모든 프로세스에 공유되고 있다.
-   프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 통신할 수 있다. 이 또한, 각 프로세스들은 각자 자신의 주소 공간처럼 인식하지만, 실제 물리 메모리는 공유되고 있다.
-   logical address는 physical address로부터 분리된다.
-   `fork()`를 통한 프로세스 생성 과정에서 페이지들이 공유되는 것을 가능하게 한다.

### Demand Paging

>   요구 페이징
>
>   요청 할 때 Paging을 한다.

프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략을 `요구 페이징`이라 하며, 가상 메모리 시스템에서 많이 사용된다. 그리고 가상 메모리는 대개 **Page(페이지)**로 관리된다. 요구 페이징을 사용하는 가상 메모리에서는 실행과정에서 필요해질 때 페이지들이 적재된다. **한 번도 접근되지 않은 페이지는 물리 메모리에 적재되지 않는다.**

프로세스 내의 개별 페이지들은 **`페이저(pager)`**에 의해 관리된다. 페이저는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어 옮으로서, **사용되지 않을 페이지를 가져오는 시간낭비와 메모리 낭비를 줄일 수 있다.**

![image-20210519132608996](https://user-images.githubusercontent.com/58545240/118761713-dd81f000-b8af-11eb-971f-99374df73ee0.png)

위 그림은 메인 메모리에 페이지가 존재 하지 않을 때의 **Page Table**의 상황이다. page table의 **valid-invalid bit**를 통해서 physical memory에 어떤 페이지가 올라가 있는지 확인한다.

-   `valid` : page가 legal 하면서 메인 메모리에 있다.
-   `invalid` : page가 not valid 하거나 Secondary Stroage(HDD, SDD)에 있다.

![image-20210519132850526](https://user-images.githubusercontent.com/58545240/118761715-df4bb380-b8af-11eb-9757-ca014d4684d6.png)

위 그림은 Page Fault가 일어 났을 때 처리하는 과정을 나타낸다.

1.  M이라는 페이지를 메모리에 로드하려고 할 때, page table에서 해당하는 페이지의 **vaild-invalid bit를 체크**한다.

2.  만약에 Page Fault라면(invalid) `MMU(Memory Management Unit)`가 **`O/S`에 trap을 발생**시킨다.

    2 - 1. 물리 메모리에 적재하기 위해서는 많은 시간이 소요되므로 해당 프로세스는 CPU 제어권을 뺐긴다.

    2 - 2. cpu `register`와 `process state` 및 `program counter`를 **PCB**에 저장한다.

3.  `Free-Frame List`에서 **비어있는 페이지를 찾는다.**

4.  `Secondary Stroage`에서 페이지를 읽어서 **새로운 프레임을 physical memory 할당**한다.

5.  기다리는 동안 CPU Core를 다른 process에게 할당한다(Context Swtich)

    5 - 1. disk i/o device controller에서 interrupt를 건다.

    5 - 2. 다른 process의 register와 process state를 저장한다.

6.  페이지를 메모리에 정상적으로 로드 했다고 page table의 valid-invalid bit를 **valid로 바꿔준다.**

    6 - 1. 프로세스를 ready queue로 이동시킨다.

7.  다시 CPU를 할당 받았을 때 PCB에 있던 값을 복원시켜 중단되었던 명령을 수행한다. (`Instruction Restart`)



**Pure Demad Paging**이라는 것은 요청을 하지 않으면 절대로 페이지를 가져오지 않고, 오로지 요청할 때만 페이지를 가져오는 것이다.
(-> 처음에 단 하나의 페이지도 로딩 하지 않고, Page Fault가 일어날 때 그 때 그 때 로딩한다.)

또한, Demand Page는 하드웨어 지원이 반드시 필요하다.

1.  Page Table

    : Valid or Invaliid bit

2.  Secondary Memory (**Swap Space**)

    : 메인 메모리에 존재 하지 않는 페이지를 저장하는 공간.
    : SSD가 빠른이유? (Swap이 엄청 빠르기 때문!!)



#### - Locality of Reference

>   참조 지역성

동일한 값 또는 해당 값에 관계된 스토리지 위치가 자주 액세스되는 특성으로, 지역성의 원리(principle of locality)라고도 한다.

참조 지역성에는 3 가지 기본형이 있다.

-   `공간(spatial) 지역성`
    -   특정 클러스터의 기억 장소들에 대해 참조가 집중적으로 이루어 지는 경향으로, 참조된 근처의 메모리를 참조한다.
-   `시간(temporal) 지역성`
    -   최근 사용되었던 기억 장소들이 집중적으로 액세스되는 경향으로, 참조했던 메모리는 빠른 시간에 다시 참조될 확률이 높다.
-   `순차(sequential)` 지역성
    -   데이터가 순차적으로 액세스되는 경향으로, 프로그램 내의 명령어가 순차적으로 구성되어 있다는 것이 대표적인 경우이다. 공간 지역성에 편입되어 설명되기도 한다.



#### - Free Frame List

Linked List로 Frame을 관리하는 Pool이다.

page fault가 발생했을때 second stroage에서 memory로 스왑핑할때, 이 free frame list에서 가져온다. 

반드시 stack or heap segment로 관리가 되어야 한다.



#### - Instruction Restart

page fault가 일어났을 때 가장 먼저 O/S에 trap을 걸어서 `wait queue`에 보내버린다, 그리고 마지막 단계에서 page in이 끝나면 다시 깨운다.

그러면 그 과정에서 **Context Switch**가 일어나는데 restart를 할 때 같은 상태 같은 위치에서 restart 해줘야 하는데, 그 때까지 페이지 테이블은 괜찮을까?
(중간 중간에 다른놈들도 Context Switch로 인한 페이지 인/아웃을 하면 어떻게 될까?)

그래서 page table을 잘 관리해야 한다. Fetch 할때 조심!!



#### - EAT

>   Effective Access Time with page faults

그러면 demand page의 퍼포먼스를 계산해보자.

-   **`p`** (0 <= p <= 1)
    : page fault가 발생할 확률

-   **`ma`**

    : memory access time

-   **`EAT`** = `(1 - p) * ma + p * page fault time`



#### - page fault service time의 세 가지 주요 작업 요소

1.  service the page-fault interrupt

2.  read in the page

    : page를 disk로부터 읽어와 frame에 적재 (I/O)

    : 가장 많은 시간이 소요된다.

3.  restart the process



#### - Demand Paging 장점

1.  당장 필요한 페이지만 메모리에 적재하기 때문에 **메모리 사용량이 감소한다.**
2.  프로세스 전체를 메모리에 올리는데 들었던 **입출력 오버헤드도 감소한다.**
3.  시스템이 **더 많은 프로세스를 수용**할 수 있게 해준다.
4.  **프로그램이 물리적 메모리 용량의 제약에서 벗어날 수 있게 해준다.**

---

### 페이지 교체 알고리즘

>   페이지 부재 발생 → 새로운 페이지 할당 해야함 → 현재 할당된 페이지 중 어떤 것을 교체할 지 결정하는 방법

![image-20210520210529647](https://user-images.githubusercontent.com/58545240/118988101-d9db8f80-b9bb-11eb-8069-ccbec194e2c6.png)

위 그림은 페이지 교체가 필요한 상황을 보여준다.

현재 1번 프로세스가 가리키고 있는(`PC`)가 B 페이지는 Page-Out되어 있는 상태고 Storage에서 B라는 페이지를 가져오려고(스와핑 시도) 하는데, 현재 physical memory에 자리가 없다(**no free frame**). 이 때 어떤 프로세스를 교체해야 가장 효율적으로 교체할 수 있을까?
**→ 페이지 교체 알고리즘 필요**

![image-20210520210651664](https://user-images.githubusercontent.com/58545240/118988130-e233ca80-b9bb-11eb-9dbc-b41970dea2b4.png)

victim(페이지 out의 대상)을 하나 정하고, victim이 있으면 page out - page in 시킨다.



그러면 어떤 Victim을 선택해야 효율적인가?

→ **Secondary Storage I/O**는 매우 시간이 많이 걸리기 때문에 이를 효율적으로 선택해야 시스템 효율이 증가한다.
→ 기왕이면 수정이 되지 않는 페이지를 선택하는 것이 좋다.

-   **`Page reference string` (참조 문자열)**
    -   CPU는 논리 주소를 통해 특정 논리 주소를 요구한다.
    -   메인 메모리에 있는 주소들은 페이지의 단위로 가져오기 때문에 페이지 번호가 연속되어 나타나게 되면 결함이 발생하지 않는다.
    -   따라서 CPU의 주소 요구에 따라 페이지 결함이 일어나지 않는 부분은 생략하여 표시하는 방법이 `Page Reference String`이다.
    -   이을 가지고 page faults의 개수를 계산한다.(frame이 많으면 많을수록 page faults는 적어진다.)
        (ex. `7 0 1 2 0 3 0 4 2 3 0 3 0 3 2 1 2 0 1 7 0 1`)



#### - FIFO

>   Fisrt-In Fisrt-Out
>
>   과거를 바라본다.

-   메모리에 먼저 올라온 페이지를 먼저 내보내는 알고리즘
-   가장 오래된 페이지를 교체한다.
-   초기화 코드에서 적절한 방법이다.
-   **장점**
    -   구현하기도 쉽다.
-   **단점**
    -   **Belady's Anomaly**가 발생한다.
    -   page frame의 개수를 늘리면 늘릴수록 page faults가 줄어야 하는데 오히려 늘어나는 현상



#### - OPT

>   Optimal
>
>   미래를 바라본다.

-   앞으로 가장 사용하지 않을 페이지를 먼저 내보내는 알고리즘
-   FIFO에 비해 결함의 횟수를 많이 감소시킬 수 있다.
-   하지만, 실질적으로 `futrue knowledge`가 필요하기 때문에, 단지 논리적으로만 최적의 알고리즘이다.



#### - LRU

>   Least Recently Used
>
>   과거 + 미래

-   최근에 사용하지 않았으면 나중에도 사용되지 않을 것이라는 아이디어이다.
-   실직적으로 사용이 가능한 알고리즘
-   최근 가장 오래동안 사용(참조되지)하지 않은 페이지를 내보낸다.
-   **OPT**보다는 페이지 결함이 더 일어날 수 있지만, 실질적으로 가장 좋은 방법 중 하나이다.
-   **단점**
    -   해당 프레임이 언제 마지막으로 사용되었는가 알아야 하지만 그 계산하는 데 비용이 많이 든다.
    -   그래서 하드웨어 지원이 받는 것이 쉽지 않다..

-   `Counter implementation`
    -   페이지가 참조될 때 counter(or clock)을 copy해서
    -   가장 낮은 값을 가진 페이지를 교체한다.
-   `Stack implementation`
    -   page number를 스택으로 구현

#### - LRU Approximation

>   LRU 근사 페이지 교체

-   LRU 알고리즘을 소프트웨어로 구현하는 것은 비용이 너무 많이 들고, 하드웨어 도움을 받아야 하지만 그것이 쉽지많은 않다.
-   따라서 하드웨어의 지원없이 **reference bit** 이용해서 구현하는 알고리즘이다.

1.  **`Additional-Reference-Bits Algorithm`**
    -   Page Table 내 각각의 Page에 **8비트 짜리 참조 비트**가 존재해서 **일정 시간의 간격마다 Access 되었던 페이지**들의 비트들을 오른쪽으로 Shift하는 연산을 수행한다.
    -   그러면 가장 큰 값의 비트를 가진 페이지가 최근에 Access되었다는 것을 알 수 있다.
    -   또한 가장 작은 값의 비트를 가진 페이지들이 `Victim Page`로 선택이 되면서 같은 값에 대해서는 FIFO 알고리즘을 이용해 `Victim`을 선정한다.
2.  **`Second-Chance Algorithm`**
    -   말 그대로 한번의 기회를 더 준다.
    -   Page Table의 각각의 Page 에는 **1비트 짜리 Reference Bit**가 존재하고 **초기값은 모두 0이며 Access가 되면 1로 바꾼다**
    -   `FIFO` 알고리즘을 기반으로 하기 때문에 `Reference Bit`가 1이어도 선택이 될 수 있는데, 이 때 **만일 `Reference Bit`가 1이면 최근에 Access되었다는 것으로 간주하여 0으로 바꾼 후, 한 번의 기회를 더 주고** 다른 `Victim Page`를 찾는다.
    -   **`Reference Bit`가 1이면 한번 봐주고 `Reference Bit`가 0이면 (그 다음에도 참조가 되면) `Victim`으로 선정**한다.
    -   시계 방향으로 탐색하며 원형의 구조를 생각할 수 있어서 Clock Algorithm 이라고도 한다.
3.  **`Enhanced Second-Algorithm`**
    -   `Reference Bit`와 `Modify Bit`를 이용해서 `Victim Page`를 찾는다.
    -   해당 부분 내의 값이 바뀌면 `Modify Bit`를 1로 바꾸어준다.
    -   **`Reference Bit`와 `Modify Bit`가 둘 다 1이라는 뜻은 최근에 Access되고 값의 변화가 있으므로 다시 선택될 가능성이 높다는 뜻이고, `Victim Page`로는 적절하지 않다는 의미**이다.
    -   하지만 모든 Page Table을 전부 뒤져야 한다는 단점이 존재한다.

#### - Counting Algorithm

>   카운팅 알고리즘은 일반적으로 잘 사용되지 않는다.
>
>   구현하는데 많은 비용이 들고 최적 페이지 교체 정책을 제대로 근사하지 못하기 때문이다.

##### - LFU

>   Least Frequently Used
>
>   Counting Based Algorithm

-   참조 횟수가 가장 적은 페이지를 교체하는 알고리즘
-   활발히 사용되는 Page는 큰 참조 값을 가지게 될 것이고 교체될 가능성이 적다고 판단한다.
-   하지만 초기에는 많이 사용되고 나중에는 많이 사용되지 않는다면 문제가 된다.
-   해결책으로 참조 횟수를 일정한 시간마다 하나씩 오른쪽으로 이동해서 지수적으로 그 영향력을 감소시키는 방법이 있다.

##### - MFU

>   Most Frequently Used
>
>   Counting Based Algorithm

-   참조 횟수가 가장 많은 페이지를 교체하는 알고리즘
-   가장 작은 참조회수를 가진 페이지가 가장 최근에 참조된 것이고 앞으로 사용될 것이라는 아이디어.



**Frame Allocation Issue**

128frame 중에 35 frame을 사용하고, 93frame이 남았다고 생각하자.

그러면 93 page faults가 일어나서 93 frame이 다 차고, 94번째 page faults가 일어났다고 가정하자.

근데 두개의 프로세스가 있는데 어떤 프로세스에게 프레임을 더 많이 줘야하나?

**N개의 프로세스가 존재할 때 M개의 프레임이 주어지면 어떻게 할당할 것인가?** 라는 문제가 존재한다.

-   `Equal` vs `Proportional`
    -   모든 프로세스에게 동등하게 줄것이냐 vs 프로세스 사이즈가 큰, 많이 필요한 애한테 많이 줄거냐ㅑ
-   `Global` vs `Local`
    -   자기 victim을 global하게 할당할 것이냐, 자기 victim을 자기 껄로 정할거냐, 
    -   `Global` : 메모리 상의 모든 프로세스 페이지에 대해 교체하는 방식 (**실제로 Local보다 효율이 좋다**)
    -   `Local` : 메모리 상의 자기 프로세스 페이지에 대해서만 교체하는 방식

#### Thrashing

>   스레싱
>
>   page fault가 빈번하게 발생하여, 페이지 교체하는(page-in , page-out) 시간이 많아지는 현상

-   어떤 프로세스가 busy swapping page in and out 상황에 있을 때 (swapping하느라 너무 바쁠때)
-   프로세스가 충분한 페이지를 가지고 있지 못한다면
    -   `page-fault` 비율이 매우 높을때
    -   = 멀티 프로그래밍의 정도가 매우 높아 질 때 (`degree of Multiprogramming`)
-    어느 시점에서 **CPU Utilization**이 급격히 하락한다.
-   ex. 프로세스가 100개인데 페이지가 100개이다. CPU는 놀고 있는데 프로세스는 스와핑하느라 너무 바쁜 상태
-   **해결방법**
    -   메인 메모리를 늘려준다. (physical memory가 부족해서 나타나는 현상이기 때문에)
    -   하드디스크를 SSD로 바꿔준다.



##### < Working-Set Model >

![image-20210520213027955](https://user-images.githubusercontent.com/58545240/118988167-ea8c0580-b9bb-11eb-813e-0de9902e9a7a.png)

-   위 그림과 같이 한군데만 막 집중적으로 참조(**참조 지역성**)하다가 텅 빈 공간이 생기게 된다.
-   그럼 인접한 곳(가장 많이 쓰이는 곳) 계속 메모리에 상주시켜 스레싱을 줄일 수 있다.
-   워킹셋 윈도우에 해당하는 페이지들은 Victim으로 선정하지 않는다.
-   **`Working Set`**
    -   메모리에 한꺼번에 올라가 있어야 하는 페이지들의 집합
-   **`Working Set Window`**
    -   워킹셋 윈도우를 주로 델타로 나타내고, 이는 고정되어 있다.
-   **`Working Set Size`**
    -   각 프로세스 별로 가장 많이 쓰이고 있는 페이지의 개수

![image-20210520221842093](https://user-images.githubusercontent.com/58545240/118988206-f11a7d00-b9bb-11eb-8ff8-9cd3846a0f97.png)

이 워킹셋 속한 페이지들은 가장 최근에 참조된 페이지들의 집합이기 때문에
만약에 해당 페이지가 사용중이라면, 해당 페이지는 워킹셋에 속해 있을 것이고
만약에 해당 페이지가 더이상 사용중이지 않다면, 워킹셋 바깥에 있을 것이기 때문에, 바깥에 있는 페이지들을 `Victim`으로 선정한다.

왼쪽 그림과 같이 **워킹셋 윈도우**가 10으로 고정되어 있으면, `t1` 에서 **워킹셋**은 `{1, 2, 5, 6, 7}`이고, **워킹셋 사이즈**는 5이다.

오른쪽 그림과 같이 **워킹셋 윈도우**가 10으로 고정되어 있으면, `t2`에서 **워킹셋**은 `{3, 4}`이고, **워킹셋 사이즈**는 2이다.



각 프로세스의 워킹셋 사이즈 총합을 `D`라고 하면
`D` : 현재 각 프로세스가 필요로 하는 전체 프레임의 개수
`m` : physical memory의 크기 일때

**`D > m` 이면 스레싱이 발생하므로 `D`가 `m`보다 작도록 계속 유지해야 스레싱이 발생하지 않는다.**

*=> 따라서 `Working Set Model`은 **Thrashing** 문제를 해결할 수 있는 모델이다.*

##### < PFF >

>   Page Fault Frequency

Page-Fault의 빈도를 조절하는 방법으로 페이지 폴트가 적당한 범위 기준 내에서 발생하도록 유지하는 방법이다.

-   page fault 발생 횟수가 상한선을 초과한다면
    -   프레임 할당이 너무 적다는 것을 의미하므로
    -   프레임을 추가하여 늘려준다.
-   page fault 발생 횟수가 하한선 미만이라면
    -   프레임 할당이 너무 많아 **메모리 낭비** 중인 것을 의미하므로
    -   프레임을 회수하여 줄여준다.